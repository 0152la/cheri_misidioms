%&cheri_misidioms_preamble
\endofdump

\begin{document}


\begin{abstract}
\noindent
Various open-source memory allocators have been ported to CHERI, a hardware capability
platform. In this paper we examine the security and performance of these
allocators when run under CheriBSD on Arm's experimental Morello platform.
We introduce a number of security attacks and show that all but one allocator,
including the default CheriBSD allocator, are vulnerable to some of the attacks.
We then show that while some forms of allocator performance are meaningful,
comparing the performance of hybrid and pure capability (i.e.~`running in
non-CHERI vs.~running in CHERI modes') allocators does not appear to be meaningful.
Although we do not fully understand the
reasons for this, it seems to be at least as much due to factors such as
immature compiler toolchains as it is due to the effects of capabilities on
hardware.
\end{abstract}

\maketitle

\section{Introduction}

CHERI (Capability Hardware Enhanced RISC Instructions) provides and enforces hardware
capabilities that allow programmers to make strong security guarantees
about the memory safety properties of their programs~\cite{watson20cheriintroduction}. However, capabilities are
not magic. Programmers must first decide which memory safety properties they
wish to enforce and then write their software in such a way to enforce those properties.
It is easy for mistakes to creep in during either step, undermining
the security guarantees programmers believe their code possesses.

In this paper we examine one of the most fundamental software components:
memory allocators (henceforth just ``allocators'').
Apart from some embedded
systems (which preallocate fixed quantities of memory), allocators are
ubiquitous, because they allow us to write programs that are generic over a
variety of memory usage patterns. Since allocators are used so frequently,
their security properties and performance are a major part of
the security properties and performance of software in general. In other words,
allocators with security flaws and/or performance problems have significant,
widespread consequences.

Our work studies allocators and CHERI from both security and performance
angles. We show that most CHERI allocators are subject to at least some simple attacks
that are likely to surprise reasonable programmers.
We then show that while some forms of allocator performance are meaningful,
comparing the performance of hybrid and pure capability (i.e.~`running in
non-CHERI vs.~running in CHERI modes') allocators does not appear to be meaningful.
We analyse some of the likely factors for this latter case,
showing that it appears to be as much about the maturity of factors
such as the compiler toolchain as it is about the effects of capabilities on hardware.
We do not claim that our
work is definitive, though it does suggest two things: that some allocators
undermine the security properties one might expect from software running on
pure capability CHERI; and that it is currently difficult to reason about the
relative performance impact of CHERI on software.

This paper is structured as follows. First, we introduce the necessary
background: a brief overview of capabilities and the CHERI project (\autoref{sec:cheri});
our running example, a trivial bump allocator (\autoref{sec:bumppointerallocator}); and
a simple example of how allocators can be vulnerable, or invulnerable, to attack on CHERI
(\autoref{sec:atk}). Then, we introduce our experiments: the allocators
under consideration (\autoref{sec:cheriallocators}); our attacks (\autoref{sec:atks});
a partial performance evaluation (\autoref{sec:performance}) and an analysis
of some of the performance discrepancies we uncovered (\autoref{sec:dissection}).


\section{CHERI Overview}
\label{sec:cheri}

In this section, we provide a simple overview of CHERI, and its major concepts.
Since CHERI has been developed over a number of years, and is explained across
a range of documentation and papers, some concepts have acquired more than one name,
or names that subtly conflict with mainstream
software development definitions. We use a single name for each concept, sometimes
introducing new names where we believe that makes things clearer.

A \emph{capability} is a token that gives those who bear it \emph{abilities} to
perform certain actions. By restricting who has access to a given capability,
one can enforce security properties (e.g.~`this part of the software can
only read from memory address range X to Y'). Capabilities have a long  history: \cite{levy84capability}
provides a narrative overview of capability architectures, and
may usefully be augmented by more recent work such as~\cite{miller06robust}.
A good first intuition is that CHERI is a modern version of this longstanding
idea, updated with fine-grained permissions, and adapted to work on recent
processor instruction sets.

We use the term \emph{CHERI} to refer to the `abstract capability machine'
that software can observe: that is, the combination of a capability hardware
instruction set, an ABI (e.g.~\cite{brooks19cheriabi}), a user-facing library that exposes
capability-related functions, and a CHERI-aware language. (e.g.~CHERI C~\cite{watson20chericprogramming},
an adaption, in the sense of both extending and occasionally altering, of C).
We refer to specific hardware implementations by their name (e.g.~CHERI
RISC-V). In this paper, we use Arm's `Morello' implementation, which is an
experimental ARMv8 chip extended with CHERI instructions.

\label{abilities}
Conceptually, a CHERI system starts with a `root' capability that has
the maximum set of abilities. Each
new \emph{child} capability must be derived from one or more \emph{parent}
capabilities. A child capability must have the same, or fewer, abilities than its
parent: put another way, capabilities' abilities monotonically decrease.
An \emph{authentic}\footnote{CHERI calls these
`tagged' or `valid' (and their inauthentic counterparts `untagged' or `invalid').}
capabilityÂ is one that has been derived from authentic parents according to
CHERI's rules. Attempts to create capabilities that violate CHERI's rules
cause the hardware to produce an \emph{inauthentic} result, guaranteeing
that capabilities cannot be forged. For example,
there is no user-space mechanism to set a capability as `valid'; only a child capability
derived, correctly, from valid parent capabilities can itself be valid.

A capability consists of a memory
\emph{address}\footnote{This portion of a capability does not \emph{have} to store an
address, though typically it does so, and the CHERI API calls it \texttt{address}.
In the context of this paper, since it always stores an address, we stick with this name.},
and its abilities: a set of \emph{permissions} (only a subset of
which we consider in this paper);
and \emph{bounds}, the memory range on which
the capability can operate.

Permissions include the ability to read / write from / to memory.
A \emph{permissions check} is said to be successful if the permission required
for a given operation is provided by a given capability.

A capability's bounds
are from a \emph{low} (inclusive) to a \emph{high} (exclusive) address: when
we refer to a capability's bounds being of `$x$' bytes we mean that
$\textit{high}-\textit{low}=x$. An address is
\emph{in-bounds} for a given capability if it is wholly contained within the
capability's bounds, or \emph{out-of-bounds} otherwise; a capability is
in (or out) of bounds if its address is in (or out) of bounds\footnote{See~\cite{woodruff19chericoncentrate} for an explanation of why an authentic
capability might have an out-of-bounds address.}.
A \emph{bounds check} is said to be successful if a given capability, address, or
address range, is in-bounds for a given capability.

A processor instruction that operates on a capability requires one or more of: an authenticity
check, a permissions check, or a bounds check. If a capability passes the
relevant checks, then the operation \emph{exercises} the capability. If a
capability fails the relevant checks then either: the hardware produces a
\lstinline{SIGPROT} exception; or produces an inauthentic capability as a result (where this is not
in violation of the CHERI rules). For example, a failed attempt to exercise a capability for a
sealing operation on Morello produces an inauthentic result, rather than an
exception.

On Morello and CHERI RISC-V, capabilities behave as if they are 128 bits in
size, but also carry an additional (129th) bit that records the authenticity of each
capability: the authenticity bit can be read, and can be unset, but cannot
be set (i.e.~authentic capabilities must be created via hardware following
CHERI's rules).

CHERI also allows `traditional' single-width
pointers-as-addresses (which on Morello and CHERI RISC-V are 64-bit addresses)
to be used. Although CHERI processors allow both double-width capabilities and
single-width addresses-as-pointers to exist alongside each other at any time,
conventionally, a program which uses both traditional addresses and
capabilities is said to be operating in \emph{hybrid} mode while a program
which uses only capabilities is in \emph{pure capability} -- henceforth ``purecap'' -- mode. In this paper
we concentrate exclusively on programs which operate in pure capability mode
unless otherwise stated.
Further, this study only explores capability-based memory safety
and does not consider CHERI support for software compartmentalization.


CHERI does not presuppose a particular Operating System (OS). While there is a
CHERI Linux port, at the time of writing the most mature OS for CHERI hardware
is CheriBSD, a FreeBSD descendent. In this paper we use CheriBSD exclusively.


\section{A Basic Pure Capability Allocator}
\label{sec:bumppointerallocator}

To illustrate how CHERI affects allocators, in this section we adapt a simple
non-CHERI aware allocator to become CHERI aware.

\begin{figure}[t]
\lstinputlisting[
  language=C,
  caption={
    A simple, but complete, non-CHERI aware, bump pointer allocator:
    \fnc{malloc} works as per normal; \fnc{free} is a no-op; and
    \fnc{realloc} always allocates a new chunk, copying
    over the old block.
    \fnc{\_\_builtin\_align\_up(v, a)} is an LLVM / clang primitive which rounds
    \texttt{v} up to the next smallest multiple of \texttt{a};
    \texttt{\_Alignof(max\_align\_t)} returns an alignment sufficiently large
    for any scalar type (i.e.~integers and pointers).
  },
label=lst:bump_alloc1]{code/bump_alloc1.c}
\end{figure}

We start with a simple, complete, example of a C bump allocator in~\autoref{lst:bump_alloc1}:
\fnc{malloc} works as per normal; \fnc{free} is
a no-op; and \fnc{realloc} always allocates a new chunk of memory. The
allocator reserves a large chunk of memory using a single \fnc{mmap} call then
doles out chunks on each \fnc{malloc} / \fnc{realloc} calls. The bump pointer
moves through the \fnc{mmap}ed chunk until it reaches the upper limit, at which
point the allocator returns \texttt{NULL}s. \fnc{realloc} is intentionally
simplistic, but correct even when the block is increased in size.


\subsection{Adapting the Allocator to CHERI}
\label{sec:adapting_to_cheri}

Perhaps surprisingly, our simple bump allocator compiles, and \fnc{malloc} runs
correctly, on CHERI systems too. As this suggests, CHERI C is largely source
compatible with normal C code, though pointer types are transparently `upgraded' to become
\emph{capability types} (on Morello occupying exactly twice the space of a
non-capability pointer). CHERI also implies changes in libraries: on CheriBSD,
for example, \fnc{mmap} returns a capability whose bounds are at least those of
the size requested: from that capability our bump allocator derives new
capabilities that differ in their address, but not their bounds. In other
words, two calls to \fnc{malloc} will produce two capabilities that have the
same bounds, allowing anyone who possesses one of the capabilities to read and
write from any portion of \fnc{malloc}ed memory.

\begin{figure}[t]
\lstinputlisting[language=C,
  caption={
    Replacing the non-CHERI aware \fnc{malloc} from ~\autoref{lst:bump_alloc1}
    with a CHERI-aware alternative
    using the idioms suggested in~{\cite[p.~30]{watson20chericprogramming}}.
    This \fnc{malloc} returns a capability whose bounds are sufficient
    to cover \texttt{size} bytes starting at the capability's address
    (calculated in lines 5--9),
    such that two callers to \fnc{malloc} cannot read or write from
    another block. We also have to update \fnc{realloc} so that it never tries to copy
    more data from the old block than the \texttt{ptr} capability gives
    it access to.
  },
    label=lst:bump_alloc2]
  {code/bump_alloc2.c}
\end{figure}

As this suggests, using CHERI without careful consideration may lead to
no additional security benefits of using CHERI. This then raises the question:
how should a secure `CHERI aware' allocator behave? There can be no single
answer to this question, but we believe that most programmers would at least expect
\texttt{malloc} to return a capability restricted to the block of memory
allocated. \autoref{lst:bump_alloc2}
shows how to adapt \texttt{malloc} to do this.

The code to create the capability (using the idioms suggested
in~\cite[p.~30]{watson20chericprogramming}) is more involved than one might
first expect. The underlying cause is that there aren't, and cannot reasonably
be, enough bits in CHERI's bounds to precisely represent every possible address
and size. Modern CHERI therefore uses an encoding for bounds that allows small
bounds to be precisely represented, at the expense of larger bounds becoming
progressively less precise~\cite{woodruff19chericoncentrate}. On Morello,
the smallest bound that cannot be precisely represented is 16,385 bytes,
which is rounded up to 16,392 bytes\footnote{For CHERI RISC-V the first unrepresentable length is
4,097 bytes, which is rounded up to 4,104.}. Our capability aware
\texttt{malloc} thus has to ensure that both the capability's low and high
bound addresses are rounded down and up (respectively) in a way that ensures
that the address and size can be fully covered.

The two versions of our allocator have meaningfully different security properties,
even when we run both on a CHERI system. For example, consider this simple
C snippet which models a buffer overrun:

\begin{lstlisting}[language=C]
char *b = malloc(1);
b[0] = 'a';
b[1] = 'b';
\end{lstlisting}

On a non-CHERI system, or a CHERI system with \autoref{lst:bump_alloc1}
as an allocator, this snippet compiles and runs without error. However, with
the allocator from \autoref{lst:bump_alloc2} the code compiles but crashes with
a security violation when attempting to execute line 3, due to the tighter
capability bounds returned by its \texttt{malloc}, showing how CHERI can prevent
programmer errors becoming security violations.

However, just because a program compiles with CHERI C does not guarantee that
it will always run without issue: when run on CHERI, \fnc{realloc} in~\autoref{lst:bump_alloc1}
causes a hardware security exception if asked to
increase the size of a block. This occurs because \fnc{memcpy} tries to copy
beyond the bounds of the input capability (e.g.~if the existing block is 8
bytes and we ask to resize it to 16 bytes, \fnc{memcpy} tries to read
16 bytes from a capability whose bounds are 8 bytes). On a non-CHERI system,
this is not a security violation, but it is treated as one on CHERI. In
\autoref{lst:bump_alloc2} we thus provide an updated \fnc{realloc} which
uses \texttt{cheri\_length\_get} (which returns a capability's bounds
in bytes) to ensure that it never copies more data than the input capability's
bounds allow.


\section{How can a CHERI Allocator be Attacked?}
\label{sec:atk}

Our definition of CHERI in~\autoref{sec:cheri} might suggest that software
running on CHERI hardware is invulnerable to attack. Alas, while CHERI gives us the
tools to make secure software, it is up to us to use them correctly --- and wisely.
We must decide which attack model is relevant to our use-case, and then write,
or adjust, the software, to withstand such attacks. Broadly speaking, allocators are
subject to spatial (e.g.~buffer overrun) or temporal (e.g.~a sequence of
function calls) attacks, and those attacks can be either on an allocators'
internals (e.g.~corrupting its private data-structures) or its interface
(e.g.~allowing code using the allocator to subvert expectations).

For example, consider this C snippet, which models a buffer overrun:

\begin{lstlisting}[language=C]
char *a = malloc(16);
char *b = malloc(16);
a[16] = 'c';
printf("%c\n", b[0]);
\end{lstlisting}

With the capability-unaware bump allocator from \autoref{lst:bump_alloc1} this
code compiles successfully and, when run, prints `\texttt{c}'\footnote{Note
that the example is in the realm of undefined behaviour, so a compiler could
compile this code to do something entirely different -- though, at the time of
writing, CheriBSD's LLVM does not do so.}. It does this because the bump
allocator allocates the second block immediately after the first in memory, so
writing 1 past the end of the first block in fact writes to the first byte of
the second block. However, with the
capability-aware allocator from \autoref{lst:bump_alloc2}, the program aborts
with a security exception when executing line 3.

Buffer overruns are so common in C code that we expect most people to consider
that part of their attack model: by extension, we believe that they
would expect a CHERI allocator to protect against such attacks. However, the
difference between~\autoref{lst:bump_alloc1} and~\autoref{lst:bump_alloc2}
shows that such protection often requires careful adjustments of code to
take advantage of CHERI. As we
shall see later, it is not just our bump allocator that is subject to this
particular attack.


\section{CHERI Allocators}
\label{sec:cheriallocators}

In this paper we consider a number of allocators that are available for
CheriBSD. We first explain the set of allocators we use, before
exploring in more detail how the allocators have been adapted (if at all) for
CHERI.


\subsection{The Allocators Under Consideration}

A number of allocators are available for CheriBSD, installable via three
different routes: as part of the base distribution; via CheriBSD
\emph{packages}; or via external sources.  We examined allocators
available via all three routes. We excluded
allocators aimed at debugging e.g.~\memalloc{ElectricFence}).
We then ran a simple validation test, \fnc{malloc}ing a block of memory,
copying data into the block, and then \fnc{free}ing the block: we
excluded any allocator which failed this test. We
document by which route we obtained all of the allocators we consider.

On that basis, the allocators we consider in this paper, and the names we use
for them for the rest of this paper, are as follows:
\begin{itemize}
\item \memalloc{jemalloc}, a modified version of the well-known
    \emph{jemalloc}~\cite{evans06scalable} allocator, which is the default allocator
    for CheriBSD.

\item \memalloc{libmalloc-simple}\footnoteurl{https://github.com/CTSRD-CHERI/cheribsd/commit/e85ccde6d78d40f130ebf126a001589d75d60473}{23rd
    February 2023} is a port of the allocator present in FreeBSD's
    \texttt{rtld-elf} utility\footnoteurl{https://github.com/freebsd/freebsd-src/blob/releng/4.3/libexec/rtld-elf/malloc.c}{
    23rd of February 2023}, based on Kingsley's malloc from 4.2BSD.

\item \memalloc{snmalloc-cheribuild} is an old version of
    \emph{snmalloc}~\cite{lietar19snmalloc} that can be installed via
    \texttt{cheribuild}. We found this version to have several problems
    which we rectified by manually building a version from \emph{snmalloc}'s
    GitHub repository, which includes the \texttt{cheribuild} version, but has
    more recent updates. We term this more recent version \texttt{snmalloc-repo}.

\item \memalloc{dlmalloc-cheribuild} is a version of the well-known
    \emph{dlmalloc} allocator~\cite{lea96memory} modified for CHERI,
    installable via \texttt{cheribuild}. \memalloc{dlmalloc-pkg64c} is an unmodified version  of the allocator, available as a package in CheriBSD. The
    ported version in \texttt{cheribuild} is based on the same as those in the
    packages, namely 2.8.6.

\item \memalloc{ptmalloc}~\cite{gloger06ptmalloc} is an extension of
    \memalloc{dlmalloc}, with added support for multiple threads. A
    non-modified package of \memalloc{ptmalloc3} version 1.8 is available in
    the package manager of CheriBSD.

\item \memalloc{bump-alloc-nocheri} is the simple, non-CHERI-aware bump
    allocator from~\autoref{lst:bump_alloc1}. Conversely, the CHERI aware version is
    \memalloc{bump-alloc-cheri},  presented
    in~\autoref{lst:bump_alloc2}.
\end{itemize}

\begin{table}[tb]
\begin{center}
\begin{tabular}{llrrr}
\toprule
Allocator & Version & SLoC & \multicolumn{2}{c}{Changed}\\
\cmidrule(lr){4-5}
  &   &   & LoC & \multicolumn{1}{c}{\%}\\
\midrule
\input{./data/results/slocs.tex}
\\ \bottomrule
\end{tabular}
\end{center}
  \caption{The allocators we examined, their size in Source Lines of Code
  (SLoC), and the number of lines changed (as an absolute value and relative
  percentage) to adapt them for pure capability CheriBSD.}
\label{tab:allocator_summary}
\end{table}

\autoref{tab:allocator_summary} shows the version of each allocator we used.
We are aware of at least two other major memory allocators that have been
partly ported to CHERI: the \emph{Boehm-Demers-Weiser} conservative garbage
collector; and the \emph{WebKit} garbage collector. Since neither port is yet
complete, we have not included them in this paper.


\subsection{How Much Have the Allocators Been Adapted for CHERI?}
\label{sec:rqs}

As we saw from \autoref{lst:bump_alloc1}, simple allocators don't need to be
adapted for CHERI, though they then derive only minor security gains. In
practice, we expect most allocators to incorporate the capability bounds enforcement
of \autoref{lst:bump_alloc2}. Indeed, more sophisticated allocators will tend
to crash without at least some modifications, when ported to CHERI. Most of the allocators available
via CheriBSD package installer (e.g.~dlmalloc) have had no source-level
changes for CHERI, so while they compile correctly, we found they crashed
almost immediately upon use.

Understanding the details of the CHERI modifications to all of the allocators under
consideration is beyond the scope of this work.
Instead, \autoref{tab:allocator_summary} shows what proportion of an
allocator's LoC are `CHERI specific' by calculating the percentage of lines of code contained between
\texttt{\#ifdef CHERI} blocks and similarly guarded code. This count is an under-approximation, as some
code outside such \texttt{\#ifdef} blocks may also have been adapted, but it
gives a rough idea of the extent of changes. This analysis was performed by a simple preprocessor-style script.

With the exception of the extremely small
\texttt{bump-alloc} and \texttt{libmalloc-simple},
the pure capability memory manager libraries in Table~\ref{tab:allocator_summary} have a mean
1.7\% of their SLoC changed.
Although this is a relatively small portion,
it is two orders of magnitude larger than the
0.026\% lines that were adapted when porting a desktop environment (including X11 and
KDE)~\cite{watson21assessing}. It is a reasonable assumption that the
lower-level, and more platform dependent, nature of allocators
requires more LoC to be adapted.



\section{The Attacks}
\label{sec:atks}

\begin{table}[t]
\begin{center}
\begin{tabular}{lccccc}
\toprule
Allocator & \tblescunauthentic & \tblescperms & \tblnarrowwidencapleak & \tbloverlap & \tblundef\\
\midrule
\input{./data/results/tests.tex}
\\ \bottomrule
\end{tabular}
\caption{Attacks which succeed on a given allocator are marked with a $\times$, while unsuccessful attacks are marked with a $\checkmark$; attack executions which fail due to other reasons (e.g., segmentation faults) are marked with $\oslash$.}
\label{tab:atks}
\end{center}
\end{table}

In this section we introduce a number of `attacks' on CHERI allocators (3
temporal and 1 spatial) and then run those attacks on the allocators from
\autoref{sec:cheriallocators}, with the results shown in \autoref{tab:atks}.
Only snmalloc is immune to all the attacks; even the default CheriBSD allocator
jemalloc is vulnerable to several of the attacks.

In the rest of this section we explain each attack, giving C code using the
CHERI API. Our code examples assume that we start with a `non-attacker' who
allocates memory and hands it over to another part of the system which has been
taken over by an `attacker'. We model this via a series of \lstinline{assert}s:
if all the \lstinline{assert}s pass, the attack is successful. The code we show
in the paper is elided relative to the version we run, which contains changes
that makes it possible for us to automate the running of the attacks over
multiple allocators. For each (allocator, attack) pair, we state whether it is
vulnerable, invulnerable, or whether the attack fails for other reasons. The
full code (available on GitHub) must be considered the definitive source of
truth for \autoref{sec:cheriallocators}.

In the rest of this section we make use of the following CHERI functions:

\setlength{\leftskip}{6pt}

\vspace{6pt}
\noindent\texttt{void *cheri\_address\_set(void *c, \\vaddr\_t a)}~~~~
Takes a capability \texttt{c} as input and produces a new capability
that is a copy of \texttt{c} except with the address \texttt{a}.
\texttt{vaddr\_t} is a CHERI C integer type that is guaranteed to be big enough
to represent addresses but, unlike \texttt{intptr\_t} is not big enough to
represent capabilities.

\vspace{6pt}
\noindent\texttt{void *cheri\_bounds\_set(void *c, \\size\_t s)}
Takes a capability \texttt{c} as input and produces a new capability
that is a copy of \texttt{c} except with bounds of size \texttt{s}.

\vspace{6pt}
\noindent\texttt{size\_t cheri\_length\_get(void *c)}
Returns the bounds of a capability \texttt{c}.

\vspace{6pt}
\noindent\texttt{\_Bool cheri\_tag\_get(void *c)}
Returns true if the capability \texttt{c} is authentic or false otherwise.

\vspace{6pt}
\noindent\texttt{void* cheri\_perms\_and(void *c,\\ size\_t perms)}
Return the capability \texttt{c} with its permissions bitwise-ANDed
with \texttt{perms}.

\vspace{6pt}
\noindent\texttt{size\_t cheri\_perms\_get(void *c)}
Return the permissions of capability \texttt{c}.

\setlength{\leftskip}{0pt}


\subsection{\narrowwiden: Narrowing then Widening Can Allow Access to Hidden Data}
\label{narrowwiden}

In the simple bump allocator of \autoref{lst:bump_alloc1}, \texttt{realloc} always
allocates a new block of memory. While this is always correct, it is inefficient,
in part because it requires copying part of the block's existing content.
Most allocators thus try to avoid allocating a new block of memory if: the
new size is the same as, or smaller than, the existing size; or if
the new size would not lead to the block overwriting its nearest neighbour.
The latter optimisation is dangerous for a CHERI allocator.

Consider the case where \texttt{realloc} wants to increase a
block in size, and there is sufficient room to do so without moving the block.
\texttt{realloc} needs to return a capability whose bounds encompass the new
(larger) size. However, such a capability cannot be derived from the input
capability, as doing so would lead to an inauthentic capability, and
we would violate the property that a capability's abilities must monotonically
decrease. Thus, the allocator needs access to a `super'
capability which it can use to derive a capability representing the new bounds.
Let us call the `super' capability \texttt{SC} and introduce a function
\texttt{size\_of\_bucket} which tells us the maximum space available for
the block starting at \texttt{ptr}. Eliding extraneous details (e.g.~about
alignment), \fnc{realloc} will then look as follows:

\begin{lstlisting}[language=C]
void *realloc(void *ptr, size_t size) {
  if (size_of_bucket(ptr) <= size) {
    // No need to reallocate.
    void *new_ptr =
      cheri_address_set(SC, ptr),
    return cheri_bounds_set(
      new_ptr, size);
  } else {
    // Allocate a larger region of memory
    // and copy the old contents.
  }
}
\end{lstlisting}

\noindent Lines 4--7 need to deal with the
case where the block is to be increased in size but will still fit
in its current bucket. We
first use \fnc{cheri\_address\_set} to derive a new capability from
\texttt{SC} whose address is the same as \texttt{ptr} but whose bounds will be
those of \texttt{SC} (lines 5 and 6) before narrowing those bounds to
\texttt{size} (lines 6 and 7).

When implemented in this style, an allocator can be subject to a trivial
attack we call \narrowwiden:

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(256);
for (uint8_t i = 0; i < 256; i++)
  arr[i] = i;
arr = realloc(arr, 1);
arr = realloc(arr, 256);
for (uint8_t i = 0; i < 256; i++)
  assert(arr[i] == i);
\end{lstlisting}

This attack first \fnc{malloc}s a block of memory, receiving a capability with
a bounds of 256 bytes (line 1). We fill the block of memory up with data so
that we can later test the success of the attack (lines 2 and 3). We then
\fnc{realloc} the block down to a single byte, receiving back a capability
whose bounds are 1 byte\footnote{Some allocators return bigger bounds, but
we ignore that possibility for now.} (line 5).
At this point, we expect to have permanently lost access to the values written to bytes 2-256 (inc.)
\andrei{if we start at byte 2, we imply we have access to only byte 1, and byte 0 doesn't exist. So this could either be 1-255 or 2-256, not 2-255 I don't think}
in lines 2 and 3. If we then \fnc{realloc} the block back to
its original size we should not have access to the values written to bytes
2-256 (inc.). However, allocators using the optimisation above will often
return a capability that covers the same portion of memory as the original
block, without zeroing it, allowing us to read the original bytes out
unchanged.

It might seem merely undesirable for \fnc{realloc} to allow us access to the
original data, but in a capability system this attack is particularly
egregious, as it may allow us to read capabilities that a programmer thought
they were hiding from us. In other words, allocators subject to this attack
can give an attacker access to capabilities, which in turn may give them new abilities,
undermining the security of the entire software.

Mitigating this attack is relatively simple. When \fnc{realloc} shrinks a
block, any excess storage should be zeroed. Note that we consider this safer
than the seemingly similar alternative of zeroing excess storage when
\fnc{realloc} enlarges a block, because this implies a delay in zeroing that
might allow other attacks to read data unexpectedly.


\subsection{\escperms: Escalate Permissions}

In situations where an allocator uses a `super' capability (as seen in
e.g.~\autoref{narrowwiden}), there is also the potential to upgrade a
capabilities permissions as shown in the following simple attack:

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(16);
assert(cheri_perms_get(arr)
  & CHERI_PERM_STORE));
arr = cheri_perms_and(arr, 0);
assert((cheri_perms_get(arr)
  & CHERI_PERM_STORE) == 0);
arr = realloc(arr, 16);
assert(cheri_perms_get(arr)
  & CHERI_PERM_STORE);
\end{lstlisting}

We first allocate a block (line 1) and then check that the capability returned
allows us to store data (\texttt{CHERI\_PERM\-\_STORE}) to that block (lines 2
and 3). We then deliberately remove the store permission (line 4), checking
that this permission really has been removed (lines 5 and 6). We then call
\fnc{realloc} without changing the block's size and check whether we have
regained the ability to store data via the capability.


\subsubsection{Mitigations}

There are two ways of mitigating such an attack. The simplest one is to AND
the output capability's permissions with the input capability's permissions:
doing so guarantees that the output capability has no more permissions
than the input capability.

However, in some cases, one should consider validating the input capability to
decide whether any action should be possible. For example, if handed a
capability whose address is genuinely an allocated block, but where the
capability has the read and write permissions unset, should \fnc{realloc}
refuse to reallocate the block? Perhaps \fnc{realloc} should check that
the capability handed to it has exactly the same permissions as the
capability handed out by the most recent \fnc{malloc} or \fnc{realloc}?
There are probably no universal answers to all possibilities, but some may be
easier to rule upon than others.


\subsection{\escinauthentic: Escalate Inauthentic Capabilities}

An important variant on \escperms is to see whether an allocator will
reallocate a block pointed to by an inauthentic capability and return
an authentic capability:

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(16);
assert(cheri_tag_get(arr));
arr = cheri_tag_clear(arr);
assert(!cheri_tag_get(arr));
arr = realloc(arr, 16);
assert(cheri_tag_get(arr));
\end{lstlisting}

Interestingly, none of the allocators we examined was vulnerable to this
attack.


\subsection{\myundef: Authentic capabilities from Undefined Behaviour}

It is easy to assume that authentic capabilities can only be derived if one
follows CHERI-C's rules correctly. However, it is possible for an attacker to use undefined
behaviour to trick an allocator into returning authentic capabilities
that it should not possess as shown in this attack:

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(256);
for (uint8_t i = 0; i < 256; i++)
  arr[i] = i;
arr = realloc(arr, 1);
free(arr);
arr = malloc(256);
for (uint8_t i = 0; i < 256; i++)
  assert(arr[i] == i);
\end{lstlisting}

This follows a similar pattern to \narrowwiden. We first allocate a block
and fill it with data (lines 1--3). Although not strictly necessary to demonstrate
the attack, we then reallocate the block down to a single byte, modelling the
case where we pass a capability with few abilities to an attacker (line 4). The
attacker then frees that block (line 5) and immediately allocates a block of the same
size (line 6) hoping that the new block is allocated in the same place as the old
block. If that is the case, they will obtain a capability spanning the same memory as the old block,
which allows them access to secret data (lines 7 and 8).

Interestingly, this attack places both the `non-attack' and `attack' portions
into undefined behaviour. Most obviously, the attack portion of the code reads
data via a capability/pointer that it cannot ensure has been initialised. Less
obviously, both attacker and non-attacker have an equivalent capability (with
the same address and bounds) but, due to capability/pointer provenance rules,
the non-attackers version of the capability is, technically speaking, no
longer valid by those rules. This outcome is unlikely to trouble an attacker
who now has a capability \emph{C3} giving the same access as \emph{C1}.


\subsubsection{Mitigations}

There are no general mitigations for \myundef. For the particular concrete
example, a partial mitigation is for \fnc{free} to scrub memory so that, at
least, whatever was present in the buffer cannot be read by the attacker: however,
since the attack has in effect `aliased' the capability, future writes can be
observed and tampered with by the attacker.

A more complete mitigation for the concrete example is for \fnc{free} to
revoke all references to the capability. In other words, CHERI allows\andrei{could allow?} one to
scan memory looking for all capabilities with bounds encompassing an address
$p$ and render them inauthentic~\cite{xia29cherivoke}. In our case, this
would cause the non-attack code to fail with a \texttt{SIGPROT} exception when it
tried to dereference \emph{C1}, downgrading the security leak into a
denial-of-service. However, it is not currently possible to perform capability
revocation at speeds that most allocators would find acceptable.


\subsection{\overlap: Capabilities Whose Bounds Memory Overlap with Another's}
\label{sec:overlap}

A capability's bounds span a portion of memory from a low to a high address. If
an allocator returns two distinct capabilities whose bounds overlap
(e.g.~because of the bounds imprecision we saw in
\autoref{sec:adapting_to_cheri} as a result of
\cite{woodruff19chericoncentrate}), an attacker might be able to read or write
memory they should not have access to.

An example attack in this mould is:

\begin{lstlisting}[language=C]
void *b1 = malloc(16);
void *b2 = malloc(16);
assert(
  cheri_base_get(b1) >= cheri_base_get(b2)
  && cheri_base_get(b1) <
    cheri_base_get(b2) + cheri_length_get(b2)
);
\end{lstlisting}

In practise, such a simple attack is unlikely to succeed on all but the
most basic allocators, as the most likely attack vector is when an allocator
fails to take into account bounds imprecision. The `full' \overlap
attack first finds the first 512 lengths that are not precisely representable
as bounds and randomly allocates multiple blocks to see if any of the
resulting capabilities overlap.


\subsection{Failed Attacks}

Several attacks in~\autoref{tab:atks} failed ($\oslash$) in a manner that means
we cannot state whether the allocator is vulnerable or invulnerable. In
this subsection we explain each such failure.

\escperms fails on \memalloc{bump-alloc-nocheri} because its \fnc{realloc}
causes a \lstinline{SIGPROT} when trying to increase a block in size. By
design, \memalloc{bump-alloc-cheri} contains a version of \fnc{realloc} which
fixes this issue. See~\autoref{sec:adapting_to_cheri} for more details.

\overlap fails on \memalloc{snmalloc-cheribuild} due to what appears to be
an internal snmalloc bug. Because of this, we included a newer version
of snmalloc as \memalloc{snmalloc-repo} which is invulnerable to \overlap.

In the case of \escinauthentic, several allocators fall into something of a
grey zone: the allocators cause a \lstinline{SIGPROT} when they try to perform
an operation on the inauthentic capability. In none of theses cases does the
allocator check the capability's authenticity, and it is an open question as to
whether anyone involved in porting the allocator to CHERI explicitly realised
that they would \lstinline{SIGPROT} with an inauthentic capability. However, we
prefer to give the allocators the benefit of doubt, and have classified them as
invulnerable to this attack.


\section{Performance Evaluation}
\label{sec:performance}

We wanted to understand the performance impact of porting allocators to CHERI.
Our intention was to run both hybrid and purecap versions of each allocator
and compare the results. However, while we expected to see differences
in performance, we were shocked to observe differences of as much as 2x
or more in wall-clock time. As far as we know, we are the first to write
publicly about such a comparison, and thus there is no obvious precedent to
draw upon. Although we do not have complete explanations for these differences,
we have found several possible causes.

However, not all is lost. While performance comparisons \emph{across} hybrid and
pure capability CHERI are hard to believe, performance comparisons \emph{within}
hybrid or pure capability CHERI do appear to be meaningful.

In this section we thus first detail a fairly traditional performance evaluation
comparing performance amongst purecap CHERI allocators, before showing that
performance across hybrid and purecap allocators is surprisingly different.
We look for, but fail to find, obvious explanations for why allocator
performance across hybrid and purecap varies so much. In~\autoref{sec:dissection} we
attempt a more detailed, and generic, analysis of factors that might explain
such differences.


\subsection{Methodology}

\begin{table}[t]
  \begin{center}
    \begin{tabular}{lll}
      \toprule
      Benchmark & Source & Characterisation \\
      \midrule
      barnes & mimalloc & Floating-point compute \\
      binary-tree & boehm & Alloc \& pointer indirection \\
      cfrac & mimalloc & Alloc \& int compute \\
      espresso & mimalloc & Alloc \& int compute \\
      glibc-simple & mimalloc & Alloc \\
      %glibc-thread & mimalloc & alloc, multi-thread \\
      mstress & mimalloc & Alloc \\
      richards & richards & Pointer indirection \\
      %rptest & mimalloc & \dejice{alloc, multi-thread} \\
      %xmalloc & mimalloc & alloc, multi-thread \\ \hline
      \bottomrule
    \end{tabular}
  \end{center}
  \caption{Our benchmark suite. We list the benchmark name, the source
  of the benchmark, and a brief characterisation of it as a workload.
  \emph{Alloc} is short-hand for `allocator intensive' (i.e.~frequent
  allocation and deallocation).}
\label{tab:benchmarks}
\end{table}

\begin{figure*}[t]
  \begin{center}
    \includegraphics[width=\textwidth]{fig/sn_je_malloc_bm_overall.pdf}
    \vspace{-25pt}
  \end{center}
  \caption{\label{fig:eval jemalloc}
  \memalloc{jemalloc} (top) and \memalloc{snmalloc} (bottom) running on purecap, normalised
  to their respective hybrid allocators. For example, barnes's wall-clock
  execution time \emph{total-time} on purecap is 1.22x greater than
  on hybrid. To understand why purecap is slower than we expected, we recorded
  several performance counters: \emph{rss-kb} is \laurie{total? average?
  maximum?} memory utilisation; \emph{INST\_RETIRED} the number of instructions
  retired while executing the benchmark; and \emph{\{L1I, L1D, L2D\}\_CACHE}
  the L1 instruction, L1 data, and L2 data, cache accesses respectively.
  None of these factors provides obvious clues as to why purecap is so
  much slower than hybrid.}
\end{figure*}

Our experiments are conducted on Arm's prototype Morello hardware:
a quad-core, modified Armv8-A 2.5GHz processor; with a 64KiB L1 data cache and
64KiB L1 instruction cache; a 1MiB L2 unified cache; two 1MiB L3 unified
caches, each shared between a pair of cores; and 16GiB DDR4 RAM. We ran
CheriBSD 22.12 as the OS, with both purecap (in \texttt{/usr/lib/}) and
hybrid (in \texttt{/usr/lib64/}) userlands installed.

We wanted a benchmark suite that contains benchmarks written in C, that have
minimal library dependencies (so that we best understand what is being run),
and that execute fixed workloads (rather than those that execute for fixed
time). We selected 5 benchmarks from \emph{mimalloc-bench}
suite~\cite{leijen19mimalloc} that meet this criteria, as well as the `classic'
binarytrees~\cite{boehm14artificial} and richards~\cite{richards99bench}
benchmarks. \autoref{tab:benchmarks} shows our complete benchmark suite.
Our benchmark suite deliberately contains a mix of allocation-heavy benchmarks
and non-allocation-heavy benchmarks, where the latter can serve as a
partial `control' to help us understand the effects of allocators on
performance against other factors.

We compile each benchmark with clang's \texttt{-O3} optimisation level. We
use \texttt{LD\_PRELOAD} at runtime to dynamically switch between allocators.
We measure wall-clock time on an otherwise unloaded Morello machine.


\subsection{Results Within Hybrid and Purecap}
\label{ssec:withinhybridpurecap}
%Figure FIXME presents results for this experiment, showing that 
%\jeremy{the majority of allocators are significantly slower than jemalloc (presumably because they are less optimized)}. 
Benchmarks compiled with snmalloc saw a geometric mean speed-up of 1.24 times compared to the system default jemalloc
in both \emph{hybrid} and \emph{purecap}. This can be attributed to benchmarks linking against
jemalloc on average executing 1.42x the number of instructions compared to snmalloc. 
Benchmarks linked against the \emph{hybrid} versions of snmalloc and jemalloc exhibit 
a similar trend with the mean instructions retired by jemalloc 1.15x times snmalloc. 

\subsection{Results Across Hybrid and Purecap}

\autoref{fig:eval jemalloc} shows a comparison of \memalloc{jemalloc} and \memalloc{snmalloc} in hybrid
and purecap. As expected, purecap is always slower than hybrid in total
execution time, and there is significant variance amongst benchmarks.
However, using the geometric mean, both jemalloc and snmalloc \emph{purecap}
are 1.59x slower than \emph{hybrid}, which is a much greater figure than we expected. That
richards, a benchmark which performs little allocation, is over 2x slower
strongly suggests that such slowdowns are not related to allocators.

To understand if there are simple explanations for the slowdown -- perhaps
that capabilities were placing huge pressure on caches -- we measured
a number of performance counters, which are also shown in \autoref{fig:eval jemalloc}.
While, again, there is variance amongst benchmarks, the performance
counters do not allow us to identify a single cause.
\laurie{do we have upto date correlation graphs? if not, can we at least give
the reader some sense of what they tell us?}

\begin{figure}
  \begin{center}
    \includegraphics[width=1.2\columnwidth]{fig/instruction_mix/stacked_bar_chart.pdf}
    \vspace{-30pt}
  \end{center}
  \caption{\label{fig:instrmix}
  Dynamic instruction mix for purecap (left-hand bar) and hybrid (right-hand bar) benchmark runs.
  Most of these are as expected. For example, branches are the same in hybrid
  and purecap; some pointer arithmetic (a subset of `data proc' in hybrid)
  moves from AArch64 to Morello (`morello arith'). Similarly, some loads
  and stores move from AArch64 to Morello. There is a small but noticeable
  increase in the overall quantity of loads and stores (AArch64 and Morello
  combined). The `Morello misc' category captures instructions related to
  capability bounds, tag checks, and so on that we would only expect to see in
  any quantity in purecap.}
\end{figure}

We then wondered whether the higher instruction counts on purecap benchmarks
was due to necessary extra instructions in purecap allocators
(thinking back to Listings~\ref{lst:bump_alloc1} and~\ref{lst:bump_alloc2})
or whether it might be due to other factors. To understand this, we wanted
to count how often different classes of instructions were executed.
Unfortunately, there is currently no direct way on either CheriBSD or Morello
to obtain such a count, so we had to cobble together two approaches: a fast,
but potentially imprecise, approach based on QEMU; and a slow, but much more
precise, approach based on Arm's Morello Platform FVP~\cite[p.~23]{morellofvp}
used as a sanity check for our QEMU results.

We wrote a custom QEMU plugin that maintains counts for each class of
instructions as a Morello instance is running. This includes the kernel booting
and shutting down as well as the benchmark we are interested in. We repeatedly
ran CheriBSD without any meaningful workload, so that we could find the
instruction counts that together constitute the `head' and `tail' of execution.
When we ran a benchmark, we then subtracted the head/tail instruction counts to
obtain the `benchmark only' instruction counts.

To validate these results, we used the Morello Platform FVP, which can emit ``tarmac''
traces~\cite[p.~5452]{fvpguide} representing complete records of execution. We
altered the FVP so that when we executed an otherwise unused instruction, it
toggled tracing on and off. We executed a complete run of the binary\_tree
benchmark, examined the traces, and counted the instructions contained therein,
which were a close match to our QEMU instruction counts. This gives us confidence
that our QEMU figures are representative.

Since our QEMU approach only has to track a few integers, whereas FVP produces
tarmac traces that are often a TiB long for our workloads, our two approaches
differ in performance by about 3 orders of magnitude. Running our full
benchmark suite for its full duration would be infeasible in FVP, so the
results we show in~\autoref{fig:instrmix} result from our QEMU approach.
As the figure shows, the instruction mixes look largely sensible: some
aspects (e.g.~branches) are identical in hybrid and purecap; some
vary where capabilities are sometimes used (e.g.~loads and stores);
and purecap uses Morello instructions. Overall, while there are one or
two minor oddities (e.g.~mstress uses Neon instructions -- classified as
floating point -- on hybrid but not purecap), there are no obvious smoking
guns.


\section{Analysing The Disparity Between Hybrid and Purecap Performance}
\label{sec:dissection}

Hybrid and purecap CHERI imply a number differences which we would expect to
account for at least some of the performance differences we see. In this
section we analyse several factors in detail. Those factors, and the names
we give them are as follows:

\newcommand\fhardware{F$_{\textrm{Hardware}}$}
\newcommand\fabi{F$_{\textrm{ABI}}$}
\newcommand\fcompiler{F$_{\textrm{Toolchain}}$}
\newcommand\fuser{F$_{\textrm{User}}$}

\vspace{6pt}\noindent\textbf{\fhardware}
At the hardware level, pointer operations (including arithmetic, loads, and
stores) have different semantics for capabilities, which is likely to lead to
different performance characteristics relative to operations on normal
pointers. Similarly, since capabilities are double word width, we would expect
them to put greater pressure on caches and other system resources relative to
single word width addresses.

\vspace{6pt}\noindent\textbf{\fabi}
At the ABI level, the purecap CheriBSD ABI is different than the hybrid ABI
(where the latter is largely the same as a non-CHERI ABI): the effects of this
at the software level, or its impact on compiler optimisations are unclear.

\vspace{6pt}\noindent\textbf{\fcompiler}
At the compiler level, both hybrid and purecap modes require altered versions
of LLVM. Neither is as mature as ``mainstream'' LLVM, and thus are unlikely to
optimise code as fully as expected. This may have many subtle effects. Although
the purecap LLVM has received more attention than the hybrid LLVM, it is also
more different from ``mainstream'' LLVM, so it is possible that the purecap
LLVM will produce less optimal code than the hybrid LLVM.

\vspace{6pt}\noindent\textbf{\fuser}
At the user level, code that wants to take advantage of CHERI will tend to use
different execution paths when compiled for purecap, as we saw in the bump
allocator of~\autoref{lst:bump_alloc1}.


\subsection{Analysis Techniques}

We used the Morello Platform FVP, which can emit "tarmac"
    trace\cite[p.~23]{morellofvp}\cite[p.~5452]{fvpguide} describing instructions
    executed. Tarmac trace includes virtual addresses, and combined with a
    record of each process's memory map, we can map instructions to individual
    functions (using ELF analysis). This technique excludes kernel activity
    because the exeception level is included in the trace, but includes
    (negligible) noise from other processes running on the system. The major
    disadvantage of this technique is that it requires a lot of storage, and is
    very slow, so we have applied it only to selected workloads. We also used
    this technique to verify a sample of QEMU measurements.


\subsection{\fhardware: Hardware pointer operation (microbenchmarks)}

To understand the impact of low-level Morello hardware performance, we wrote a
series of simple microbenchmarks that we can run under both hybrid and purecap
CheriBSD. Most are written in C (with annotations to minimise compiler
variance), but many include, or are primarily written in, assembly. Our aim
with these microbenchmarks is not to indicate real-world performance, but to
help us better understand larger benchmarks.

\vspace{6pt}\noindent
\texttt{00-factorial-asm-minimal} is a tail-recursive integer factorial
    implementation that, despite not using capabilities in the loop, shows an
    unusual bimodality in hybrid but a wide, and fairly even spread, in
    purecap. We have no obvious explanation for this, so we assume it
    is a microarchitectural artefact.

\vspace{6pt}\noindent
\texttt{01-factorial-asm-indirect} is similar, but uses an indirect
    tail call (using Morello's \texttt{br} instruction). The purecap target
    tail-calls a capability whilst the hybrid target tail-calls a plain
    address. This shows there is a consistent overhead of just under
    10\% in branching via a capability.

\vspace{6pt}\noindent
\texttt{10-random-graph-walk-l1} performs a random walk through a
    graph that fits in Morello's 64KiB L1 data cache. This
    suggests that there is no inherent overhead in reading from a capability.

\vspace{6pt}\noindent
\texttt{11-random-graph-walk-fixed} is similar, but uses a larger, constant,
    number of nodes. That set consumes 1MiB in hybrid and (due to capabilities
    double word width) 2MiB in purecap. Despite this, there is little
    performance difference between hybrid and purecap.

\vspace{6pt}\noindent
\texttt{20-so-call} measures the PLT overhead by having a simple loop
    call an empty function in another shared object. This operation
    is significantly slower in purecap.

\vspace{6pt}\noindent
\texttt{30-ptr-add-asm} measures pointer addition, a common operation.
    Although capability addition is more complex (due to bounds checking),
    it has a dedicated instruction, which probably explains why
    there is no meaningful performance difference between hybrid and purecap.

\vspace{6pt}\noindent
\texttt{31-ptr-add-align} performs pointer addition followed by an
    align-down operation, a common operation in allocators. The capability
    variant has a dedicated instruction for this, while the hybrid version
    is a bitwise operation. Despite this, the purecap version is much slower
    than the hybrid version.

\vspace{6pt}\noindent
\texttt{99-busy-loop} is an empty C loop, to act as a control. The C
    loop uses no capabilities, and compiles to identical code for hybrid and
    purecap targets. Hybrid and purecap have the same performance.


\begin{figure}
  \begin{center}
    \includegraphics[width=1.2\columnwidth]{fig/microbenchmarks.pdf}
    \vspace{-30pt}
  \end{center}
  \caption{\label{fig:mbench}
  Microbenchmark performance results, with purecap normalised to median hybrid
  performance (slower to the left, faster to the right). This shows that many
  operations have similar performance on hybrid and purecap but some, such as
  calling a function in a shared object, are significantly slower on purecap. }
\end{figure}


\subsection{Cache pressure}

\jacob{Include and describe PMU results.}

\subsection{\fabi: Purecap ABI difficulties}
\label{ssec:purecap ABI difficulties}

We have observed some toolchain behaviours that differ between hybrid and
purecap. For example, this is a store (of zero) to a global variable in Morello
hybrid:

\begin{lstlisting}
    adrp x8, #+0x20000
    str xzr, [x8, #2472]
\end{lstlisting}

In that case, the \texttt{adrp} combined with the \texttt{str} offset locate
the global, and the store can write to it directly. However, the purecap ABI
requires another level of indirection in order to obtain a capability with
tight bounds:

\begin{lstlisting}
    adrp c1, #+0x10000
    ldr c1, [c1, #3776]
    str xzr, [c1]
\end{lstlisting}

Behaviours of this sort may be required (or at least be beneficial) under the
purecap security model, and may therefore be difficult to optimise. We have
completed neither security nor performance analysis for most benchmarks.
For example, FVP trace analysis\jacob{TODO: Link to method} indicates that
global variable accesses appear to be a major difference between hybrid and
purecap compilations of hot functions in the richards benchmark. However, in
the absence of profiling tools, it is unclear how much of the performance
discrepancy they are responsible for.


\subsection{\fcompiler Toolchain maturity}

We noticed that the same code compiled for hybrid and purecap by LLVM could
sometimes lead to much longer/shorter machine code. The differences are
far too extensive to admit a simple analysis, but we hypothesise that
they might be due to capability code either: preventing LLVM from performing
some of its normal optimisations when capability code is present; or LLVM
simply not having been taught how to optimise capability code. Two small examples
demonstrate the overall point.

In hybrid code, zeroing memory is compiled to a single instruction:

\begin{lstlisting}
stp     xzr, xzr, [x0]
\end{lstlisting}

\noindent whereas in purecap it is compiled to two instructions:

\begin{lstlisting}
movi    v0.2d, #0000000000000000
stp     q0, q0, [c0]
\end{lstlisting}

\noindent The purecap version could have used a single instructions
with the \texttt{czr} register. This may or may not improve performance,
but serves as an example of how quickly minor code generation differences
can make it difficult for humans to comprehend differences between
hybrid and purecap code generation.

Another example we found relevant to allocators is found in a hot path
within jemallocs \fnc{malloc} function, where a byte-sized thread-local
is loaded from memory. In hybrid this is compiled to:

\begin{lstlisting}
ldr     x2, [...]
mrs     x1, TPIDR_EL0
ldrb    w0, [x2, x1]
\end{lstlisting}

In purecap this is compiled to a load and a bounds restriction:

\begin{lstlisting}
ldp     x2, x3, [...]
mrs     c1, CTPIDR_EL0
add     c2, c1, x2
scbnds  c2, c2, x3
ldrb    w0, [c2]
\end{lstlisting}

These additional instructions will almost certainly have a measurable impact
on performance, but do not appear to have any security benefit:
the \texttt{c2} register is not indexed by a variable, and a greater capability is
already available in \texttt{c1}. It seems likely that this is a missed
optimisation opportunity by the compiler rather than a deliberate security restriction.


\subsection{\fuser: Security behaviours}

\jacob{TODO: All the scbnds instructions. These are important for security.}



\section{Conclusions}

CHERI holds great promise for securing software in general: allocators are a
key part of that story. In this paper we have shown that many CHERI allocators,
including the current CheriBSD default allocator, suffer from simple security
vulnerabilities. We also showed how difficult it currently it is to understand
the performance impact of running software on CHERI.

Despite all of this, one allocator has shone throughout this paper: snmalloc is
not susceptible to any of our attacks, and is faster than the default CheriBSD
allocator in our benchmarks. We suggest that snmalloc be considered to be the
default CheriBSD allocator going forward.

% \textbf{Acknowledgements:} We thank Ruben Ayrapetyan and David Chisnall for
% comments. This work was funded by the Digital Security by Design (DSbD) Programme
% delivered by UKRI.


\bibliographystyle{plain}
\bibliography{bib}

\end{document}
