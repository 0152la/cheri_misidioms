%&cheri_misidioms_preamble
\endofdump

\begin{document}
\maketitle

\begin{abstract}
Several memory allocators have been ported to CHERI, a hardware capability
platform. We define a number of simple (mostly, but not exclusively, temporal)
vulnerabilities that CHERI memory allocators are potentially vulnerable to.
Since we first made a pre-print of this paper available, some allocators have
fixed some or all vulnerabilities, but many remain vulnerable: our work may
  also prove useful for those working on CHERI memory allocators in the future.
\end{abstract}


\section{Introduction}

Capability Hardware Enhanced RISC Instructions
(CHERI)~\cite{watson20cheriintroduction} provides and enforces hardware
capabilities that allow programmers to make strong security guarantees
about the memory safety properties of their programs. However, capabilities are
not magic. Programmers must first decide which memory safety properties they
wish to enforce and then actually enforce those memory safety properties.
It is easy for mistakes to creep in during either step, undermining
the security guarantees programmers believe their code possesses.

In this paper we examine one of the most fundamental software components:
memory allocators (henceforth just ``allocators''). Apart from some embedded
systems (which preallocate fixed quantities of memory), allocators are
ubiquitous because they allow us to write programs that are generic over a
variety of memory usage patterns. Security flaws in allocators thus tend
to have significant and widespread consequences.

We show that it is surprisingly difficult to make a `secure' allocator for pure
capability CHERI\@. We first show the basic problems with a simple bump-pointer
allocator example (\autoref{sec:bumppointerallocator}). We then
examine~\alloccount{} existing allocators that have been ported to CHERI
(\autoref{sec:cheriallocators}). Finally we introduce and name~\allocbugs{}
simple `attacks' on pure capability memory allocators, showing that most of the
allocators are vulnerable to most of the attacks (\autoref{sec:atk}). Since
we first made a pre-print of this paper available, some allocators have
fixed some or all vulnerabilities, but many remain vulnerable.


\section{Background}

We assume high-level familiarity with capabilities (\cite{levy84capability}
provides an approachable historical overview of capability architectures, and
may usefully be augmented by more recent work such as~\cite{miller06robust}),
CHERI generally (for a useful introduction to CHERI,
see~\cite{watson20cheriintroduction}),
the CHERI ABI~\cite{brooks19cheriabi},
and CHERI C (the dialect of C that CHERI defines)~\cite{watson20chericprogramming}.

Because CHERI has been developed over a number of years, and is explained over
a variety of documentation and papers, some concepts have more than one name.
We have found that some of those names make it difficult to talk, and sometimes
reason about, capability usage.
Unfortunately, we can think of no better solution to this than to propose our
own terminology.

We use the term \textit{CHERI} to refer to the `abstract capability machine'
that software can observe: that is, the combination of a capability hardware
instruction set, an ABI, and a user-facing library that exposes
capability-related functions.  We refer to specific hardware implementations by
their name (e.g.~Arm's `Morello' or `CHERI RISC-V').

CHERI capabilities are immutable and thus a new \emph{child} capability must be
derived from one or more \emph{parent} capabilities.  We refer to a capability
as \emph{authentic} (what CHERI calls `tagged' or `valid') if it has been
derived from its parents according to CHERI's rules, or \emph{inauthentic}
(what CHERI calls `untagged' or `invalid') otherwise. An inauthentic capability
may be duplicated at will but attempting to use an inauthentic capability in
any other way leads to a hardware exception.  A capability consists of an
\emph{address} in memory and a set of \emph{permissions} (only a subset of
which we consider in this paper). Amongst the permissions are \emph{bounds} -- the region of memory an
authentic capability is allowed to read/write from/to. A capability's bounds
are from a \emph{low} (inclusive) to a \emph{high} (exclusive) address and we
refer to `a bound of $x$ bytes' to mean a capability where
$\textit{high}-\textit{low}=x$.  If a capability's address is contained within
its bounds we refer to the capability as a whole as \emph{in-bounds} or
\emph{out-of-bounds} otherwise (see~\cite{woodruff19chericoncentrate} for an
explanation of why an authentic capability might have an out-of-bounds
address). Other permissions include boolean flags such as whether a capability
can read/write to memory addresses within its bounds.

As well as capabilities (which on Morello and CHERI RISC-V, for example, are
128 bits), CHERI also allows `traditional' single-width
pointers-as-addresses (which on Morello and CHERI RISC-V are 64-bit addresses)
to be used. Although CHERI processors allow both double-width capabilities and
single-width addresses-as-pointers to exist alongside each other at any time,
conventionally, a program which uses both traditional addresses and
capabilities is said to be operating in \emph{hybrid} mode while a program
which uses only capabilities is in \emph{pure capability} mode. In this paper
we concentrate exclusively on programs which operate in pure capability mode.


\section{A Basic Allocator for Pure Capability CHERI}
\label{sec:bumppointerallocator}

\laurie{jeremy: why don't we present the absolute most bare bones allocator
(including free and realloc i guess?) that supports purecap. this would bring
to life the coalescing stuff, if nothing else.}

\andrei{Instead of having an example allocator with a bunch of source code, how
about discussing general properties of modern allocators, and potential issues
in a CHERI context. Properties of interest: coalescing (monotonicity of
capabilities), free (need for "supercapability"/revocation), allocator metadata.}

\andrei{In addition, are there any further complications from being in a capability
environment that might affect an allocator, that we can think of?}

\laurie{a concrete example of an allocator + its problems is, imho, vital}

%% general intro text

Since modern memory allocators are critical to software performance, they are
highly optimised --- and, consequently, often difficult to understand in
detail. In this section we explore a trivial allocator \bumpalloc which allows
us to consider the major implementation issues relevant to this paper, in terms
of capabilities.

Some memory management design patterns recur in a wide variety of allocators.
The complexity of capabilities means the incorporation of these patterns must
be scrutinized with capabilities in mind, in order to ensure minimal burden is
placed on developers. Jones et al.\ (cite GC handbook) outline many of these
design patterns from a pragmatic perspective.  In this section, we discuss some
of the issues we have identified and how they might cause potential challenges
in a capability-aware context.

\subsection{Bare-bones Bump Pointer}

\lstinputlisting[language=C, caption={A very basic, but usable, non-capability
bump pointer allocator.},
label=lst:bump_alloc]{listings/bump_alloc1.c}

A very basic version of \bumpalloc is shown in~\autoref{lst:bump_alloc}.  In
this implementation, \fnc{malloc} always returns a new chunk if memory is
available, otherwise it returns \texttt{NULL}, while \texttt{free} is a no-op
and \fnc{realloc} is aliased to \fnc{malloc}.
%% FIXME realloc semantics incorrect!

This code initially reserves a large chunk of memory using a single
\fnc{mmap} call then doles out successive small chunks on \fnc{malloc}
calls. The bump pointer moves through the initially allocated chunk until it
reaches the upper limit at which point the memory is exhausted.


\subsection{Capability Bounds}

When this allocator code is compiled and executed on a capability platform, the
values returned by \fnc{malloc} will share the same capability metadata as the
capability returned by the original \fnc{mmap} call, in particular the
page-granular bounds.  We can tighten the bounds for each \fnc{malloc} return
value by deriving a new capability with updated base and bounds.
% using CHERI intrinsic functions.
% like \texttt{cheri\_address\_set} and \texttt{cheri\_bounds\_set}.

\lstinputlisting[language=C, caption={Bump pointer allocator that returns
bounded capability values to client code.},
label=lst:bump_alloc2]{listings/bump_alloc2.c}

\autoref{lst:bump_alloc2} shows how such derived capabilities can be
calculated. Note there is complex capability value logic required to ensure
the bounds are representable as a compressed capability. We pad to ensure the
malloc buffer is at least as large as it needs to be.

\subsection{Temporal Safety Issues}
From a security perspective, after a successful \fnc{realloc} call,
there still exists in scope a capability pointing to some part of memory (i.e.,
the source \fnc{realloc} address). This small detail might evade the attention
of a software developer working with such a simple allocator implementation,
leading to potential capability leakage, thus undermining the security
guarantees of capabilities.

One method of overcoming temporal issues could be \emph{capability revocation}.
Ideally, we could revoke a capability that has gone ``out of scope'' (perhaps
by invalidating the tag bit), such that any attempt to use that capability
would lead to a trap. However, as there is no record of how capabilities are
used and copied, there is no way of tracking where capabilities that have to be
revoked end up, without fully scanning memory. As this is a fairly expensive
operation, alternative measures need to be found to enhance temporal safety.

\subsection{Memory coalescing}

One important functionality of memory allocators is \emph{memory coalescing}.
As a program operates, deallocating objects leads to there being unused gaps in
memory. In order to maximize memory access performance, via locality and cache
coherence, it is desirable to have memory usage be as dense as possible. Thus,
an allocator would like to move objects in memory to maximize density. However,
after allocation, an object only has access to the initial allocated memory
space. In order for an allocator to move the object, it would need to generate
itself a new capability. This would mean giving the allocator greater
permissions to memory, which could undermine security if the allocator itself
would become the target of an adversary.

\subsection{Richer Metadata}
One advantage of using capabilities instead of traditional pointers
is the additional metadata held within the capability.
For example, we are able to fetch the
size of the original allocation by querying the bounds of the capability
value --- if we assume that the capability bounds map directly onto the
allocated buffer size.
\jeremy{also mention spare bits in object field? Can we use these?}

In many allocators, this size metadata is crucial for ensuring the correct
behaviour of \texttt{free} - which might need to query the size of its
capability argument in order to determine which free list this buffer should
be appended to, or how many words of memory can be marked as unused.

Classical allocators, such as \textit{dlmalloc}, actually store this size
metadata in-line with the pointer - at a fixed offset from the pointer base.
This is a constant space overhead for each allocation. Now with capability
metadata, allocator metadata can be `shared' with capability metadata, so long
as the size matches the bounds.

This assumption could be violated in certain circumstances, for instance:
\begin{itemize}
\item if the allocated buffer size is not properly representable in the
    capability metadata, because of the CHERI compression scheme. The solution
    to this problem is to ensure that all allocatable sizes are representable,
    which might mean padding some allocations to a larger representable size.
\item if the client code (the \fnc{malloc} caller) is able to modify the
    capability metadata, perhaps to reduce the bounds of the capability value.
    The solution is to ensure that only capability values returned directly
    from \fnc{malloc} are allowed to be arguments to free calls. (Indeed, this
    is the standard assumption in existing non-capability C programs.)
\end{itemize}

Sometimes, additional potential metadata (e.g.\ marking colour data) required
by the memory manager (garbage collector) cannot be represented directly as
capability metadata and would need to be accessible via the base capability
value, or in a separate privileged space.  There might be a security problem if
this metadata is accessible (and modifiable) by client code. However if the
capability bounds restrict access to this metadata, then there is a performance
problem since the memory management subsystem somehow needs to upgrade
user-visible capabilities in order to access metadata fields.
\jeremy{Is this what snmalloc does? - Yes, David Chisnall refers to this as
\emph{amplification}}


\paragraph{Elevated permissions}

While perhaps not as specific as the previous two features, a memory allocator
must be able to perform operations at a higher privilege level than that of
normal user code. As capabilities enforce boundaries on what data can be
accessed or executed, it might break the expectation that memory allocation
functions can be called from user code, due to them affecting the overall
system. \jeremy{what does this mean? Can we have an example please?}

\laurie{the rest of this comment is text moved from elsewhere that probably
should end up in this section
```Memory management code needs to be highly efficient, due to the frequency of
its execution. There are abundant memory management design patterns that recur
in a variety of allocators. Jones et al.\ (cite GC handbook) outlines many of
these patterns from an implementation perspective.  Due to the constraints of
CHERI, some of these memory management design patterns no longer work properly.
We review three such problematic patterns in this section.\emph{andrei: Enumerate
these 3, or paragraphs to emphasise which they are?}
Contiguous free buffers in managed memory should be merged to form a larger
buffer. This \emph{coalescing} pattern will fail on CHERI systems when
contiguous buffers have non-overlapping bounds, perhaps since the buffers are
derived from distinct \texttt{mmap} calls. \emph{andrei: Is it also the case that you
can't ``combine'' two capabilities to form a larger one?}
Memory managers often use simple bitwise arithmetic to synthesize addresses
efficiently, e.g.\ for iterating over fixed length buffers.
Such \emph{address synthesis} is not permitted in CHERI, since
valid metadata cannot be synthesized. Instead, calculations must be offset from
a capability with valid bounds. Finding the appropriate capability value is
generally less efficient than synthesizing it.
Some allocators use a \emph{header word} to store metadata for allocated
buffers. The header word is usually located one word before the user-visible
pointer begins. In CHERI, a problem is caused if the metadata word is
out-of-bounds for the user-visible pointer --- in which case the memory manager
needs to retain a separate, more privileged capability to access the metadata.
On the other hand, if the metadata is in-bounds for the user-visible pointer
then the metadata could be modified by user code, so CHERI cannot protect
against metadata corruption.'''}

\section{Existing CHERI Allocators}
\label{sec:cheriallocators}

\laurie{we need to add citations for the allocators where possible}
\andrei{Currently this section talks about porting effort, some assorted
properties, and then security properties. Is this sufficient, or is there
something else?}

We looked at a number of sources in order to find memory allocators ported to
CHERI\@. These are:
\begin{enumerate}
    \item [CheriBSD] We found two allocators provided in CheriBSD itself. One
        of them is identified as \memalloc{libmalloc-simple}, while the other,
        default option for CheriBSD, is a port of \memalloc{jemalloc};
    \item [cheribuild] Among the build targets provided by cheribuild, we
        identified \memalloc{snmalloc}~\cite{snmalloc}, an allocator from
        Microsoft, and \memalloc{dlmalloc}~\cite{dlmalloc}, Doug Lea's malloc
        implementation;
    \item [pkg64c] CheriBSD comes with its own package manager, which for the
        Morello purecap variant of the OS, is known as \texttt{pkg64c}. A
        cursory search for the keyword ``alloc'' found ports for:
        \andrei{cites/links here} \memalloc{dlmalloc},
        \memalloc{ElectricFence}, \memalloc{dmalloc}, \memalloc{ptmalloc}, and
        \memalloc{libxalloc};
    \item [Standalone] We were able to track down standalone, public version of
        allocators ported to CHERI, or as part of libc alternatives. These are
        \memalloc{snmalloc}~\footnoteurl{https://github.com/microsoft/snmalloc, 24 Jan 2023},
        allocators from the
        Huawei~\footnoteurl{https://github.com/cheri-linux/musl, 24 Jan 2023}
        and
        Morello~\footnoteurl{https://git.morello-project.org/morello/musl-libc,
        24 Jan 2023} ports of \texttt{musl}, allocator from the Morello
        \memalloc{newlib}~\footnoteurl{https://git.morello-project.org/morello/newlib,
        24 Jan 2023} port, and finally the toy bump allocator discussed
        in~\autoref{sec:bumppointerallocator}.
\end{enumerate}

That gives us a total of \alloccount{} allocators we have found. These
allocator, along with the particular commit hash (truncated to 10 characters)
or version number used during evaluation, as well as some source data (where
available) can be seen in~\autoref{tab:allocator_summary}. We note that some
allocators, such as \memalloc{snmalloc} have been found from multiple sources;
in tese cases, we distinguish the provenance by appending the source name
(e.g., we identify \memalloc{snmalloc-repo} as the standalone variant, and
\memalloc{snmalloc-cheribuild} as that provided by cheribuild). Unfortunately,
during evaluation we discovered that not all of these allocators were in
working condition.  Particularly, most allocators coming with \texttt{pkg64c}
crashed with a segmentation fault on execution of our tests. \andrei{Hopefully
we can test these shortly} Furthermore, at the moment of writing, we do not
have access to a CHERI Linux system, meaning we are unable to test the
\memalloc{musl} and \memalloc{newlib} ports.

For the source data in~\autoref{tab:allocator_summary}, we provide the total
number of Source Lines of Code (SLoC), as given by the \texttt{cloc} utility,
then the total number of lines of code ``changed'' during porting (which we
define as the number of lines in a CHERI \texttt{ifdef} block), as well as
percentage of total SLoC. We note that for \memalloc{bump-alloc} the number of
changed lines of code is zero, as we wrote the toy allocator with CHERI in
mind.

% In this paper we examine the following memory allocators which have
% been ported to CheriBSD: \textit{jemalloc} (the default allocator on CheriBSD),
% Kingsley's \textit{BSD malloc} (\laurie{say something about it -- I don't even
% know what it is and I'm a fully paid-up member of the BSD cult!}), and the two
% unnamed allocators inside the libc alternatives \textit{newlib} and
% \textit{Musl}. As a baseline we show a trivial \textit{bump-pointer
% allocator} of our own devising.\andrei{Is `snmalloc` not part of this
% experiment? I think they have a decent CHERI port. Also, can I find the
% data/scripts for this experiment somewhere?}

At least two other memory allocators have been partly ported to CHERI: the
conservative garbage collector \textit{Boehm-Demers-Weiser} garbage collector
and the garbage collector inside the JavaScript virtual machine
\textit{JavaScriptCore}. To the best of our knowledge, neither port is
yet complete\andrei{I don't know much about gc's, but could we extract either
some design ideas, or even some functionality to add to our comparison?}.


\subsection{Existing CheriBSD allocators}
\label{sec:rqs}

\input{./data/results/slocs.tex}

%\begin{table}[tb]
  %\begin{center}
    %\begin{tabular}{lllll}
      %\toprule
      %Allocator          & Version & SLoC & \multicolumn{2}{c}{Changed} \\
      %\cmidrule(lr){4-5}
			 %&       &        & LoC & \multicolumn{1}{c}{\%} \\
      %\midrule
      %jemalloc           &       & 39,059 & 116 & 0.30\% \\
      %libmalloc-simple\andrei{Is this BSD malloc?}   &       & 680    & 43  & 6.32\% \\
      %musl-libc          &       & 72,177 & 624 & 0.87\% \\
      %newlib stdlib      &       & 26,041 & 83  & 0.32\%\\
      %\bottomrule
    %\end{tabular}
  %\end{center}
  %\caption{The allocators we examined, their size in Source Lines of Code
  %(SLoC), and the number of lines changed to adapt them for pure capability
  %CheriBSD.\laurie{jeremy: we need to include the version number for each
  %allocator (or, at least, a git hash or similar) so that people can
  %reproduce our study.}\laurie{shouldn't bsdmalloc be in this table
    %too?}}
  %\label{tab:allocator_summary}
%\end{table}

How difficult is it to port a standard memory allocator to pure capability
CheriBSD\@? In this section we briefly examine several existing allocators. We
show the allocators we consider in \autoref{tab:allocator_summary}, as well as
their size, and the quantity and proportion of lines changed for the CHERI
port.

As \autoref{tab:allocator_summary} shows, with the exception of the extremely
small libmalloc-simple, the pure capability CheriBSD ports require around
0.3-0.9\% of lines to be changed. This is an order of magnitude bigger than the
0.026\% lines changed for porting a desktop environment (including X11 and
KDE)~\cite{watson21assessing}. Given the lower-level, and thus more platform
dependent, nature of memory allocators, this relative difference seems
reasonable.

\laurie{i don't think we need to go into too much detail, but there is some
value IMHO in seeing how much of the static API different allocators use.
unfortunately i don't fully understand some of the original text so the rest of
this section from this point onwards needs careful consideration.} A different
proxy for porting complexity is to measure the number of different CHERI API
calls a ported memory allocator makes use of: broadly speaking, the more of the
CHERI API is used, the harder the porting effort was likely to have been.
Comparing across the allocators is somewhat muddied because there are (at
least) three CHERI APIs in common use. This is due to the gradual evolution of
the software ecosystem over the past decade.

The most fundamental C-level API is provided by compiler builtins, such as
\texttt{\_\_builtin\_cheri\_base\_get}. There are currently 39 such builtins,
plus another four that are Morello-specific. In addition, the CHERI port of
LLVM introduces three generic builtins for managing alignment, which we do not
count as CHERI features for this analysis. Three of the memory allocators we
study -- newlib, Musl and Trivial -- make use of this
"builtin" API\@.

Another API is provided by \filename{cheric.h}. This is considered to be a
legacy, deprecated API\@. However, it is still in use, including by two of the
memory allocators we study (BSD malloc and jemalloc). \texttt{cheric.h}
provides 63 functions (or function-like macros), 29 of which are implemented as
trivial pass-throughs to compiler builtins. Several of the remaining 34
functions are fairly complicated compound operations. For example,
\texttt{cheri\_is\_subset} involves eight unique calls to four other functions.
\texttt{cheric.h} also provides some additional utilities for kernel use
(\texttt{cheri\_kern\_*}), and exposes some implementation details
(\texttt{\_\_cheri\_*}), but we disregard both subsets for this analysis.

\jacob{We should analyse how many of the cheric.h calls are to pass-through
functions, because they'll be easy to compare with cheriintrin.h
etc.}\andrei{What is a pass-through function? I can have a look}

The current preferred API is \filename{cheriintrin.h}, which provides 34
functions (or function-like macros), of which the vast majority (30) map
directly onto builtins, and the remaining four are very simple wrappers.

\jacob{Do we study anything using \texttt{cheriintrin.h}?}
\andrei{Add links/versions of these CHERI APIs we mention}

For each of the allocators, we inspect the source code to count the number of
distinct CHERI API calls. Note that if the same function is called in multiple
source code locations, we only count it once.  This gives us a static measure
of API coverage, for each allocator. \autoref{tab:rq1} shows the results,
indicating that some allocators have a broader spread of API calls. \emph{What
does this imply?} \emph{What are the API calls doing?}

\input{./data/results/cheri_api.tex}

%\begin{table}
  %\begin{center}
    %\begin{tabular}{ccrr}
    %\toprule
      %\textbf{allocator} & \textbf{API} & \textbf{\# API calls} & \textbf{API coverage} \\
      %\midrule
      %BSD malloc & cheric & 10 & 10/57 \\
      %jemalloc & cheric & 11 & 11/57 \\
      %Musl & builtin & ?? 22 or 6 ?? & 6/37 \\
      %Newlib & builtin & 9 & 9/37 \\
      %Trivial & builtin & 3 & 3/37 \\ 
      %\bottomrule
    %\end{tabular}
  %\end{center}
  %\caption{\label{tab:rq1}Coverage of CHERI API calls by various allocators}
%\end{table}

\jacob{Ok, it's time for a difficult question, sorry! Basically, why are we
asking this question (\textbf{RQ1}), and what are we hoping to learn from it?
Static API usage is relatively easy to measure, but I'm not sure what~table~\ref{tab:rq1} tells me.
Dynamic usage is more difficult to measure, but has more obvious uses (e.g.~for performance analysis).
However, for \emph{security} analysis, we probably want to count uses with the
vague property of ``sequences that require careful thought''.
Typically, it seems, these are cases affected by bounds imprecision (where
simple tests might work even for invalid code). Such sequences require significant work to
implement, and carry a greater risk of vulnerability.
For example: the bump allocator required a sequence with a critcial order of
operations, buT it was probably only a handful of API calls in the end. I think there were similar sequences in BoehmGC too.
Section~\ref{sec:atk}~goes into more detail there (by counter-example).}
\andrei{I will second this. My first impression of RQ1 was that it's more to do with performance analysis.}

\jacob{What \emph{are} the most common API calls? That was what \textbf{RQ1} asked.}


%%%


\subsection{Security Properties}
\label{sec:rqs:rq4}

The CHERI hardware extensions supports a variety of enforceable security
policies, but these require careful coding in software.
For memory allocators, CHERI offers the possibility of:
\begin{itemize}
\item lightweight software compartmentalization
\item temporal memory safety on the heap
\item spatial memory safety on the heap
\end{itemize}

When we survey existing CHERI memory allocators `in-the-wild', we
see that they currently provide support for spatial memory safety
on the heap.

In terms of the Common Weakness Enumeration (CWE \andrei{cite}), all the
allocators we surveyed only mitigate CWE-125: Out-of-bounds
Read~\footnote{\url{https://cwe.mitre.org/data/definitions/125.html}} and
CWE-787: Out-of-bounds
Write~\footnote{\url{https://cwe.mitre.org/data/definitions/787.html}}, for
dynamically allocated memory in the managed heap.

While this is stronger security than the equivalent non-CHERI versions of
these allocators, it is apparent that the CHERI allocators do not yet
take advantage of the full range of security mechanisms afforded by the
hardware. The next section goes on to explore potential security
vulnerabilities, mostly concerning temporal memory safety.


%%%%%


\section{Attacking Pure Capability Memory Allocators}
\label{sec:atk}

\input{./data/results/tests.tex}

%\begin{table}[t]
%\begin{center}
%\begin{tabular}{lcc}
%  \toprule
%Attack            & BSD simple & jemalloc \\
%\midrule
%narrow            & $\times$   & $\times$ \\
%narrow\_realloc   & $\times$   & $\times$ \\
%narrow\_widen     & $\times$   & $\times$ \\
%privesc           & $\times$   & $\times$ \\
%privesc2          &            & $\times$ \\
%undef             & $\times$   & $\times$ \\
%\bottomrule
%\end{tabular}
%\caption{Attacks which succeed on a given allocator are marked with a $\times$.}
%\label{tab:atks}
%\end{center}
%\end{table}

We came up with \numattacks{} potential memory allocator vulnerabilities, which
could be used to undermine the security guarantees offered by CHERI\@. We
prepared tests exercising each of these vulnerability, and execute them over
the allocators mentioned in~\autoref{sec:cheriallocators}, except those
allocators which have not passed our validation test. We observe a total of
\allocbugs{} attack successes (\autoref{tab:atks}), indicating potential CHERI
security violations.

Conceptually, the capability memory allocator vulnerabilities we identified
come in two flavours: the allocator can initially hand out more permissions
than expected; or can later be tricked in to escalating a capability's
privileges. As these undermine the security guarantees of using capabilities,
we refer to these issues as \emph{attacks}. In this section we start with three
serious attacks in the latter category, before detailing one minor attack in
the former category\andrei{Since we have names for these attacks, could we use
them, to refer back to the actual test sources}, as well as discuss theoretical
mitigations for each of the issues.

Formally speaking, CHERI capabilities have monotonically decreasing privileges:
in other words, when taking an existing capability \emph{C1} as input, any
capability \emph{C2} we derive from \emph{C1} must have the same or fewer
privileges. This may seem to make it impossible to increase a capability's
privileges, but software components can store high privilege capabilities that,
if misused, could give the appearance of returning a capability with increased
privileges. Due to the nature of memory allocators, they must be able to make
use of a higher-privileged capability in order to function.

Functions which take in a low privileged capability and use a higher privileged
capability\footnote{More formally, which take as input a capability \emph{C1}
and make internal use of  a capability \emph{C2}, where \emph{C2}'s set of
privileges are not a subset of \emph{C1}'s privileges.} to perform calculations
are at risk of privilege escalation, and need to be carefully audited for bad
idioms.

\subsection{\privesc: Insufficient validation of the input capability}

Consider a memory allocator whose \fnc{realloc(cap, size)} function takes in a
capability \texttt{cap} whose address references the beginning of a block of
memory and returns a new capability whose address references the beginning of a
block of memory sufficient for storing \texttt{size} bytes.  A common
\fnc{realloc} optimisation is to avoid moving memory if the requested size fits
within the `bucket' that the block already resides within.  We might then write
a simple \fnc{realloc} as follows, assuming that we have access to a
high-privileged capability \texttt{MC} (e.g.~from
\fnc{mmap}~\cite{brooks19cheriabi}):

\begin{lstlisting}[language=C]
void *realloc(void *cap, size_of size) {
  if (size_of_bucket(cap) <= size) {
    // No need to reallocate.
    return cheri_bounds_set(
      cheri_address_set(MC, cap),
      size);
  } else {
    // Allocate a larger region of memory and copy
    // cap's contents over.
    ...
  }
}
\end{lstlisting}

\noindent The crucial optimisation is on line 2: if we already have enough
memory for the resized block, we simply return a new capability with the same
address as the original capability but with an increased upper bound. By
definition, reducing the size of a block means that it will always fit within
its existing bucket so the above optimisation is guaranteed to be correct.

Unfortunately this implementation of \fnc{realloc} is subject to privilege
escalation. For example, one can pass in a capability with narrow bounds and
receive back a capability with wider bounds:

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(16);
arr = cheri_bounds_set(arr, 8);
assert(cheri_tag_get(arr) && cheri_length_get(arr) == 8);
arr = realloc(arr, 16);
assert(cheri_tag_get(arr) && cheri_length_get(arr) == 16);
\end{lstlisting}

We first \fnc{malloc} a block, returning a capability \emph{C1} with bounds
$0\ldots{}n$ bytes (line 1). We then derive a new capability \emph{C2} with
bounds $0\ldots{}m$ bytes where $m < n$ (lines 2 and 3). We can then use
\fnc{realloc} to turn \emph{C2} back into \emph{C1} -- even though we had
lost access to \emph{C1} entirely!

This is not just a theoretical attack: our example \fnc{realloc} is effectively
a simplified version of CheriBSD's \fnc{realloc}, which (as of
2021-08-18\footnote{\href{https://github.com/CTSRD-CHERI/cheribsd/issues/1065}{https://github.com/CTSRD-CHERI/cheribsd/issues/1065}})
is vulnerable to this attack. Any capability whose bounds contain the base
address of a memory block can potentially have its privileges escalated, with
\fnc{realloc} returning a capability with the same permissions as the memory
system's main capability (as well as widening bounds, this allows
e.g.~upgrading a read-only capability to a read/write capability).

\subsubsection{Mitigations}

Privilege escalation occurs when a function fails to fully validate a possibly
lower-privileged capability correctly before using a higher-privileged
capability. Exactly what validation should occur is highly situation dependent,
which is why it is easy to get wrong.

In most, perhaps all, reasonable cases, the input CHERI capability should be
authentic and the capability's address in-bounds. However, as our
\fnc{realloc} attack shows, these two conditions are necessary but not
sufficient.  For example, one solution to the \fnc{realloc} attack is to
check that \fnc{cap}'s address refers to the start of a memory block and
that the capability's permissions are equal to the permissions returned by the
most recent \fnc{malloc} or \fnc{realloc} for that memory block. This
implies that the memory allocator must either store, or be able to derive by
other means, the capability returned by the most recent \fnc{malloc} or
\fnc{realloc} call.

However, it may be too restrictive to restrict \fnc{realloc} to precisely
equal capabilities: one may wish to allow \emph{compatible} capabilities. The
definition of compatibility is then crucial, particularly as different CHERI
architectures have different bounds representations and permissions.

\subsection{\narrowwiden: Narrowing then widening}

Assuming that a child capability with narrow bounds has been derived while
respecting the issues raised in \narrowingdoesnt (\autoref{sec:narrow}), it may
seem that our issues with capability bounds are over. However, if one later
widens those bounds again, one may unintentionally leak secrets.

CheriBSD's default \fnc{realloc} is subject to this problem. The following
code executes successfully, with the capability returned by \fnc{realloc}
giving access to the same range of memory as the original \fnc{malloc}. Note
that \fnc{realloc} does not move, or scrub, memory in such a case. Thus, if
the user expected the setting of bounds to protect a secret, this code will not
give the protection expected.

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(256);
for (uint8_t i = 0; i < 255; i++) arr[i] = i;
arr = realloc(arr, 1);
assert(cheri_tag_get(arr) && cheri_length_get(arr) == 1);
arr = realloc(arr, 256);
for (uint8_t i = 0; i < 255; i++) assert(arr[i] == i);
\end{lstlisting}


\subsubsection{Mitigations}

In the specific example above, \fnc{realloc} should scrub memory when the
size of a memory block is being narrowed. However, this may not be appropriate
in all cases, particularly where capability bounds narrowing is being used to
hide a secret from another compartment. In such cases, code which can widen a
capability's bounds must be carefully audited.


\subsection{\myundef: Authentic capabilities from undefined behaviour}

It is easy to assume that authentic capabilities can only be derived if one
follows CHERI-C's
\andrei{This is the first and only reference to this ``CHERI-C''}
rules correctly. However, it is possible for an attacker to use undefined
behaviour to derive authentic capabilities. Consider the following code:

\begin{lstlisting}[language=C]
uint8_t *c1 = malloc(16);
ptraddr_t c1_addr = cheri_address_get(c1);
uint8_t *c2 = cheri_bounds_set(c1, 8);

free(c2);
uint8_t *c3 = malloc(16);
assert(cheri_tag_get(c3) && cheri_length_get(c3) == 16);
assert(cheri_address_get(c3) == c1_addr);
\end{lstlisting}

In this example, we first derive a capability \emph{C1} with bounds of 16 bytes
(line 1) before deriving a narrower capability \emph{C2} from it (line 3). It
is then possible that after \fnc{free}ing the block of memory addressed by \emph{C1},
a subsequent \fnc{malloc} of 16 bytes returns a
capability \emph{C3} that is identical to \emph{C1}. This attack relies
on the underlying memory allocator reusing memory blocks, which many do in a
predictable fashion: this example runs successfully on CheriBSD (as of
2021-08-19).

Interestingly, C's pointer provenance rules mean that, after the code above has
executed, using \emph{C1} is no longer defined behaviour though this will not
trouble an attacker, who will find that most programs still execute as expected
and who now has a capability \emph{C3} giving the same access as \emph{C1}.


\subsubsection{Mitigations}

There are no general mitigations for \myundef. For the particular concrete
example, a partial mitigation is for \texttt{free} to scrub memory so that, at
least, whatever was present in the buffer cannot read by the attacker: however,
since the attack has in effect `aliased' the capability, future writes can be
observed and tampered with by the attacker.

A more complete mitigation for the concrete example is for \texttt{free} to
revoke all references to the capability. In other words, CHERI allows one to
scan memory looking for all capabilities with bounds encompassing an address
$p$ and invalidate the capability~\cite{xia29cherivoke}. In this case, this
means that the original code will then fail with a \texttt{SIGPROT} when it
tries to use \emph{C1}, downgrading the security leak into a denial-of-service.
However, scanning the stack and heap in order to perform revocation is not
likely to be a quick operation.


\subsection{\narrowingdoesnt: Narrowing a capability's bounds does not always fully narrow the capability's bounds}
\label{sec:narrow}

\laurie{this isn't quite an attack in the same style as the others or, at
least, i couldn't tickle it in quite the same way. however, if there are
allocators which allocate `larger' chunks of memory contiguously, they could be
subject to this attack, as one block's bounds might overlap with a
predecessor/successor}

Capabilities have high and low bounds, which are a strong enforcement mechanism
for restricting the region of memory that the capability can access for
reading and writing. It is thus tempting to write code which hides secrets
(e.g.~allocator metadata) beyond the reach of a capability's bounds such as the
following:

% Adapted from narrow.c
\begin{lstlisting}[language=C]
uint8_t *array_with_hidden_secret(size_t size) {
    uint8_t *arr = malloc(size);
    return cheri_bounds_set(arr, size - 1);
}
\end{lstlisting}

\noindent We first \fnc{malloc} an array with enough space to store
\texttt{size} bytes (line 2) before creating a child capability
which prevents access to the array's final byte (line 3). We can verify this
behaviour by checking the returned capability's length, as in the following
code, which executes without error:

% Adapted from narrow.c
\begin{lstlisting}[language=C]
uint8_t *arr = array_with_hidden_secret(16385);
assert(cheri_length_get(arr) == 16384);
\end{lstlisting}

\noindent This idiom is insidious because it works correctly for the sorts of
`human friendly' sizes that programmers tend to test, but not for many other
sizes. As we saw above, creating a capability with a bound of 16384 bytes
prevents access to the array's last byte. However, making the array 1 byte
bigger undermines our expectations, as in the following code, which executes
without error:

% Adapted from narrow.c
\begin{lstlisting}[language=C]
uint8_t *arr = array_with_hidden_secret(16386);
assert(cheri_length_get(arr) == 16392);
\end{lstlisting}

\noindent Although we expected a capability with a bound of 16385 bytes, the
capability we receive has a bound of 16392 bytes. On Morello, 16385 bytes is
the smallest bound which
can not be precisely represented in a capability, and thus it has been been
rounded up to the next representable bound.

Practically speaking, this means that one cannot expect that narrowing a
capability's bounds precisely captures only the requested region of memory: in
general, the capability will provide access to more memory than one wishes.
Forgetting to take account of this, as in our example above, leads to secrets
being leaked.

The underlying issue is that modern CHERI systems use `CHERI
Concentrate'~\cite{woodruff19chericoncentrate}, an approach to representing
bounds that requires relatively few bits: for example Morello's capabilities
have 31 bits to express the bounds for a 64-bit address space. The trade-off is
simple: the fewer bits used for bounds, the smaller capabilities are (which is
good for memory use and performance), but the less precise the bounds that can
be represented. The encoding is ingenious, but hard to capture succinctly: in essence,
bounds use exponents, in similar fashion to IEEE 754 floating point
numbers: the wider the bound, the less accurately it will be
represented. When a desired length cannot be precisely represented, the next
largest precisely representable length is used in the bound.


\subsubsection{Mitigations}

There are three approaches that can ensure that narrowing bounds does not cause
secrets to be leaked.

First, one can check whether the narrowed bounds do/would capture only the
desired region of memory and if they don't/wouldn't, move the secret data to a
(probably new) non-overlapping region of memory. One can check whether bounds
will be adequately narrowed in advance using
\fnc{cheri\_representable\_length} or retrospectively by querying the
narrowed capability with \fnc{cheri\_length\_get}.

Second, one can lay out memory in advance such that, no matter what imprecise
bounds are used, secrets will not leak. In essence, this requires adding
padding to each object to take account of imprecise bounds. One could rewrite
\fnc{array\_with\_hidden\_secret} using this technique, provided that the
number of secret items at the end of the array does not vary after array
creation time.

These two approaches have different costs. The first approach requires users
only to pay for the cost of wasted memory if it is needed. However, at best
this introduces unexpected pauses as memory is allocated and copied. At worst,
this approach is infeasible --- one cannot, for example, easily move the
\emph{n}th element of a contiguous array because it is too big to be
represented with precise bounds. The second approach, in contrast, has fixed
up-front costs, but requires wasting memory for every object, even if no
future capability will ever have bounds covering it.

Third, one can abort execution if bounds cannot be precisely represented. The
\fnc{cheri\_bounds\_set\_exact} is a `safe' variant of
\fnc{cheri\_bounds\_set} which raises an error if bounds cannot be precisely
represented. We would prefer to see this be the standard bounds-setting
function, with a \fnc{cheri\_bounds\_set\_unsafe} variant allowing the
programmer to bypass bounds precision checks (because they are confident that
either: their bounds request can be precisely represented; or their code works
correctly with any resulting imprecision).

\jacob{Notably, occurrences of this pattern in real code will (as we've seen) be
much less obvious, and very hard to spot in code reviews. We could really do
with a helper that tests whether or not a hypothetical access would be
permitted, so we can write assertions in our \texttt{realloc} implementation, etc.}
\laurie{what would such a helper function look like?}


\subsection{Capability overflow}

\laurie{is this possible?}
\jacob{Not when used in the obvious way (e.g. dereferencing), but extreme
(65-bit) bounds behave in non-portable ways when queried explicitly, e.g.
saturating on Morello, and this isn't obvious in the CHERI API\@. This makes
manually testing the bounds difficult.}
\laurie{interesting! can we make a simple code example which shows this?}


\section{Conclusions}

\textbf{Acknowledgements:} We thank Ruben Ayrapetyan and David Chisnall for
comments.


\bibliographystyle{plain}
\bibliography{bib}

\end{document}
