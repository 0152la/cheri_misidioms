%&cheri_misidioms_preamble
\endofdump

\begin{document}


\begin{abstract}
\noindent
Several memory allocators have been ported to CHERI, a hardware capability
platform. In this paper we examine the security and performance of these
allocators. We show that most allocators are subject to simple security vulnerabilities,
which we categorise and explain. However, we show that current versions of LLVM
inconsistently optimise CHERI code, leading to a muddled performance picture.
\end{abstract}

\maketitle

\section{Introduction}

Capability Hardware Enhanced RISC Instructions
(CHERI)~\cite{watson20cheriintroduction} provides and enforces hardware
capabilities that allow programmers to make strong security guarantees
about the memory safety properties of their programs. However, capabilities are
not magic. Programmers must first decide which memory safety properties they
wish to enforce and then write their software in a way that enforces those properties.
It is easy for mistakes to creep in during either step, undermining
the security guarantees programmers believe their code possesses.

In this paper we examine one of the most fundamental software components:
memory allocators (henceforth just ``allocators''). Apart from some embedded
systems (which preallocate fixed quantities of memory), allocators are
ubiquitous, because they allow us to write programs that are generic over a
variety of memory usage patterns. Since allocators are used so frequently,
their security properties and performance are a major part of
the security properties and performance of software in general. In other words,
allocators with security flaws and/or performance problems have significant,
widespread consequences.

In this paper we examine allocators and CHERI from both security and performance
angles. We show that all CHERI allocators are subject to at least some simple attacks
that are likely to surprise reasonable programmers. To our surprise, we also
show that it is difficult to draw meaningful conclusions about performance:
we show that compilers on CHERI platforms do not optimise code as fully as one
would expect, leading to a muddled performance picture. We do not claim our
work is definitive, though it does suggest two things: that some allocators
undermine the security properties one might expect from software running on
pure capability CHERI; and that it is currently difficult to reason about the
performance of software on CHERI.

In essence the paper is split in two. First, we introduce the necessary
background: a brief overview of CHERI for those unfamiliar with it (\autoref{sec:cheri});
our running example, a simple bump allocator (\autoref{sec:bumppointerallocator}; and
a simple example of how allocators can be vulnerable, or invulnerable, to attack on CHERI
(\autoref{sec:atk}). Second, we introduce our experiments: the allocators
under consideration (\autoref{sec:cheriallocators}); our attacks (\autoref{sec:atks});
and our (attempted) performance evaluation (\autoref{performance}).


\section{CHERI Overview}
\label{sec:cheri}

In this section, we provide a simple overview of CHERI, and its major concepts.
Since CHERI has been developed over a number of years, and is explained over
a variety of documentation and papers, some concepts have acquired more than one name,
or names that subtly conflict with mainstream
software development definitions. We use a single name for each concept, sometimes
introducing new names where we believe that makes things clearer.

A \emph{capability} is a token that gives those who bear it \emph{abilities} to
perform certain actions. By restricting who has access to a given capability,
one can enforce security properties (e.g.~`this part of the software can
only read from memory address X to Y'). Capabilities have a long and storied history: \cite{levy84capability}
provides an approachable historical overview of capability architectures, and
may usefully be augmented by more recent work such as~\cite{miller06robust}.
A good first intuition is that CHERI is a modern update of this venerable
idea, updated with fine-grained permissions, and adapted to work on modern
processor instruction sets.

We use the term \emph{CHERI} to refer to the `abstract capability machine'
that software can observe: that is, the combination of a capability hardware
instruction set, an ABI (e.g.~\cite{brooks19cheriabi}), a user-facing library that exposes
capability-related functions, and a CHERI-aware language. (e.g.~CHERI C~\cite{watson20chericprogramming},
an adaption, in the sense of both extending and occasionally altering, of C).
We refer to specific hardware implementations by their name (e.g.~CHERI
RISC-V). In this paper, we mostly use Arm's `Morello' implementation, which is an
experimental ARMv8 chip extended with CHERI instructions.

\label{abilities}
Conceptually, a CHERI system starts with a `super' capability that has
the maximum set of abilities. Each
new \emph{child} capability must be derived from one or more \emph{parent}
capabilities. Child capabilities must have the same, or fewer, abilities than its
parent: put another way, capabilities' abilities monotonically decrease.
An \emph{authentic}\footnote{CHERI calls these
`tagged' or `valid' (and their inauthentic counterparts `untagged' or `invalid').}
capabilityÂ is one that has been derived from authentic parents according to
CHERI's rules. Attempts to create capabilities that violate CHERI's rules
cause the hardware to produce an \emph{inauthentic} result, guaranteeing
that capabilities cannot be forged. For example,
there is no user-space mechanism to set a capability as `valid'; only a child capability
derived, correctly, from valid parent capabilities can itself be valid.

A capability consists of an
\emph{address}\footnote{This portion of a capability does not \emph{have} to store an
address, though typically it does so, and the CHERI API calls it \texttt{address}.
In the context of this paper, since it always stores an address, we stick with this name.},
and its abilities: a set of \emph{permissions} (only a subset of
which we consider in this paper);
and \emph{bounds}, the memory range on which
the capability can operate.

Permissions include the ability to read / write from memory.
A \emph{permissions check} is said to be successful if the permission required
for a given operation is provided by a given capability.

A capability's bounds
are from a \emph{low} (inclusive) to a \emph{high} (exclusive) address: when
we refer to a capability's bounds being of `$x$' bytes we mean that
$\textit{high}-\textit{low}=x$. An address is
\emph{in-bounds} for a given capability if it is wholly contained within the
capability's bounds, or \emph{out-of-bounds} otherwise; a capability is
in (or out) of bounds if its address is in (or out) of bounds
\footnote{See~\cite{woodruff19chericoncentrate} for an explanation of why an authentic
capability might have an out-of-bounds address.}.
A \emph{bounds check} is said to be successful if a given capability, address, or
address range, is in-bounds for a given capability.

Hardware that operates on a capability requires one or more of: an authenticity
check, a permissions check, or a bounds check. If a capability passes the
relevant checks, then the operation \emph{exercises} the capability. If a
capability fails the relevant checks then either: the hardware produces an
exception; or produces an inauthentic capability as a result (where this is not
in violation of the CHERI rules). For example, a failed attempt to exercise a capability for a
sealing operation on Morello produces an inauthentic result, rather than an
exception.

On Morello and CHERI RISC-V, capabilities behave as if they are 128 bits in
size, but also carry an additional bit that records the authenticity of each
capability: the authenticity bit can be read, and can be unset, but cannot
be set (i.e.~authentic capabilities must be created via hardware following
CHERI's rules).

CHERI also allows `traditional' single-width
pointers-as-addresses (which on Morello and CHERI RISC-V are 64-bit addresses)
to be used. Although CHERI processors allow both double-width capabilities and
single-width addresses-as-pointers to exist alongside each other at any time,
conventionally, a program which uses both traditional addresses and
capabilities is said to be operating in \emph{hybrid} mode while a program
which uses only capabilities is in \emph{pure capability} mode. In this paper
we concentrate exclusively on programs which operate in pure capability mode.

CHERI does not presuppose a particular Operating System (OS). While there is a
CHERI Linux port, at the time of writing the most mature OS for CHERI hardware
is CheriBSD, a FreeBSD descendent. In this paper we use CheriBSD exclusively.


\section{A Basic Pure Capability Allocator}
\label{sec:bumppointerallocator}

To illustrate how CHERI affects allocators, in this subsection we adapt a simple
non-CHERI aware allocator to become CHERI aware.

\begin{figure}[t]
\lstinputlisting[
  language=C,
  caption={
    A simple, but complete, non-CHERI aware, bump pointer allocator:
    \fnc{malloc} works as per normal; \fnc{free} is a no-op; and
    \fnc{realloc} always allocates a new chunk, copying
    over the old block.
    \fnc{\_\_builtin\_align\_up(v, a)} is an LLVM / clang primitive which rounds
    \texttt{v} up to the next smallest multiple of \texttt{a};
    \texttt{\_Alignof(max\_align\_t))} returns an alignment sufficiently large
    for any scalar type (i.e.~integers and pointers).
  },
label=lst:bump_alloc1]{code/bump_alloc1.c}
\end{figure}

We start with a simple, complete, example of a C bump allocator in
~\autoref{lst:bump_alloc1}: \fnc{malloc} works as per normal; \fnc{free} is
a no-op; and \fnc{realloc} always allocates a new chunk of memory. The
allocator reserves a large chunk of memory using a single \fnc{mmap} call then
doles out chunks on each \fnc{malloc} / \fnc{realloc} calls. The bump pointer
moves through the \fnc{mmap}ed chunk until it reaches the upper limit, at which
point the allocator returns \texttt{NULL}s. \fnc{realloc} is intentionally
simplistic, but correct even when the block is increased in size.


\subsection{Adapting the Allocator to CHERI}

Perhaps surprisingly, our simple bump allocator compiles, and \fnc{malloc} runs
correctly, on CHERI systems too. As this suggests, CHERI C is largely source
compatible with normal C code, though pointer types are transparently `upgraded' to become
\emph{capability types} (on Morello occupying exactly twice the space of a
non-capability pointer). CHERI also implies changes in libraries: on CheriBSD,
for example, \fnc{mmap} returns a capability whose bounds are at least those of
the sized requested: from that capability our bump allocator derives new
capabilities that differ in their address, but not their bounds. In other
words, two calls to \fnc{malloc} will produce two capabilities that have the
same bounds, allowing anyone who possesses one of the capabilities to read and
write from any portion of \fnc{malloc}ed memory.

\begin{figure}[t]
\lstinputlisting[language=C,
  caption={
    Replacing the non-CHERI aware \fnc{malloc} from ~\autoref{lst:bump_alloc1}
    with a CHERI-aware alternative
    using the idioms suggested in~{\cite[p.~30]{watson20chericprogramming}}.
    This \fnc{malloc} returns a capability whose bounds are sufficient
    to cover \texttt{size} bytes starting at the capability's address
    (calculated in lines 5--10),
    such that two callers to \fnc{malloc} cannot read or write from
    another block. We also have to update \fnc{realloc} so that it never tries to copy
    more data from the old block than the \texttt{ptr} capability gives
    it access to.
  },
    label=lst:bump_alloc2]
  {code/bump_alloc2.c}
\end{figure}

As this suggests, using CHERI without careful consideration may lead to
no additional security benefits of using CHERI. This then raises the question:
how should a secure `CHERI aware' allocator behave? There can be no single
answer to this question, but we believe that most programmers would expect
\texttt{malloc} to return a capability restricted to the block of memory
allocated. \autoref{lst:bump_alloc2}
shows how to adapt \texttt{malloc} to do this.

The code to create the capability (using the idioms suggested
in~\cite[p.~30]{watson20chericprogramming}) is more involved than one might
first expect. The underlying cause is that there aren't, and cannot reasonably
be, enough bits in CHERI's bounds to precisely represent every possible address
and size. Modern CHERI therefore uses an encoding for bounds that allows small
bounds to be precisely represented, at the expense of larger bounds becoming
progressively less precise~\cite{woodruff19chericoncentrate}. On Morello,
the smallest bound that cannot be precisely represented is 16,385 bytes,
which is rounded up to 16,392 bytes\footnote{For CHERI RISC-V the first unrepresentable length is
4,097 bytes, which is rounded up to 4,104.}. Our capability aware
\texttt{malloc} thus has to ensure that both the capability's low and high
bound addresses are rounded down and up (respectively) in a way that ensures
that the address and size can be fully covered.

The two versions of our allocator have meaningfully different security properties,
even when we run both on a CHERI system. For example, consider this simple
C snippet which models a buffer overrun:

\begin{lstlisting}[language=C]
char *b = malloc(1);
b[0] = 'a';
b[1] = 'b';
\end{lstlisting}

On a non-CHERI system, or a CHERI system with \autoref{lst:bump_alloc1}
as an allocator, this snippet compiles and runs without error. However, with
the allocator from \autoref{lst:bump_alloc2} the code compiles but crashes with
a security violation when attempting to execute line 3, due to the tighter
capability bounds returned by its \texttt{malloc}, showing how CHERI can prevent
programmer errors becoming security violations.

However, just because a program compiles with CHERI C does not guarantee that
it will always run without issue: when run on CHERI, \fnc{realloc} in~\autoref{lst:bump_alloc1}
causes a hardware security exception if asked to
increase the size of a block. This occurs because \fnc{memcpy} tries to copy
beyond the bounds of the input capability (e.g.~if the existing block is 8
bytes and we ask to resize it to 16 bytes, \fnc{memcpy} tries to read
16 bytes from a capability whose bounds are 8 bytes). On a non-CHERI system,
this is not a security violation, but it is treated as one on CHERI. In
\autoref{lst:bump_alloc2} we thus provide an updated \fnc{realloc} which
uses \texttt{cheri\_length\_get} (which returns a capability's bounds
in bytes) to ensure that it never copies more data than the input capability's
bounds allow.


\section{How can a CHERI Allocator be Attacked?}
\label{sec:atk}

Our definition of CHERI in~\autoref{sec:cheri} might suggest that software
running on CHERI hardware is invulnerable to attack. Alas, while CHERI gives us the
tools to make secure software, it is up to us to use them correctly --- and wisely.
We must decide which attack model is relevant to our software, and then write,
or adjust, the software, to withstand such attacks. Broadly speaking, allocators are
subject to spatial (e.g.~buffer overrun) or temporal (e.g.~a sequence of
function calls) attacks, and those attacks can be either on an allocators'
internals (e.g.~corrupting its private data-structures) or its interface
(e.g.~allowing code using the allocator to subvert expectations).

For example, consider this C snippet, which models a buffer overrun:

\begin{lstlisting}[language=C]
char *a = malloc(16);
char *b = malloc(16);
a[16] = 'c';
printf("%c\n", b[0]);
\end{lstlisting}

With the capability-unaware bump allocator from \autoref{lst:bump_alloc1} this
code compiles successfully and, when run, prints `\texttt{c}'\footnote{Note
that the example is in the realm of undefined behaviour, so a compiler could
compile this code to do something entirely different -- though, at the time of
writing, CheriBSD's LLVM does not do so.}. It does this because the bump
allocator allocates the second block immediately after the first in memory, so
writing 1 past the end of the first block in fact writes to the first byte of
the second block. However, with the
capability-aware allocator from \autoref{lst:bump_alloc2}, the program aborts
with a security exception when executing line 3.

Buffer overruns are so common in C code that we expect most people to consider
that part of their attack model: by extension, we believe that they
would expect a CHERI allocator to protect against such attacks. However, the
difference between~\autoref{lst:bump_alloc1} and~\autoref{lst:bump_alloc2}
shows that such protection often requires careful adjustments of code to
take advantage of CHERI. As we
shall see later, it is not just our bump allocator that is subject to this
particular attack.


\section{CHERI Allocators}
\label{sec:cheriallocators}

In this paper we consider a number of allocators that are available for
CheriBSD. We first of all explain the set of allocators we use, before
exploring in more detail how the allocators have been adapted (if at all) for
CHERI.


\subsection{The Allocators Under Consideration}

A number of allocators are available for CheriBSD, installable via three
different routes: as part of the base distribution; via CheriBSD
\emph{packages}; or via external sources.  We examined allocators
available via all three routes. We excluded
allocators aimed only for debugging purposes (e.g.~\memalloc{ElectricFence}).
We then ran a simple validation test, \fnc{malloc}ing a block of memory,
copying data into the block, and then \fnc{free}ing the block: we
excluded any allocator which failed this test. We
document by which route we obtained all of the allocators we consider.

On that basis, the allocators we consider in this paper, and the names we use
for them for the rest of this paper, are as follows:
\begin{itemize}
\item \memalloc{jemalloc}, a modified version of the well-known
    \emph{jemalloc}~\cite{evans06scalable} allocator, is the default allocator
    for CheriBSD.

\item \memalloc{libmalloc-simple}\footnoteurl{https://github.com/CTSRD-CHERI/cheribsd/commit/e85ccde6d78d40f130ebf126a001589d75d60473}{23rd
    February 2023} is a port of the allocator present in FreeBSD`s
    \texttt{rtld-elf} utility\footnoteurl{https://github.com/freebsd/freebsd-src/blob/releng/4.3/libexec/rtld-elf/malloc.c}{
    23rd of February 2023}.

\item \memalloc{snmalloc-cheribuild} is an old version of
    \emph{snmalloc}~\cite{lietar19snmalloc} that can be installed via
    \texttt{cheribuild}. We found that this version to have several problems
    which we rectified by manually building a version from \emph{snmalloc}'s
    GitHub repository, which includes the \texttt{cheribuild} version, but has
    more recent updates. We term this latter version \texttt{snmalloc-repo}.

\item \memalloc{dlmalloc-cheribuild} is a version of the well-known
    \emph{dlmalloc} allocator~\cite{lea96memory} modified for CHERI,
    installable via \texttt{cheribuild}. CheriBSD's packages include
    \memalloc{dlmalloc-pkg64c} which is an unmodified version of dlmalloc. The
    ported version in \texttt{cheribuild} is based on the same as those in the
    packages, namely 2.8.6.

\item \memalloc{ptmalloc}~\cite{gloger06ptmalloc} is an extension of
    \memalloc{dlmalloc}, with added support for multiple threads. A
    non-modified package of \memalloc{ptmalloc3} version 1.8 is available in
    the package manager of CheriBSD

\item \memalloc{bump-alloc-nocheri} is the simple, non-CHERI-aware bump
    allocator from~\autoref{lst:bump_alloc1}. Conversely,
    \memalloc{bump-alloc-cheri} is the CHERI aware version, presented
    in~\autoref{lst:bump_alloc2}.
\end{itemize}

\input{./data/results/slocs.tex}

\autoref{tab:allocator_summary} shows the version of each allocator we used.
We are aware of at least two other major memory allocators that have been
partly ported to CHERI: the \emph{Boehm-Demers-Weiser} conservative garbage
collector; and the \emph{WebKit} garbage collector. Since neither port is yet
complete, we have not included them in this paper.


\subsection{How Much Have the Allocators Been Adapted for CHERI?}
\label{sec:rqs}

As we saw from \autoref{lst:bump_alloc1}, simple allocators don't need to be
adapted for CHERI at all, though they then derive only minor security gains. In
practise, we expect most allocators to at least reflect the capability bound
changes of \autoref{lst:bump_alloc2}. \laurie{this is speculative: andrei,
jeremy, is this correct?}\andrei{If this is what's up until this point, I think yes. If it's about after this point, I think `dlmalloc-pkg64c` is good evidence if that} More sophisticated allocators will also tend to tend
to crash without at least some modifications; a concrete example of this is the
allocators provided by \texttt{pkg64c} -- we have found no evidence that any
CHERI-specific code has been added to their sources, but they still compile on
CheriBSD. However, they cannot execute a simple validation test without
crashing. Furthermore, existing allocator metadata must be updated to include
capability data at least to some degree, in order to be able to derive
capabilities with appropriate bounds.

Understanding all of the CHERI modifications to all of the allocators under
consideration would lead to us not being able to see the forest for the trees.
Instead, \autoref{tab:allocator_summary} shows what proportion of an
allocator's LoC are `CHERI specific' by calculating the percentage of lines of code contained between
\texttt{\#ifdef CHERI} blocks. This count is an under-approximation, as some
code outside such \texttt{\#ifdef} blocks may also have been adapted, but it
gives a rough idea of the extent of changes. \laurie{jeremy: what tool did you use for this?}

With the exception of the extremely small \texttt{libmalloc-simple}, the pure capability CheriBSD allocators
have had around 0.3--0.9\% of their LoC adapted. Although this is a relatively small portion,
it is an order of magnitude bigger than the
0.026\% lines that were adapted when porting a desktop environment (including X11 and
KDE)~\cite{watson21assessing}. It is a reasonable assumption that the
lower-level, and more platform dependent, nature of allocators has
caused more LoC to be adapted.

A different proxy for the complexity of CHERI adaption is the number of CHERI API
calls a ported memory allocator makes use of: broadly speaking, the more of the
CHERI API is used, the `deeper' we might consider the adaption to be.
Comparing across the allocators is somewhat muddied because there are (at
least) three CHERI APIs in common use. We define these APIs as follows:

\begin{itemize}
  \item
The \emph{builtin} API consists of C functions provided as LLVM / Clang
extensions (e.g.~\texttt{\_\_builtin\_cheri\_base\_get}). There are 39 generic
CHERI functions, with Morello defining four more. As these builtins are
provided by the compiler, we note that they are available by default.

\item
The \emph{cheric.h} API is deprecated, but still frequently used,
providing 63 functions and macros (29 of \laurie{just the macros?} which are,
in essence, simple wrappers around the \emph{builtin} API).

\item
The \emph{cheriintrin.h} API is similar to, but supersedes, the \emph{cheric.h}
API. \laurie{can we explain why it supersedes cheric?}\andrei{does intrin
fully cover cheric?} It provides 34 functions and macros, 30 of which map
directly to the \emph{builtin} API.
\end{itemize}

The former two header files are provided for a more accessible interface to
CHERI functions, and to provide some level of portability. For example, certain
hardware properties are defined with negative numbers in RISC-V, and with
positive numbers on
Morello\footnoteurl{https://github.com/CTSRD-CHERI/llvm-project/blob/master/clang/lib/Headers/cheriintrin.h##L73-L74}{2nd of March 2023}.

Another distinction to be made is that we can assume allocators making use of
\emph{cheric.h} to be more dated than ones using \emph{cheriintrin.h}. Of
course, any software that needs access to CHERI functions can choose to use the
readily-available \emph{builtin} API. \andrei{I wonder if there's some
documentation about what it offers, or do you need to look at source code? I
would assume there is some document for the other two}

\laurie{obvious question: why does cheriintrin.h exist if it's just wrapping
the builtins?!}\andrei{I would assume to provde a cleaner interface to use
(e.g., cheri-ddc-get is --builtin-cheri-global-data-get, and
cheri-representable-length is --builtin-cheri-round-representable-length}

\section{The Attacks}
\label{sec:atks}

\input{./data/results/tests.tex}

In this section we introduce a number of `attacks' on CHERI allocators (3
temporal and 1 spatial) and then run those attacks on the allocators from
\autoref{sec:cheriallocators}, with the results shown in \autoref{tab:atks}.
At least one allocator is vulnerable to each of these attacks; only
snmalloc is immune to all the attacks; and the default CheriBSD allocator
jemalloc is vulnerable to several of the attacks.

In the rest of this section we explain each attack, C code using the CHERI API
when possible, and also explaining possible mitigations. The code we show in
the paper is sometimes a simplified version of that we run: the latter must be
considered the definitive source of truth for \autoref{sec:cheriallocators}.
All our code is available on GitHub.

In the rest of this section we make use of the following CHERI functions:

\setlength{\leftskip}{6pt}

\vspace{6pt}
\noindent\texttt{void *cheri\_address\_set(void *c, \\vaddr\_t a)}~~~~
Takes a capability \texttt{c} as input and produces a new capability
that is a copy of \texttt{c} except with the address \texttt{a}.
\texttt{vaddr\_t} is a CHERI C integer type that is guaranteed to be big enough
to represent addresses but, unlike \texttt{intptr\_t} is not big enough to
represent capabilities.

\vspace{6pt}
\noindent\texttt{void *cheri\_bounds\_set(void *c, \\size\_t s)}
Takes a capability \texttt{c} as input and produces a new capability
that is a copy of \texttt{c} except with bounds of size \texttt{s}.

\vspace{6pt}
\noindent\texttt{size\_t cheri\_length\_get(void *c)}
Returns the bounds of a capability \texttt{c}.

\vspace{6pt}
\noindent\texttt{\_Bool cheri\_tag\_get(void *c)}
Returns true if the capability \texttt{c} is authentic or false otherwise.

\vspace{6pt}
\noindent\texttt{void* cheri\_perms\_and(void *c,\\ size\_t perms)}
Return the capability \texttt{c} with its permissions bitwise-ANDed
with \texttt{perms}.

\vspace{6pt}
\noindent\texttt{size\_t cheri\_perms\_get(void *c)}
Return the permissions of capability \texttt{c}.

\setlength{\leftskip}{0pt}


\subsection{\narrowwiden: Narrowing then Widening Can Allow Access to Hidden Data}
\label{narrowwiden}

In the simple bump allocator of \autoref{lst:bump_alloc1}, \texttt{realloc} always
allocates a new block of memory. While this is always correct, it is inefficient,
in part because it requires copying part of the block's existing content.
Most allocators thus try to avoid allocating a new block of memory if: the
new size is the same as, or smaller than, the existing size; or if
the new size would not lead to the block overwriting its nearest neighbour.
The latter optimisation is dangerous for a CHERI allocator.

Consider the case where \texttt{realloc} wants to increase a
block in size, and there is sufficient room to do so without moving the block.
\texttt{realloc} needs to return a capability whose bounds encompass the new
(larger) size. However, such a capability cannot be derived from the input
capability, as doing so would lead to an inauthentic capability, and
we would violate the property that a capability's abilities must monotonically
decrease. Thus, the allocator needs access to a `super'
capability which it can use to derive a capability representing the new bounds.
Let us call the `super' capability \texttt{SC} and introduce a function
\texttt{size\_of\_bucket} which tells us the maximum space available for
the block starting at \texttt{ptr}. Eliding extraneous details (e.g.~about
alignment), \fnc{realloc} will then look as follows:

\begin{lstlisting}[language=C]
void *realloc(void *ptr, size_t size) {
  if (size_of_bucket(ptr) <= size) {
    // No need to reallocate.
    void *new_ptr =
      cheri_address_set(SC, ptr),
    return cheri_bounds_set(
      new_ptr, size);
  } else {
    // Allocate a larger region of memory
    // and copy the old contents.
  }
}
\end{lstlisting}

\noindent Lines 4--7 need to deal with the
case where the block is to be increased in size but will still fit
in its current bucket. We
first use \fnc{cheri\_address\_set} to derive a new capability from
\texttt{SC} whose address is the same as \texttt{ptr} but whose bounds will be
those of \texttt{SC} (lines 5 and 6) before narrowing those bounds to
\texttt{size} (lines 6 and 7).

When implemented in this style, an allocator can be subject to a trivial
attack we call \narrowwiden:

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(256);
for (uint8_t i = 0; i < 255; i++)
  arr[i] = i;
arr = realloc(arr, 1);
arr = realloc(arr, 256);
for (uint8_t i = 0; i < 255; i++)
  assert(arr[i] == i);
\end{lstlisting}

This attack first \fnc{malloc}s a block of memory, receiving a capability with
a bounds of 256 bytes (line 1). We fill the block of memory up with data so
that we can later test the success of the attack (lines 2 and 3). We then
\fnc{realloc} the block down to a single byte, receiving back a capability
whose bounds are 1 byte\footnote{Some allocators return bigger bounds, but
we ignore that possibility for now.} (line 5).
At this point, we expect to have permanently lost access to the values written to bytes 2-255 (inc.)
in lines 2 and 3. If we then \fnc{realloc} the block back to
its original size we should not have access to the values written to bytes
2-255 (inc.). However, allocators using the optimisation above will often
return a capability that covers the same portion of memory as the original
block, without zeroing it, allowing us to read the original bytes out
unchanged.

It might seem merely undesirable for \fnc{realloc} to allow us access to the
original data, but in a capability system this attack is particularly
egregious, as it may allow us to read capabilities that a programmer thought
they were hiding from us. In other words, allocators subject to this attack
can give an attacker access to capabilities, which in turn may give them new abilities,
undermining the security of the entire software.

Mitigating this attack is relatively simple. When \fnc{realloc} shrinks a
block, any excess storage should be zeroed. Note that we consider this safer
than the seemingly similar alternative of zeroing excess storage when
\fnc{realloc} enlarges a block, because this implies a delay in zeroing that
might allow other attacks to read data unexpectedly.


\subsection{\escperms: Escalate Permissions}

In situations where an allocator uses a `super' capability (as seen in
e.g.~\autoref{narrowwiden}), there is also the potential to upgrade a
capabilities permissions as shown in the following simple attack:

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(16);
assert(cheri_perms_get(arr)
  & CHERI_PERM_STORE));
arr = cheri_perms_and(arr, 0);
assert((cheri_perms_get(arr)
  & CHERI_PERM_STORE) == 0);
arr = realloc(arr, 16);
assert(cheri_perms_get(arr)
  & CHERI_PERM_STORE);
\end{lstlisting}

We first allocate a block (line 1) and then check that the capability returned
allows us to store data (\texttt{CHERI\_PERM\-\_STORE}) to that block (lines 2
and 3). We then deliberately remove the store permission (line 4), checking
that this permission really has been removed (lines 5 and 6). We then call
\fnc{realloc} without changing the blocks size and check whether we have
regained the ability to store data via the capability.


\subsubsection{Mitigations}

There are two ways of mitigating such an attack. The simplest one is to AND
the output capability's permissions with the input capability's permissions:
doing so guarantees that the output capability has no more permissions
than the input capability.

However, in some cases, one should consider validating the input capability to
decide whether any action should be possible. For example, if handed a
capability whose address is genuinely an allocated block, but where the
capability has the read and write permissions unset, should \fnc{realloc}
refuse to reallocate the block? Perhaps \fnc{realloc} should check that
the capability handed to it has exactly the same permissions as the
capability handed out by the most recent \fnc{malloc} or \fnc{realloc}?
There are probably no universal answers to all possibilities, but some may be
easier to rule upon than others.


\laurie{the rest after this still needs editing}

\subsection{\narrowwiden: Narrowing then widening}

When working with allocated memory, we are free to \fnc{realloc} a previously
\fnc{malloc}ed chunk of memory to whatever arbitrary size we required. However,
in the world of capabilities, this becomes a slightly tricky issue.
Capabilities themselves are intrinsically monotonically decreasing. As such,
``widening'' a capability needs to be handled differently than increasing the
bounds of that capability, as that is impossible.  Nevertheless, current memory
allocator do support increasing the bounds of a fnc{malloc}ed capability, as
expected. However, this might inadvertently reclaim secrets that were thought
to be hidden via clever use of capability bounds.

CheriBSD's default \fnc{realloc} is subject to this problem. The following
code executes successfully, with the capability returned by \fnc{realloc}
giving access to the same range of memory as the original \fnc{malloc}. Note
that \fnc{realloc} does not move, or scrub, memory in such a case. Thus, if
the user expected the setting of bounds to protect a secret, this code will not
give the protection expected.

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(256);
for (uint8_t i = 0; i < 255; i++)
  arr[i] = i;
arr = realloc(arr, 1);
assert(cheri_tag_get(arr) &&
  cheri_length_get(arr) >= 1);
arr = realloc(arr, 256);
for (uint8_t i = 0; i < 255; i++)
  assert(arr[i] == i);
\end{lstlisting}


\subsubsection{Mitigations}

In the specific example above, \fnc{realloc} should scrub memory when the
size of a memory block is being narrowed. However, this may not be appropriate
in all cases, particularly where capability bounds narrowing is being used to
hide a secret from another compartment. In such cases, code which can widen a
capability's bounds must be carefully audited.


\subsection{\escperms: Allocator Optimisations can Cause
Permissions Escalation}


\subsection{\myundef: Authentic capabilities from undefined behaviour}

It is easy to assume that authentic capabilities can only be derived if one
follows CHERI-C's
\andrei{This is the first and only reference to this ``CHERI-C''}
rules correctly. However, it is possible for an attacker to use undefined
behaviour to derive authentic capabilities. Consider the following code:

\begin{lstlisting}[language=C]
uint8_t *c1 = malloc(16);
ptraddr_t c1_addr = cheri_address_get(c1);
uint8_t *c2 = cheri_bounds_set(c1, 8);

free(c2);
uint8_t *c3 = malloc(16);
assert(cheri_tag_get(c3) && cheri_length_get(c3) == 16);
assert(cheri_address_get(c3) == c1_addr);
\end{lstlisting}

In this example, we first derive a capability \emph{C1} with bounds of 16 bytes
(line 1) before deriving a narrower capability \emph{C2} from it (line 3). It
is then possible that after \fnc{free}ing the block of memory addressed by \emph{C1}\andrei{example frees C2, actual code sets C1 to NULL and frees C2},
a subsequent \fnc{malloc} of 16 bytes returns a
capability \emph{C3} that is identical to \emph{C1}. This attack relies
on the underlying memory allocator reusing memory blocks, which many do in a
predictable fashion: this example runs successfully on CheriBSD\andrei{jemalloc?} (as of
2021-08-19).

Interestingly, C's pointer provenance rules mean that, after the code above has
executed, using \emph{C1} is no longer defined behaviour. Although this will not
trouble an attacker, who will find that most programs still execute as expected
and who now has a capability \emph{C3} giving the same access as \emph{C1}.


\subsubsection{Mitigations}

There are no general mitigations for \myundef. For the particular concrete
example, a partial mitigation is for \fnc{free} to scrub memory so that, at
least, whatever was present in the buffer cannot be read by the attacker: however,
since the attack has in effect `aliased' the capability, future writes can be
observed and tampered with by the attacker.

A more complete mitigation for the concrete example is for \fnc{free} to
revoke all references to the capability. In other words, CHERI allows one to
scan memory looking for all capabilities with bounds encompassing an address
$p$ and render them inauthentic~\cite{xia29cherivoke}. In this case, this
means that the original code will then fail with a \texttt{SIGPROT} when it
tries to dereference \emph{C1}, downgrading the security leak into a
denial-of-service. However, scanning the stack and heap in order to perform
revocation is not likely to be a quick operation.


\subsection{\overlap: Returning capabilities whose bounds overlap with another block's}
\label{sec:overlap}

Capabilities have high and low bounds, which are a strong enforcement mechanism
for restricting the region of memory that the capability can access for
reading and writing. However, while small bounds can be precisely represented,
large bounds are over-approximated, raising the possibility of the capability
for one memory block having bounds which overlap with that of another nearby
memory block. For example, we expect that the following code never succeeds\andrei{Meaning the assert never triggers?}:

\begin{lstlisting}[language=C]
void *b1 = malloc(size);
void *b2 = malloc(size);
assert(
  cheri_base_get(b1) >= cheri_base_get(b2) &&
  cheri_base_get(b1) <
    cheri_base_get(b2) + cheri_length_get(f2)
);
\end{lstlisting}

The underlying issue is that capabilities have to be able to cover the full
span of virtual memory without having enough bits to do so precisely. For
example, Morello's capabilities have 31 bits to express the bounds for a 64-bit
address space. Modern CHERI systems use `CHERI
Concentrate'~\cite{woodruff19chericoncentrate} to encode bounds. A good analogy
is that CHERI Concentrate is similar to IEEE 754 floating point numbers: the wider
the bound, the less accurately it will be represented. When a desired length
cannot be precisely represented, the next largest precisely representable
length is used in the bound. On Morello, 16,385 bytes is the smallest bound
which can not be precisely represented in a capability, and which is thus
rounded up to the next representable bound (in this case 16,392\footnote{For
CHERI RISC-V the first unrepresentable length is 4,097 bytes, which is rounded
up to 4,104.}).


\subsubsection{Mitigations}

There are three approaches that can ensure that narrowing bounds does not cause
secrets to be leaked.

First, one can check whether the narrowed bounds do/would capture only the
desired region of memory and if they don't/wouldn't, move the secret data to a
(probably new) non-overlapping region of memory. One can check whether bounds
will be adequately narrowed in advance using
\fnc{cheri\_representable\_length} or retrospectively by querying the
narrowed capability with \fnc{cheri\_length\_get}.

Second, one can lay out memory in advance such that, no matter what imprecise
bounds are used, secrets will not leak. In essence, this requires adding
padding to each object to take account of imprecise bounds. One could rewrite
\fnc{array\_with\_hidden\_secret}\andrei{Don't see another reference to this function} using this technique, provided that the
number of secret items at the end of the array does not vary after array
creation time.

These two approaches have different costs. The first approach requires users
only to pay for the cost of wasted memory if it is needed. However, at best
this introduces unexpected pauses as memory is allocated and copied. At worst,
this approach is infeasible --- one cannot, for example, easily move the
\emph{n}th element of a contiguous array because it is too big to be
represented with precise bounds. The second approach, in contrast, has fixed
up-front costs, but requires wasting memory for every object, even if no
future capability will ever have bounds covering it.

Third, one can abort execution if bounds cannot be precisely represented. The
\fnc{cheri\_bounds\_set\_exact} is a `safe' variant of
\fnc{cheri\_bounds\_set} which raises an error if bounds cannot be precisely
represented. We would prefer to see this be the standard bounds-setting
function, with a \fnc{cheri\_bounds\_set\_unsafe} variant allowing the
programmer to bypass bounds precision checks (because they are confident that
either: their bounds request can be precisely represented; or their code works
correctly with any resulting imprecision).

\jacob{Notably, occurrences of this pattern in real code will (as we've seen) be
much less obvious, and very hard to spot in code reviews. We could really do
with a helper that tests whether or not a hypothetical access would be
permitted, so we can write assertions in our \texttt{realloc} implementation, etc.}
\laurie{what would such a helper function look like?}

\subsection{Failed attacks}

In~\autoref{tab:atks}, there are a number of entries indicated by $\oslash$.
These entries indicate attacks that have failed due to various reasons on the
specified allocator. We discuss each of these failures in turn:
\begin{description}
    \item[\overlap over both bump allocators] This particular test allocates
        much more memory than our naive allocator implementations have been
        designed to handle, leading to a quick out-of-memory issue.
    \item[\narrowwiden cap over CHERI-aware bump allocator] \andrei{investigating}
    \item[\overlap over \memalloc{snmalloc-cheribuild}] The attack triggers a
        \texttt{SIGPROT} during an allocation. As this particular allocator is
        an older version of \memalloc{snmalloc-repo}, in which the issue is not
        present, we attribute the failure due to a bug, which was later fixed.
    \item[\escperms over non-CHERI-aware bump allocator] Our naive
        \fnc{realloc} implementation performs a \fnc{memcpy} of \texttt{size}
        bytes from the old memory block to the new one, where \texttt{size} is
        the \fnc{realloc} amount. This is done to preserve the original data,
        as we do not store metadata regarding the original allocation size. As
        such, due to tightening the bounds before widening them, we trigger a
        \texttt{SIGPROT} during the widening process, essentially having CHERI
        capture this implementation bug.
\end{description}

\subsection{Capability overflow}

\laurie{is this possible?}
\jacob{Not when used in the obvious way (e.g. dereferencing), but extreme
(65-bit) bounds behave in non-portable ways when queried explicitly, e.g.
saturating on Morello, and this isn't obvious in the CHERI API\@. This makes
manually testing the bounds difficult.}
\laurie{interesting! can we make a simple code example which shows this?}
\jacob{Yes, if there's time!}


\section{Performance}
\label{performance}

Our measurements on Morello hardware show a performance penalty on most
`purecap' benchmarks (compared with a `hybrid' baseline).
\jacob{We should quantify this with one of our graphs.}
Although the relative performance of purecap code is of great interest, there
are significant differences between contemporary hybrid and purecap workloads
that make a fair comparison difficult. Recall that the principle difference
between the purecap and hybrid ABI is that C pointers are capabilities in
purecap, but addresses (by default) in hybrid workloads. This also extends to
the stack pointer, and other ABI details not usually visible to the C language.

Many factors affect the overall performance of purecap allocators:

\begin{itemize}
  \item Hardware pointer operations (including arithmetic, loads and stores)
    have different semantics for capabilities, and may show performance
    difference.
  \item Capabilities are larger than addresses, and will exert greater pressure
    on caches and related system resources.
  \item Hybrid C compilers are likely to inherit many optimisations from the
    mature, capability-unaware compilers on which they are based. However, we
    expect purecap toolchains to be much less mature, and therefore more likely
    to miss possible optimisations.
  \item Security-related behaviours of purecap code (such as setting bounds on
    allocations) requires extra work.
  \item The purecap ABI design may make some common optimisations difficult.
    Many (or all) of these might be important for maintaining the desired
    security properties.
\end{itemize}

To an extent, some of the above affect capability-aware hybrid allocators too,
for example in comparison with a capability-unaware baseline. For example, a
hybrid \fnc{memcpy} has to preserve capabilities, and so requires a slightly
different implementation than the true baseline. However, we were not able to
measure any performance difference in preliminary tests, and so we focussed our
analysis on purecap and hybrid.
\jacob{Do we have data to back this up?}

\subsection{Hardware pointer operations}

To attempt to rule out (or account for) low-level hardware performance
variation, we wrote a series of very simple microbenchmarks, each designed to
reveal low-level differences:

\begin{itemize}
  \item \texttt{00-factorial-asm-minimal} is a tail-recursive factorial
    implementation, used as a control. This does not use capabilities (or the
    stack), and should behave identically on hybrid and purecap.
  \item \texttt{01-factorial-asm-minimal} is similar, but uses an indirect
    tail call, to attempt to measure any fundamental overhead in executing a
    capability.
  \item \texttt{99-busy-loop} is an empty C loop, to act as another control.
    The C loop uses no capabilities, and compiles to identical code for both
    hybrid and purecap.
\end{itemize}
\jacob{TODO: Test pointer arithmetic too.}

In addition, we included some benchmarks that (for practical reasons) we wrote
in C, and therefore are influenced by the ability of the C compiler to optimise
them:

\begin{itemize}
  \item \texttt{10-random-graph-walk-l1} performs a (C) random walk through a
    graph that fits in the L1 D cache, to attempt to measure any fundamental
    overhead in reading from a capability. Note that the purecap workload has a
    smaller number of graph nodes, since each node is larger.\jacob{TODO:
    Confirm the L1 cache size.}
  \item \texttt{11-random-graph-walk-fixed} is the same, but keeping the number
    of nodes constant. We picked 16384 nodes because this is the first
    power-of-two working set size at which the hybrid and purecap variants start
    to perform differently.
\end{itemize}

\jacob{TODO: Analysis}

\subsection{Cache pressure}

\jacob{Include and describe PMU results.}

\subsection{Purecap ABI difficulties}

We have observed some toolchain behaviours that differ between hybrid and
purecap. For example, this is a store (of zero) to a global variable in Morello
hybrid:

\begin{lstlisting}
    adrp x8, #+0x20000
    str xzr, [x8, #2472]
\end{lstlisting}

In that case, the \texttt{adrp} combined with the \texttt{str} offset locate
the global, and the store can write to it directly. However, the purecap ABI
requires another level of indirection in order to obtain a capability with
tight bounds:

\begin{lstlisting}
    adrp c1, #+0x10000
    ldr c1, [c1, #3776]
    str xzr, [c1]
\end{lstlisting}

Behaviours of this sort may be required (or at least be beneficial) under the
purecap security model, and may therefore be difficult to optimise. However, we
have completed neither security nor performance analysis for the examples we've
seen.

\subsection{Toolchain maturity}

\jacob{TODO: Code examples.}

\subsection{Security behaviours}

\jacob{TODO: All the scbnds instructions. These are important for security.}

\section{Allocator Performance Study}
%% Glasgow contribution here

This section analyses the runtime performance of various
CHERI memory allocator implementations when linked against a
set of compute- and memory-intensive benchmarks written in C.
The selected benchmarks are listed in~\autoref{tab:benchmarks},
drawn from the \emph{mimalloc-bench} test suite \cite{leijen19mimalloc}
chosen for their minimal library dependences, along with other common pointer-intensive
workloads \cite{boehm14artificial,richards99bench} that are frequently used for allocator performance evaluation.

\begin{table}
  \begin{center}
    \begin{tabular}{l|l|l}
      \emph{name} & \emph{source} & \emph{character} \\ \hline
      barnes & mimalloc & floating-point compute \\
      binary-tree & boehm & alloc, pointer chasing \\
      cfrac & mimalloc & alloc, int compute \\
      espresso & mimalloc & alloc, int compute \\
      glibc-simple & mimalloc & alloc \\
      %glibc-thread & mimalloc & alloc, multi-thread \\
      mstress & mimalloc & alloc \\
      richards & richards & pointer chasing \\
      %rptest & mimalloc & \dejice{alloc, multi-thread} \\
      %xmalloc & mimalloc & alloc, multi-thread \\ \hline
    \end{tabular}
  \end{center}
  \caption{\label{tab:benchmarks}Benchmarks used for CHERI allocator performance evaluation}
\end{table}

For each benchmark, we compile \emph{hybrid} (i.e.\ with no capability support) and
\emph{purecap} (i.e.\ using capabilities) binaries at O3 optimization level with the Morello LLVM toolchain.
We use \texttt{LD\_{}PRELOAD} to link with the various memory allocators.
We measure execution times for each benchmark (hybrid and purecap variants) with
each allocator on CheriBSD and report geometric mean slowdown across the benchmarks
relative to the platform default allocator which is a CHERI-extended version of \emph{jemalloc}.
Figure FIXME presents results for this experiment, showing that \jeremy{the majority of allocators are significantly slower than jemalloc (presumably because they are less optimized)}.

\begin{figure*}
  \begin{center}
    \includegraphics[width=\textwidth]{fig/jemalloc_bm_overall.pdf}
  \end{center}
 \caption{\label{fig:eval jemalloc}Normalized performance characteristics of purecap \texttt{jemalloc}}
\end{figure*}

For the remainder of this performance analysis, we focus exclusively on jemalloc since it is the default allocator for CheriBSD. We attempt to quantify the overhead of deploying capabilities with jemalloc in our memory-intensive benchmark workloads.
As above, each benchmark is compiled as \emph{hybrid} and \emph{purecap} binaries with \texttt{-O3} optimization levels
and the geometric mean of 30 execution runs are used for evaluation. 
When looking at individual benchmark performance, it is clear that the slowdown is highly dependent on the nature of each workload.
Figure \ref{fig:eval jemalloc}  shows the relative slowdown of the purecap
binaries for each benchmark with jemalloc, relative to the hybrid binaries.
Notice which benchmarks have highest relative slowdowns - binary trees, cfrac, espresso, mstress - highly allocation intensive. Also richards - which is \emph{not} allocation intensive but performs many pointer-chasing operations.

Next we considered the hardware performance counter metrics for these executions, using the \texttt{pmcstat} tool on CheriBSD. Again, we report purecap results relative to the corresponding hybrid results. We note large overheads in memory access \jeremy{what else?}
indicating that there is significantly increased pressure on the memory system due to capability values being twice the size of raw pointers.
\jeremy{also look at RSS sizes}


\jeremy{should we report our correlation stats, showing which performance counters correlate with execution time?}


Finally we considered the dynamic instruction counts for
these executions, categorizing instructions based on their
opcode types (following the classification from the Arm index-by-opcode in the Morello architecture reference manual - cite).
We generated instruction counts using the Morello QEMU emulator with a custom plugin, and validated a subset of these results by cross-checking them against the Arm FVP emulator for Morello.
Instructions captured are user mode instructions (i.e.\ excluding kernel activity) during benchmark execution
(i.e.\ excluding any OS boot activity).
Figure FIXME shows the results, with purecap benchmark results presented relative to hybrid dynamic instruction counts.
For the majority of benchmarks, we see that the pointer arithmetic (which in hybrid mode is captured as data processing) is now morello arithmetic, involving capabilities. Similarly, some load and store operations are now morello operations, loading and storing capabilities.
We notice that sometimes there is an overall increase in loads and stores for purecap, possibly caused by immature compiler code generation for Morello.
The `morello misc' overhead involves capability bounds checks, tag checks, etc --- which are intrinsic features of
CHERI. This is inescapable overhead, additional instructions that must run to support capability-aware execution. In general, this overhead is within \jeremy{XXX 10?? } \% of the total instruction count. 


\section{Conclusions}

It is beyond the
scope of this paper to ascertain whether these vulnerabilities are because the
allocators have not yet been fully adapted to CHERI or whether the necessary
adaptations to the allocator are impractical.

CHERI allocator ports don't take full advantage of the new secure features. Is it difficult to backport CHERI features onto legacy allocators? Which allocator does best and why?
Do we actually need a custom allocator, created specifically for CHERI?

Performance results are difficult to generalize, given we are working with an experimental architecture and a relatively immature software ecosystem / compiler toolchain. However we draw the following high-level conclusions from our performance analysis. CHERI does have a significant impact on memory access, particularly for pointer-intensive workloads. Careful micro-architectural and compiler optimizations are required here.
The instruction execution overhead of CHERI is not unreasonable - quote geometric mean figures. It's a worthwhile price to pay for improved runtime security of
legacy C workloads.

Note - ongoing performance analysis and optimization from Arm / CHERI team.
Also note other security and performance benefits of CHERI (compartmentalization) that we have not considered at all in this study.

% \textbf{Acknowledgements:} We thank Ruben Ayrapetyan and David Chisnall for
% comments. This work was funded by the Digital Security by Design (DSbD) Programme
% delivered by UKRI.


\bibliographystyle{plain}
\bibliography{bib}

\end{document}
