%&cheri_misidioms_preamble
\endofdump

\begin{document}
\maketitle

\begin{abstract}
We show that while it is relatively easy to adapt a memory allocator for
pure capability CHERI, it is hard to make it secure. We start with
a basic memory allocator and show the challenges involved in
adapting it to pure capability CHERI. We then
examine \laurie{four? five?} C memory allocators adapted for CheriBSD,
and show that they are subject to a number of simple attacks.
\end{abstract}


\section{Introduction}

CHERI provides and enforces hardware capabilities that allow programmers to
make strong security guarantees about their programs. Available CHERI hardware
has shown itself to be robust \laurie{cite} but programmers have to work out
how to best use hardware capabilities to achieve a desired level of security
in their software. Mistakes made in the use of capabilities can undermine
the security that software believes it possesses.

In this paper we show that it is surprisingly difficult to make a secure memory
allocator for pure capability CHERI. We first show the basic problems through
an example of a bump-pointer allocator
(Section~\ref{sec:bumppointerallocator}). We then examine several existing
allocators that have been ported to CheriBSD
(Section~\ref{sec:cheriallocators}). Finally we introduce and name several
simple `attacks' on pure capability memory allocators, showing that most of the
allocators are vulnerable to most of the attacks (Section~\ref{sec:atk}).


\section{Background}

We assume high-level familiarity with capabilities (\cite{levy84capability}
provides an approachable historical overview of capability architectures, and
may usefully be augmented by more recent work such as~\cite{miller06robust}),
CHERI generally (for a useful introduction to CHERI,
see~\cite{watson20cheriintroduction}),
the CHERI ABI~\cite{brooks19cheriabi},
and CHERI C (the dialect of C that CHERI defines)~\cite{watson20chericprogramming}.

Because CHERI has been developed over a number of years, and is explained over
a variety of documentation and papers, some concepts have more than one name.
We have found that some of those names make it difficult to talk, and sometimes
reason about, capability usage.
Unfortunately, we can think of no better solution to this than to propose our
own terminology.

We use the term \textit{CHERI} to refer to the `abstract capability machine'
that software can observe: that is, the combination of a capability hardware
instruction set, an ABI, and a user-facing library that exposes
capability-related functions.  We refer to specific hardware implementations by
their name (e.g.~Arm's `Morello' or `CHERI RISC-V').

CHERI capabilities are immutable and thus a new \emph{child} capability must be
derived from one or more \emph{parent} capabilities.  We refer to a capability
as \emph{authentic} (what CHERI calls `tagged' or `valid') if it has been
derived from its parents according to CHERI's rules, or \emph{inauthentic}
(what CHERI calls `untagged' or `invalid') otherwise. An inauthentic capability
may be duplicated at will but attempting to use an inauthentic capability in
any other way leads to a hardware exception.  A capability consists of an
\emph{address} in memory and a set of \emph{permissions} (only a subset of
which we consider in this paper). Amongst the permissions are \emph{bounds} -- the region of memory an
authentic capability is allowed to read/write from/to. A capability's bounds
are from a \emph{low} (inclusive) to a \emph{high} (exclusive) address and we
refer to `a bound of $x$ bytes' to mean a capability where
$\textit{high}-\textit{low}=x$.  If a capability's address is contained within
its bounds we refer to the capability as a whole as \emph{in-bounds} or
\emph{out-of-bounds} otherwise (see~\cite{woodruff19chericoncentrate} for an
explanation of why an authentic capability might have an out-of-bounds
address). Other permissions include boolean flags such as whether a capability
can read/write to memory addresses within its bounds.

As well as capabilities (which on Morello and CHERI RISC-V, for example, are
128 bits), CHERI also allows `traditional' single-width
pointers-as-addresses (which on Morello and CHERI RISC-V are 64-bit addresses)
to be used. Although CHERI processors allow both double-width capabilities and
single-width addresses-as-pointers to exist alongside each other at any time,
conventionally, a program which uses both traditional addresses and
capabilities is said to be operating in \emph{hybrid} mode while a program
which uses only capabilities is in \emph{pure capability} mode. In this paper
we concentrate exclusively on programs which operate in pure capability mode.


\section{A Basic Allocator for Pure Capability CHERI}
\label{sec:bumppointerallocator}

\laurie{jeremy: why don't we present the absolute most bare bones allocator
(including free and realloc i guess?) that supports purecap. this would bring
to life the coalescing stuff, if nothing else.}

\andrei{Instead of having an example allocator with a bunch of source code, how
about discussing general properties of modern allocators, and potential issues
in a CHERI context. Properties of interest: coalescing (monotonicity of
capabilities), free (need for "supercapability"/revocation), allocator metadata.}

\andrei{In addition, are there any further complications from being in a capability
environment that might affect an allocator, that we can think of?}

Memory allocators are core components in programming, lying at the border
between user-written programs and the OS kernel. Due to their necessity, a lot
of work has been put into optimising memory allocators. However, it is unlikely
that a memory allocator written without capabilities in mind will work on pure
capability CHERI without some adaption, due to the additional restrictions
imposed on the system by capabilities. In this section we present the salient
points of a simple pure capability allocator, emphasising how certain features
cannot work in the domain of capabilities.

\lstinputlisting[language=C, caption="Example of simple bump allocator", label=lst:bump_alloc]{code/bump_alloc.c}

The simplest memory allocator is an \emph{bump allocator}, illustrated
in~\ref{lst:bump_alloc}. The \fnc{alloc} function allocates a new section of
memory, while \fnc{realloc} allows the user to resize that memory, in case it
is needed. One advantage of using capabilities instead of traditional pointers
is the additional metadata held within the capability: we are able to get the
size of the original allocation by querying the bounds of the capability.

However, from a security perspective, after a successful \fnc{realloc} call,
there still exists in scope a capability pointing to some part of memory (i.e.,
the source \fnc{realloc} address). This small detail might evade the scrutiny
of a software developer working with such a simple allocator implementation,
leading to potential capability leakage, thus undermining the security
guarantees of capabilities.

There are abundant memory management design patterns that recur in a variety of
allocators. The addition of capabilities means the design of these features
must be scrutinized with capabilities in mind, in order to ensure minimal
burden is placed on developers. Jones et al.\ (cite GC handbook) outlines many
of these patterns from an implementation perspective. We discuss some of these
features we have identified to pose potential issues in a capability-aware
context.

\paragraph{Memory coalescing}

\andrei{can`t combine two capabilities into one, as they are monotonic -
affects performance. Could potentially use super-capabilities, which might
undermine security}

\paragraph{Allocator metadata}

\andrei{Some capability metadata is useful (e.g., sizes of allocated memories
for freeing), but additional potential metadata (e.g. ???) required by the
allocator / garbage collector would need to either be accessible in whatever
context, or lie in a privileged space}

\paragraph{Elevated permissions}

While perhaps not as specific as the previous two features, a memory allocator
must be able to perform operations at a higher privilege level than that of
normal user code. As capabilities enforce boundaries on what data can be
accessed or executed, it might break the expectation that memory allocation
functions can be called from user code, due to them affecting the overall
system.

\laurie{the rest of this comment is text moved from elsewhere that probably
should end up in this section
```Memory management code needs to be highly efficient, due to the frequency of
its execution. There are abundant memory management design patterns that recur
in a variety of allocators. Jones et al.\ (cite GC handbook) outlines many of
these patterns from an implementation perspective.  Due to the constraints of
CHERI, some of these memory management design patterns no longer work properly.
We review three such problematic patterns in this section.\emph{andrei: Enumerate
these 3, or paragraphs to emphasise which they are?}
Contiguous free buffers in managed memory should be merged to form a larger
buffer. This \emph{coalescing} pattern will fail on CHERI systems when
contiguous buffers have non-overlapping bounds, perhaps since the buffers are
derived from distinct \texttt{mmap} calls. \emph{andrei: Is it also the case that you
can't ``combine'' two capabilities to form a larger one?}
Memory managers often use simple bitwise arithmetic to synthesize addresses
efficiently, e.g.\ for iterating over fixed length buffers.
Such \emph{address synthesis} is not permitted in CHERI, since
valid metadata cannot be synthesized. Instead, calculations must be offset from
a capability with valid bounds. Finding the appropriate capability value is
generally less efficient than synthesizing it.
Some allocators use a \emph{header word} to store metadata for allocated
buffers. The header word is usually located one word before the user-visible
pointer begins. In CHERI, a problem is caused if the metadata word is
out-of-bounds for the user-visible pointer --- in which case the memory manager
needs to retain a separate, more privileged capability to access the metadata.
On the other hand, if the metadata is in-bounds for the user-visible pointer
then the metadata could be modified by user code, so CHERI cannot protect
against metadata corruption.'''}


\section{Existing CHERI Allocators}
\label{sec:cheriallocators}

\laurie{we need to add citations for the allocators where possible}

In this paper we examine the following memory allocators which have
been ported to CheriBSD: \textit{jemalloc} (the default allocator on CheriBSD),
Kingsley's \textit{BSD malloc} (\laurie{say something about it -- I don't even
know what it is and I'm a fully paid-up member of the BSD cult!}), and the two
unnamed allocators inside the libc alternatives \textit{newlib} and
\textit{Musl}. As a baseline we show a trivial \textit{bump-pointer
allocator} of our own devising.

At least two other memory allocators have been partly ported to CHERI: the
conservative garbage collector \textit{Boehm-Demers-Weiser} garbage collector
and the garbage collector inside the JavaScript virtual machine
\textit{JavaScriptCore}. To the best of our knowledge, neither port is
yet complete\andrei{I don't know much about gc's, but could we extract either
some design ideas, or even some functionality to add to our comparison?}.


\subsection{Existing CheriBSD allocators}
\label{sec:rqs}

\begin{table}[tb]
  \begin{center}
    \begin{tabular}{lllll}
      \toprule
      Allocator          & Version & SLoC & \multicolumn{2}{c}{Changed} \\
      \cmidrule(lr){4-5}
			 &       &        & LoC & \% \\
      \midrule
      jemalloc           &       & 39,059 & 116 & 0.30\% \\
      libmalloc-simple   &       & 680    & 43  & 6.32\% \\
      musl-libc          &       & 72,177 & 624 & 0.87\% \\
      newlib stdlib      &       & 26,041 & 83  & 0.32\%\\
      \bottomrule
    \end{tabular}
  \end{center}
  \label{tab:allocator_summary}
  \caption{The allocators we examined, their size in Source Lines of Code
  (SLoC), and the number of lines changed to adapt them for pure capability
  CheriBSD.\laurie{jeremy: we need to include the version number for each
  allocator (or, at least, a git hash or similar) so that people can
  reproduce our study.}\laurie{shouldn't bsdmalloc be in this table too?}}
\end{table}

How difficult is it to port a standard memory allocator to pure capability
CheriBSD? In this section we briefly examine several existing allocators.
Table~\ref{tab:allocator_summary} shows the allocators we consider, their size,
and the quantity and proportion of lines changed for the CHERI port.

As Table~\ref{tab:allocator_summary} shows, with the exception of the extremely
small libmalloc-simple, the pure capability CheriBSD ports require around
0.3-0.9\% of lines to be changed. This is an order of magnitude bigger than the
0.026\% lines changed for porting a desktop environment (including X11 and
KDE)~\cite{watson21assessing}. Given the lower-level, and thus more platform
dependent, nature of memory allocators, this relative difference seems
reasonable.

\laurie{i don't think we need to go into too much detail, but there is some
value IMHO in seeing how much of the static API different allocators use.
unfortunately i don't fully understand some of the original text so the rest of
this section from this point onwards needs careful consideration.}
A different proxy for porting complexity is to measure the number of different
CHERI API calls a ported memory allocator makes use of: broadly speaking, the
more of the CHERI API is used, the harder the porting effort was likely to have
been. Comparing across the allocators is somewhat muddied because there are two
\laurie{or three?} generations of the CHERI API \laurie{cheric.h, cheriintrin.h, and ... ?}


For system-level C programming, there are two
distinct CHERI APIs; this is due to the gradual evolution of
the software ecosystem over the past decade.
Older projects use the legacy \texttt{cheric.h}
header file, which exposes
57 CHERI functions to client code.
Two of the memory allocators we study, i.e.\ BSD malloc and jemalloc,
make use of this now-deprecated API.

A newer \texttt{builtin} CHERI API relies on LLVM-supported
\textit{compiler intrinsics}; there are 37 CHERI functions exposed
as intrinsic functions to client code.
\emph{why 20 fewer functions???}
Three of the memory allocators we study, i.e.\ newlib, Musl and trivial, make use of this \texttt{builtin} API.

\jacob{Where does \texttt{cheriintrin.h} fit into that? That's the preferred header today, isn't it?}

\jacob{I would guess that, for our purposes, these APIs overlap significantly,
amounting to simple renames in most cases. As part of this paper, should we
determine some sort of mapping to make the comparison easier? It's notable that
most API calls map to single CHERI instructions, which should make that mapping
easier.}

For each of the allocators, we inspect the source code
to count the number of distinct CHERI API calls. Note that if the same function is called in multiple source code locations, we only count it once.
This gives us a static measure of API coverage, for each allocator.
Table \ref{tab:rq1} shows the results, indicating that some allocators
have a broader spread of API calls.
\emph{What does this imply?}
\emph{What are the API calls doing?}


\begin{table}
  \begin{center}
    \begin{tabular}{ccrr}
    \toprule
      \textbf{allocator} & \textbf{API} & \textbf{\# API calls} & \textbf{API coverage} \\
      \midrule
      BSD malloc & cheric & 10 & 10/57 \\
      jemalloc & cheric & 11 & 11/57 \\
      Musl & builtin & ?? 22 or 6 ?? & 6/37 \\
      Newlib & builtin & 9 & 9/37 \\
      Trivial & builtin & 3 & 3/37 \\ 
      \bottomrule
    \end{tabular}
  \end{center}
  \caption{\label{tab:rq1}Coverage of CHERI API calls by various allocators}
\end{table}

\jacob{Ok, it's time for a difficult question, sorry! Basically, why are we
asking this question (\textbf{RQ1}), and what are we hoping to learn from it?
Static API usage is relatively easy to measure, but I'm not sure what~table~\ref{tab:rq1} tells me.
Dynamic usage is more difficult to measure, but has more obvious uses (e.g.~for performance analysis).
However, for \emph{security} analysis, we probably want to count uses with the
vague property of ``sequences that require careful thought''.
Typically, it seems, these are cases affected by bounds imprecision (where
simple tests might work even for invalid code). Such sequences require significant work to
implement, and carry a greater risk of vulnerability.
For example: the bump allocator required a sequence with a critcial order of
operations, buT it was probably only a handful of API calls in the end. I think there were similar sequences in BoehmGC too.
Section~\ref{sec:atk}~goes into more detail there (by counter-example).}
\andrei{I will second this. My first impression of RQ1 was that it's more to do with performance analysis.}

\jacob{What \emph{are} the most common API calls? That was what \textbf{RQ1} asked.}


%%%


\subsubsection{RQ4: Security Properties}
\label{sec:rqs:rq4}

The CHERI hardware extensions supports a variety of enforceable security
policies, but these require careful coding in software.
For memory allocators, CHERI offers the possibility of:
\begin{itemize}
\item lightweight software compartmentalization
\item temporal memory safety on the heap
\item spatial memory safety on the heap
\end{itemize}

When we survey existing CHERI memory allocators `in-the-wild', we
see that they currently provide support for spatial memory safety
on the heap.

In terms of the Common Weakness Enumeration (CWE, cite), all the allocators we
surveyed only mitigate CWE-125: Out-of-bounds Read and
CWE-787: Out-of-bounds Write, for dynamically allocated memory in the managed heap.

While this is stronger security than the equivalent non-CHERI versions of
these allocators, it is apparent that the CHERI allocators do not yet
take advantage of the full range of security mechanisms afforded by the
hardware. The next section goes on to explore potential security
vulnerabilities, mostly concerning temporal memory safety.


%%%%%


\section{Attacking Pure Capability Memory Allocators}
\label{sec:atk}

\begin{table}[t]
\begin{center}
\begin{tabular}{lcc}
  \toprule
Attack            & BSD simple & jemalloc \\
\midrule
narrow            & $\times$   & $\times$ \\
narrow\_realloc   & $\times$   & $\times$ \\
narrow\_widen     & $\times$   & $\times$ \\
privesc           & $\times$   & $\times$ \\
privesc2          &            & $\times$ \\
undef             & $\times$   & $\times$ \\
\bottomrule
\end{tabular}
\caption{Attacks which succeed on a given allocator are marked with a $\times$.}\andrei{Missing reference in text}
\end{center}
\end{table}

Conceptually, capability memory allocator attacks come in two
flavours\andrei{Only two, or only two we look at?}: the allocator can initially
hand out more permissions than expected; or can later be tricked in to
escalating a capability's privileges. In this section we start with three
serious attacks in the latter category, before detailing one minor `attack' in
the former category.

Formally speaking, CHERI capabilities
have monotonically decreasing privileges: in other words, when taking an existing
capability \emph{C1} as input, any capability \emph{C2} we derive from
\emph{C1} must have the same or fewer privileges. This may seem to make it
impossible to increase a capability's privileges, but software
components can store high privilege capabilities that can then be used to
give the appearance of returning a capability with increased privileges.

Functions which take in a low privileged capability and use a higher priviliged
capability\footnote{More formally, which take in a capability \emph{C1} and use
a capability \emph{C2}, where \emph{C2}'s set of priviliges are not a subset of
\emph{C1}'s privileges.} to perform calculations are at risk of privilege
escalation, and need to be carefully audited for bad idioms.


\subsection{Insufficient validation of the input capability}

Consider a memory allocator whose \texttt{realloc(cap, size)} function takes in
a capability \texttt{cap} whose address references the beginning of a block of
memory and returns a new capability whose address references the beginning of a
block of memory sufficient for storing \texttt{size} bytes.
A common \texttt{realloc} optimisation is to avoid moving memory if the
requested size fits within the `bucket' that the block already resides within.
We might then write a simple \texttt{realloc} as follows, assuming that we have
access to a high-privileged capability \texttt{MC} (e.g.~from
\texttt{mmap}~\cite{brooks19cheriabi}):

\begin{lstlisting}[language=C]
void *realloc(void *cap, size_of size) {
  if (size_of_bucket(cap) <= size) {
    // No need to reallocate.
    return cheri_bounds_set(
      cheri_address_set(MC, cap),
      size);
  } else {
    // Allocate a larger region of memory and copy
    // cap's contents over.
    ...
  }
}
\end{lstlisting}

\noindent The crucial optimisation is on line 2: if we already have enough
memory for the resized block, we simply return a new capability with the same
address as the original capability but with an increased upper bound. By
definition, reducing the size of a block means that it will always fit within
its existing bucket so the above optimisation is guaranteed to be correct.

Unfortunately this implementation of \texttt{realloc} is subject to privilege
escalation. For example, one can pass in a capability with narrow bounds and
receive back a capability with wider bounds:

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(16);
arr = cheri_bounds_set(arr, 8);
assert(cheri_tag_get(arr) && cheri_length_get(arr) == 8);
arr = realloc(arr, 16);
assert(cheri_tag_get(arr) && cheri_length_get(arr) == 16);
\end{lstlisting}

We first \texttt{malloc} a block, returning a capability \emph{C1} with bounds
$0\ldots{}n$ bytes (line 1). We then derive a new capability \emph{C2} with
bounds $0\ldots{}m$ bytes where $m < n$ (lines 2 and 3). We can then use
\texttt{realloc} to turn \emph{C2} back into \emph{C1} -- even though we had
lost access to \emph{C1} entirely!

This is not just a theoretical attack: our example \texttt{realloc} is effectively
a simplified version of CheriBSD's \texttt{realloc}, which (as of
2021-08-18\footnote{\href{https://github.com/CTSRD-CHERI/cheribsd/issues/1065}{https://github.com/CTSRD-CHERI/cheribsd/issues/1065}})
is vulnerable to this attack. Any capability whose bounds contain the base address of
a memory block can potentially have its privileges escalated, with
\texttt{realloc} returning a capability with the same permissions as the memory
system's main capability (as well as widening bounds, this allows
e.g.~upgrading a read-only capability to a read/write capability).


\subsubsection{Mitigations}

Privilege escalation occurs when a function fails to fully validate a possibly
lower-privileged capability correctly before using a higher-privileged
capability. Exactly what validation should occur is highly situation dependent,
which is why it is easy to get wrong.

In most, perhaps all, reasonable cases, the input CHERI capability should be
authentic and the capability's address in-bounds. However, as our
\texttt{realloc} attack shows, these two conditions are necessary but not
sufficient.  For example, one solution to the \texttt{realloc} attack is to
check that \texttt{cap}'s address refers to the start of a memory block and
that the capability's permissions are equal to the permissions returned by the
most recent \texttt{malloc} or \texttt{realloc} for that memory block. This
implies that the memory allocator must either store, or be able to derive by
other means, the capability returned by the most recent \texttt{malloc} or
\texttt{realloc} call.

However, it may be too restrictive to restrict \texttt{realloc} to precisely
equal capabilities: one may wish to allow \emph{compatible} capabilities. The
definition of compatibility is then crucial, particularly as different CHERI
architectures have different bounds representations and permissions.


\subsection{\narrowwiden: Narrowing then widening}

Assuming that a child capability with narrow bounds has been derived while
respecting the issues raised in \narrowingdoesnt
\andrei{should this come after the \narrowingdoesnt{} subsection?}
, it may seem that our issues with capability bounds are over. However, if one
later widens those bounds again, one may unintentionally leak secrets.

CheriBSD's default \texttt{realloc} is subject to this problem. The following
code executes successfully, with the capability returned by \texttt{realloc}
giving access to the same range of memory as the original \texttt{malloc}. Note
that \texttt{realloc} does not move, or scrub, memory in such a case. Thus, if
the user expected the setting of bounds to protect a secret, this code will not
give the protection expected.

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(256);
for (uint8_t i = 0; i < 255; i++) arr[i] = i;
arr = realloc(arr, 1);
assert(cheri_tag_get(arr) && cheri_length_get(arr) == 1);
arr = realloc(arr, 256);
for (uint8_t i = 0; i < 255; i++) assert(arr[i] == i);
\end{lstlisting}


\subsubsection{Mitigations}

In the specific example above, \texttt{realloc} should scrub memory when the
size of a memory block is being narrowed. However, this may not be appropriate
in all cases, particularly where capability bounds narrowing is being used to
hide a secret from another compartment. In such cases, code which can widen a
capability's bounds must be carefully audited.


\subsection{\myundef: Authentic capabilities from undefined behaviour}

It is easy to assume that authentic capabilities can only be derived if one
follows CHERI-C's
\andrei{This is the first and only reference to this ``CHERI-C''}
rules correctly. However, it is possible for an attacker to use undefined
behaviour to derive authentic capabilities. Consider the following code:

\begin{lstlisting}[language=C]
uint8_t *c1 = malloc(16);
vaddr_t c1_addr = cheri_address_get(c1);
uint8_t *c2 = cheri_bounds_set(c1, 8);

free(c2);
uint8_t *c3 = malloc(16);
assert(cheri_tag_get(c3) && cheri_length_get(c3) == 16);
assert(cheri_address_get(c3) == c1_addr);
\end{lstlisting}

In this example, we first derive a capability \emph{C1} with bounds of 16 bytes
(line 1) before deriving a narrower capability \emph{C2} from it (line 3). It
is then possible that after \texttt{free}ing the block of memory addressed by \emph{C1},
a subsequent \texttt{malloc} of 16 bytes returns a
capability \emph{C3} that is identical to \emph{C1}. This attack relies
on the underlying memory allocator reusing memory blocks, which many do in a
predictable fashion: this example runs successfully on CheriBSD (as of
2021-08-19).

Interestingly, C's pointer provenance rules mean that, after the code above has
executed, using \emph{C1} is no longer defined behaviour though this will not
trouble an attacker, who will find that most programs still execute as expected
and who now has a capability \emph{C3} giving the same access as \emph{C1}.


\subsubsection{Mitigations}

There are no general mitigations for \myundef. For the particular concrete
example, a partial mitigation is for \texttt{free} to scrub memory so that, at
least, whatever was present in the buffer cannot read by the attacker: however,
since the attack has in effect `aliased' the capability, future writes can be
observed and tampered with by the attacker.

A more complete mitigation for the concrete example is for \texttt{free} to
revoke all references to the capability. In other words, CHERI allows one to
scan memory looking for all capabilities with bounds encompassing an address
$p$ and invalidate the capability~\cite{xia29cherivoke}. In this case, this
means that the original code will then fail with a \texttt{SIGPROT} when it
tries to use \emph{C1}, downgrading the security leak into a denial-of-service.
However, scanning the stack and heap in order to perform revocation is not
likely to be a quick operation.


\subsection{\narrowingdoesnt: Narrowing a capability's bounds does not always fully narrow the capability's bounds}

\laurie{this isn't quite an attack in the same style as the others or, at
least, i couldn't tickle it in quite the same way. however, if there are
allocators which allocate `larger' chunks of memory contiguously, they could be
subject to this attack, as one block's bounds might overlap with a
predecessor/successor}

Capabilities have high and low bounds, which are a strong enforcement mechanism
for restricting the region of memory that the capability can access for
reading and writing. It is thus tempting to write code which hides secrets
(e.g.~allocator metadata) beyond the reach of a capability's bounds such as the
following:

% Adapted from narrow.c
\begin{lstlisting}[language=C]
uint8_t *array_with_hidden_secret(size_t size) {
    uint8_t *arr = malloc(size);
    return cheri_bounds_set(arr, size - 1);
}
\end{lstlisting}

\noindent We first \texttt{malloc} an array with enough space to store
\texttt{size} bytes (line 2) before creating a child capability
which prevents access to the array's final byte (line 3). We can verify this
behaviour by checking the returned capability's length, as in the following
code, which executes without error:

% Adapted from narrow.c
\begin{lstlisting}[language=C]
uint8_t *arr = array_with_hidden_secret(16385);
assert(cheri_length_get(arr) == 16384);
\end{lstlisting}

\noindent This idiom is insidious because it works correctly for the sorts of
`human friendly' sizes that programmers tend to test, but not for many other
sizes. As we saw above, creating a capability with a bound of 16384 bytes
prevents access to the array's last byte. However, making the array 1 byte
bigger undermines our expectations, as in the following code, which executes
without error:

% Adapted from narrow.c
\begin{lstlisting}[language=C]
uint8_t *arr = array_with_hidden_secret(16386);
assert(cheri_length_get(arr) == 16392);
\end{lstlisting}

\noindent Although we expected a capability with a bound of 16385 bytes, the
capability we receive has a bound of 16392 bytes. On Morello, 16385 bytes is
the smallest bound which
can not be precisely represented in a capability, and thus it has been been
rounded up to the next representable bound.

Practically speaking, this means that one cannot expect that narrowing a
capability's bounds precisely captures only the requested region of memory: in
general, the capability will provide access to more memory than one wishes.
Forgetting to take account of this, as in our example above, leads to secrets
being leaked.

The underlying issue is that modern CHERI systems use `CHERI
Concentrate'~\cite{woodruff19chericoncentrate}, an approach to representing
bounds that requires relatively few bits: for example Morello's capabilities
have 31 bits to express the bounds for a 64-bit address space. The trade-off is
simple: the fewer bits used for bounds, the smaller capabilities are (which is
good for memory use and performance), but the less precise the bounds that can
be represented. The encoding is ingenious, but hard to capture succinctly: in essence,
bounds use exponents, in similar fashion to IEEE 754 floating point
numbers: the wider the bound, the less accurately it will be
represented. When a desired length cannot be precisely represented, the next
largest precisely representable length is used in the bound.


\subsubsection{Mitigations}

There are three approaches that can ensure that narrowing bounds does not cause
secrets to be leaked.

First, one can check whether the narrowed bounds do/would capture only the
desired region of memory and if they don't/wouldn't, move the secret data to a
(probably new) non-overlapping region of memory. One can check whether bounds
will be adequately narrowed in advance using
\texttt{cheri\_representable\_length} or retrospectively by querying the
narrowed capability with \texttt{cheri\_length\_get}.

Second, one can lay out memory in advance such that, no matter what
imprecise bounds are used, secrets will not leak. In essence, this requires
adding padding to each object to take account of imprecise bounds. One could rewrite
\texttt{array\_with\_hidden\_secret} using this technique, provided that the
number of secret items at the end of the array does not vary after array creation
time.

These two approaches have different costs. The first approach requires users
only to pay for the cost of wasted memory if it is needed. However, at best
this introduces unexpected pauses as memory is allocated and copied. At worst,
this approach is infeasible --- one cannot, for example, easily move the
\emph{n}th element of a contiguous array because it is too big to be
represented with precise bounds. The second approach, in contrast, has fixed
up-front costs, but requires wasting memory for every object, even if no
future capability will ever have bounds covering it.

Third, one can abort execution if bounds cannot be precisely represented. The
\texttt{cheri\_bounds\_set\_exact} is a `safe` variant of
\texttt{cheri\_bounds\_set} which raises an error if bounds cannot be precisely
represented. We would prefer to see this be the standard bounds-setting
function, with a \texttt{cheri\_bounds\_set\_unsafe} variant allowing the
programmer to bypass bounds precision checks (because they are confident that
either: their bounds request can be precisely represented; or their code works
correctly with any resulting imprecision).

\jacob{Notably, occurrences of this pattern in real code will (as we've seen) be
much less obvious, and very hard to spot in code reviews. We could really do
with a helper that tests whether or not a hypothetical access would be
permitted, so we can write assertions in our \texttt{realloc} implementation, etc.}
\laurie{what would such a helper function look like?}


\subsection{Capability overflow}

\laurie{is this possible?}
\jacob{Not when used in the obvious way (e.g. dereferencing), but extreme
(65-bit) bounds behave in non-portable ways when queried explicitly, e.g.
saturating on Morello, and this isn't obvious in the CHERI API. This makes
manually testing the bounds difficult.}
\laurie{interesting! can we make a simple code example which shows this?}


\section{Conclusions}

\textbf{Acknowledgements:} We thank Ruben Ayrapetyan and David Chisnall for
comments.


\bibliographystyle{plain}
\bibliography{bib}

\end{document}
