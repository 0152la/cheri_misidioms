%&cheri_misidioms_preamble
\endofdump

\begin{document}


\begin{abstract}
\noindent
Several memory allocators have been ported to CHERI, a hardware capability
platform. In this paper we examine the security and performance of these
allocators. We show that the allocators are subject to simple security vulnerabilities,
which we categorise and explain. However, we show that current versions of LLVM
inconsistently optimise CHERI code, leading to a muddled performance picture.
\end{abstract}

\maketitle

\section{Introduction}

Capability Hardware Enhanced RISC Instructions
(CHERI)~\cite{watson20cheriintroduction} provides and enforces hardware
capabilities that allow programmers to make strong security guarantees
about the memory safety properties of their programs. However, capabilities are
not magic. Programmers must first decide which memory safety properties they
wish to enforce and then write their software in a way that enforces those properties.
It is easy for mistakes to creep in during either step, undermining
the security guarantees programmers believe their code possesses.

In this paper we examine one of the most fundamental software components:
memory allocators (henceforth just ``allocators''). Apart from some embedded
systems (which preallocate fixed quantities of memory), allocators are
ubiquitous, because they allow us to write programs that are generic over a
variety of memory usage patterns. Since allocators are used so frequently,
their security properties and performance are a major part of
the security properties and performance of software in general. In other words,
allocators with security flaws and/or performance problems have significant,
widespread consequences.

In this paper we examine allocators and CHERI from both security and performance
angles. We show that all CHERI allocators are subject to at least some simple attacks
that are likely to surprise reasonable programmers. To our surprise, we also
show that it is difficult to draw meaningful conclusions about performance:
we show that compilers on CHERI platforms do not optimise code as fully as one
would expect, leading to a muddled performance picture. We do not claim our
work is definitive, though it does suggest two things: that some allocators
undermine the security properties one might expect from software running on
pure capability CHERI; and that it is currently difficult to reason about the
performance of software on CHERI.

In essence the paper is split in two. First, we introduce the necessary
background: a brief overview of CHERI for those unfamiliar with it (\autoref{sec:cheri});
our running example, a simple bump allocator (\autoref{sec:bumppointerallocator}; and
a simple example of how allocators can be vulnerable, or invulnerable, to attack on CHERI
(\autoref{sec:atk}). Second, we introduce our experiments: the allocators
under consideration (\autoref{sec:cheriallocators}); our attacks (\autoref{sec:atks});
and our (attempted) performance evaluation (\autoref{performance}).


\section{CHERI Overview}
\label{sec:cheri}

In this section, we provide a simple overview of CHERI, and its major concepts.
Since CHERI has been developed over a number of years, and is explained over
a variety of documentation and papers, some concepts have acquired more than one name,
or names that subtly conflict with mainstream
software development definitions. We use a single name for each concept, sometimes
introducing new names where we believe that makes things clearer.

A \emph{capability} is a token that gives those who bear it \emph{abilities} to
perform certain actions. By restricting who has access to a given capability,
one can enforce security properties (e.g.~`this part of the software can
only read from memory address X to Y'). Capabilities have a long and storied history: \cite{levy84capability}
provides an approachable historical overview of capability architectures, and
may usefully be augmented by more recent work such as~\cite{miller06robust}.
A good first intuition is that CHERI is a modern update of this venerable
idea, updated with fine-grained permissions, and adapted to work on modern
processor instruction sets.

We use the term \emph{CHERI} to refer to the `abstract capability machine'
that software can observe: that is, the combination of a capability hardware
instruction set, an ABI (e.g.~\cite{brooks19cheriabi}), a user-facing library that exposes
capability-related functions, and a CHERI-aware language. (e.g.~CHERI C~\cite{watson20chericprogramming},
an adaption, in the sense of both extending and occasionally altering, of C).
We refer to specific hardware implementations by their name (e.g.~CHERI
RISC-V). In this paper, we mostly use Arm's `Morello' implementation, which is an
experimental ARMv8 chip extended with CHERI instructions.

\label{abilities}
Conceptually, a CHERI system starts with a `super' capability that has
the maximum set of abilities. Each
new \emph{child} capability must be derived from one or more \emph{parent}
capabilities. Child capabilities must have the same, or fewer, abilities than its
parent: put another way, capabilites' abilities monotonically decrease.
An \emph{authentic}\footnote{CHERI calls these
`tagged' or `valid' (and their inauthentic counterparts `untagged' or `invalid').}
capabilityÂ is one that has been derived from authentic parents according to
CHERI's rules. Attempts to create capabilities that violate CHERI's rules
cause the hardware to produce an \emph{inauthentic} result, guaranteeing
that capabilities cannot be forged. For example,
there is no user-space mechanism to set a capability as `valid'; only a child capability
derived, correctly, from valid parent capabilities can itself be valid.

A capability consists of an
\emph{address} (typically in memory \laurie{this clause sounds weird: are we trying to cover sealed capabilities or similar?}
\jacob{I didn't want that diversion, but didn't want to leave a gap for pedantry either.}
), and its abilities: a set of \emph{permissions} (only a subset of
which we consider in this paper);
and \emph{bounds}, the memory range on which
the capability can operate.

Permissions include the ability to read / write from memory.
A \emph{permissions check} is said to be successful if the permission required
for a given operation is provided by a given capability.

A capability's bounds
are from a \emph{low} (inclusive) to a \emph{high} (exclusive) address: when
we refer to a capability's bounds being of `$x$' bytes we mean that
$\textit{high}-\textit{low}=x$. An address is
\emph{in-bounds} for a given capability if it is wholly contained within the
capability's bounds, or \emph{out-of-bounds} otherwise; a capability is
in (or out) of bounds if its address is in (or out) of bounds
\footnote{See~\cite{woodruff19chericoncentrate} for an explanation of why an authentic
capability might have an out-of-bounds address.}.
A \emph{bounds check} is said to be successful if a given capability, address, or
address range, is in-bounds for a given capability.

Hardware that operates on a capability requires one or more of: an authenticity
check, a permissions check, or a bounds check. If a capability passes the
relevant checks, then the operation \emph{exercises} the capability. If a
capability fails the relevant checks then either: the hardware produces an
exception; or produces an inauthentic capability as a result (where this is not
in violation of the CHERI rules). For example, a failed attempt to exercise a capability for a
sealing operation on Morello produces an inauthentic result, rather than an
exception.

On Morello and CHERI RISC-V, capabilities behave as if they are 128 bits in
size, but also carry an additional bit that records the authenticity of each
capability: the authenticity bit can be read, and can be unset, but cannot
be set (i.e.~authentic capabilities must be created via hardware following
CHERI's rules).

CHERI also allows `traditional' single-width
pointers-as-addresses (which on Morello and CHERI RISC-V are 64-bit addresses)
to be used. Although CHERI processors allow both double-width capabilities and
single-width addresses-as-pointers to exist alongside each other at any time,
conventionally, a program which uses both traditional addresses and
capabilities is said to be operating in \emph{hybrid} mode while a program
which uses only capabilities is in \emph{pure capability} mode. In this paper
we concentrate exclusively on programs which operate in pure capability mode.

CHERI does not presuppose a particular Operating System (OS). While there is a
CHERI Linux port, at the time of writing the most mature OS for CHERI hardware
is CheriBSD, a FreeBSD descendent. In this paper we use CheriBSD exclusively.


\section{A Basic Pure Capability Allocator}
\label{sec:bumppointerallocator}

To illustrate how CHERI affects allocators, in this subsection we adapt a simple
non-CHERI aware allocator to become CHERI aware.

\begin{figure}[t]
\lstinputlisting[
  language=C,
  caption={
    A simple, but complete, non-CHERI aware, bump pointer allocator:
    \fnc{malloc} works as per normal; \fnc{free} is a no-op; and
    \fnc{realloc} always allocates a new chunk, copying
    over the old block.
    \fnc{\_\_builtin\_align\_up(v, a)} is an LLVM / clang primitive which rounds
    \texttt{v} up to the next smallest multiple of \texttt{a}: in this example,
    every memory block returned by \fnc{malloc} is sufficiently aligned to
    store a pointer.
  },
label=lst:bump_alloc1]{code/bump_alloc1.c}
\end{figure}

We start with a simple, complete, example of a C bump allocator in
Listing~\ref{lst:bump_alloc1}: \fnc{malloc} works as per normal; \fnc{free} is
a no-op; and \fnc{realloc} always allocates a new chunk of memory. The
allocator reserves a large chunk of memory using a single \fnc{mmap} call then
doles out chunks on each \fnc{malloc} / \fnc{realloc} calls. The bump pointer
moves through the \fnc{mmap}ed chunk until it reaches the upper limit, at which
point the allocator returns \texttt{NULL}s. \fnc{realloc} is intentionally
simplistic, but correct even when the block is increased in size.


\subsection{Adapting the Allocator to CHERI}

Perhaps surprisingly, our simple bump allocator compiles, and \fnc{malloc} runs
correctly, on CHERI systems too. As this suggests, CHERI C is largely source
compatible with normal C code, though pointer types are transparently `upgraded' to become
\emph{capability types} (on Morello occupying exactly twice the space of a
non-capability pointer). CHERI also implies changes in libraries: on CheriBSD,
for example, \fnc{mmap} returns a capability whose bounds are at least those of
the sized requested: from that capability our bump allocator derives new
capabilities that differ in their address, but not their bounds. In other
words, two calls to \fnc{malloc} will produce two capabilities that have the
same bounds, allowing anyone who possesses one of the capabilities to read and
write from any portion of \fnc{malloc}ed memory.

\begin{figure}[t]
\lstinputlisting[language=C,
  caption={
    Replacing the non-CHERI aware \fnc{malloc} from
    Listing~\ref{lst:bump_alloc1} with a CHERI-aware alternative
    using the idioms suggested in~{\cite[p.~30]{watson20chericprogramming}}.
    This \fnc{malloc} returns a capability whose bounds are sufficient
    to cover \texttt{size} bytes starting at the capability's address
    (calculated in lines 5--10),
    such that two callers to \fnc{malloc} cannot read or write from
    another block. We also have to update \fnc{realloc} so that it never tries to copy
    more data from the old block than the \texttt{ptr} capability gives
    it access to.
  },
    label=lst:bump_alloc2]
  {code/bump_alloc2.c}
\end{figure}

As this suggests, using CHERI without careful consideration may lead to
no additional security benefits of using CHERI. This then raises the question:
how should a secure `CHERI aware' allocator behave? There can be no single
answer to this question, but we believe that most programmers would expect
\texttt{malloc} to return a capability restricted to the block of memory
allocated. Listing~\ref{lst:bump_alloc2}
shows how to adapt \texttt{malloc} to do this.

The code to create the capability (using the idioms suggested
in~\cite[p.~30]{watson20chericprogramming}) is more involved than one might
first expect. The underlying cause is that there aren't, and cannot reasonably
be, enough bits in CHERI's bounds to precisely represent every possible address
and size. Modern CHERI therefore uses an encoding for bounds that allows small
bounds to be precisely represented, at the expense of larger bounds becoming
progressively less precise~\cite{woodruff19chericoncentrate}. On Morello,
the smallest bound that cannot be precisely represented is 16,385 bytes,
which is rounded up to 16,392 bytes\footnote{For CHERI RISC-V the first unrepresentable length is
4,097 bytes, which is rounded up to 4,104.}. Our capability aware
\texttt{malloc} thus has to ensure that both the capability's low and high
bound addresses are rounded down and up (respectively) in a way that ensures
that the address and size can be fully covered.

The two versions of our allocator have meaningfully different security properties,
even when we run both on a CHERI system. For example, consider this simple
C snippet which models a buffer overrun:

\begin{lstlisting}[language=C]
char *b = malloc(1);
b[0] = 'a';
b[1] = 'b';
\end{lstlisting}

On a non-CHERI system, or a CHERI system with \autoref{lst:bump_alloc1}
as an allocator, this snippet compiles and runs without error. However, with
the allocator from \autoref{lst:bump_alloc2} the code compiles but crashes with
a security violation when attempting to execute line 3, due to the tighter
capability bounds returned by its \texttt{malloc}, showing how CHERI can prevent
programmer errors becoming security violations.

However, just because a program compiles with CHERI C does not guarantee that
it will always run without issue: when run on CHERI, \fnc{realloc} in
Listing~\ref{lst:bump_alloc1} causes a hardware security exception if asked to
increase the size of a block. This occurs because \fnc{memcpy} tries to copy
beyond the bounds of the input capability (e.g.~if the existing block is 8
bytes and we ask to resize it to 16 bytes, \fnc{memcpy} tries to read
16 bytes from a capability whose bounds are 8 bytes). On a non-CHERI system,
this is not a security violation, but it is treated as one on CHERI. In
\autoref{lst:bump_alloc2} we thus provide an updated \fnc{realloc} which
uses \texttt{cheri\_length\_get} (which returns a capability's bounds
in bytes) to ensure that it never copies more data than the input capability's
bounds allow.


\section{How can a CHERI Allocator be Attacked?}
\label{sec:atk}

Our definition of CHERI in Section~\ref{sec:cheri} might suggest that software
running on CHERI hardware is invulnerable to attack. Alas, while CHERI gives us the
tools to make secure software, it is up to us to use them correctly --- and wisely.
We must decide which attack model is relevant to our software, and then write,
or adjust, the software, to withstand such attacks. Broadly speaking, allocators are
subject to spatial (e.g.~buffer overrun) or temporal (e.g.~a sequence of
function calls) attacks, and those attacks can be either on an allocators'
internals (e.g.~corrupting its private data-structures) or its interface
(e.g.~allowing code using the allocator to subvert expectations).

For example, consider this C snippet, which models a buffer overrun:

\begin{lstlisting}[language=C]
char *a = malloc(16);
char *b = malloc(16);
a[16] = 'c';
printf("%c\n", b[0]);
\end{lstlisting}

With the capability-unaware bump allocator from \autoref{lst:bump_alloc1} this
code compiles successfully and, when run, prints `\texttt{c}'\footnote{Note
that the example is in the realm of undefined behaviour, so a compiler could
compile this code to do something entirely different -- though, at the time of
writing, CheriBSD's LLVM does not do so.}. It does this because the bump
allocator allocates the second block immediately after the first in memory, so
writing 1 past the end of the first block in fact writes to the first byte of
the second block. However, with the
capability-aware allocator from \autoref{lst:bump_alloc2}, the program aborts
with a security exception when executing line 3.

Buffer overruns are so common in C code that we expect most people to consider
that part of their attack model: by extension, we believe that they
would expect a CHERI allocator to protect against such attacks. However, the
difference between Listings~\ref{lst:bump_alloc1} and~\ref{lst:bump_alloc2}
shows that such protection often requires careful adjustments of code to
take advantage of CHERI. As we
shall see later, it is not just our bump allocator that is subject to this
particular attack.


\section{CHERI Allocators}
\label{sec:cheriallocators}

In this paper we consider a number of allocators that are available for
CheriBSD. We first of all explain the set of allocators we use, before
exploring in more detail how the allocators have been adapted (if at all) for
CHERI.


\subsection{The Allocators Under Consideration}

A number of allocators are available for CheriBSD, installable via three
different routes: as part of the base distribution; via CheriBSD
\emph{packages}; or via external sources.  We examined allocators
available via all three routes. We excluded
allocators aimed only for debugging purposes (e.g.~\memalloc{ElectricFence}).
We then ran a simple validation test, \fnc{malloc}ing a block of memory,
copying data into the block, and then \fnc{free}ing the block: we
excluded any allocator which failed this test. We
document by which route we obtained all of the allocators we consider.

On that basis, the allocators we consider in this paper, and the names we use
for them for the rest of this paper, are as follows:
\begin{itemize}
\item \memalloc{jemalloc}, a modified version of the well-known
    \emph{jemalloc}~\cite{evans06scalable} allocator, is the default allocator
    for CheriBSD.

\item \memalloc{libmalloc-simple}\footnoteurl{https://github.com/CTSRD-CHERI/cheribsd/commit/e85ccde6d78d40f130ebf126a001589d75d60473}{23rd
    February 2023} is a port of the allocator present in FreeBSD`s
    \texttt{rtld-elf} utility\footnoteurl{https://github.com/freebsd/freebsd-src/blob/releng/4.3/libexec/rtld-elf/malloc.c}{
    23rd of February 2023}.

\item \memalloc{snmalloc-cheribuild} is an old version of
    \emph{snmalloc}~\cite{lietar19snmalloc} that can be installed via
    \texttt{cheribuild}. We found that this version to have several problems
    which we rectified by manually building a version from \emph{snmalloc}'s
    GitHub repository, which includes the \texttt{cheribuild} version, but has
    more recent updates. We term this latter version \texttt{snmalloc-repo}.

\item \memalloc{dlmalloc-cheribuild} is a version of the well-known
    \emph{dlmalloc} allocator~\cite{lea96memory} modified for CHERI,
    installable via \texttt{cheribuild}. CheriBSD's packages include
    \memalloc{dlmalloc-pkg64c} which is an unmodified version of dlmalloc. The
    ported version in \texttt{cheribuild} is based on the same as those in the
    packages, namely 2.8.6.

\item \memalloc{ptmalloc}~\cite{gloger06ptmalloc} is an extension of
    \memalloc{dlmalloc}, with added support for multiple threads.

\item \memalloc{bump-alloc-nocheri} is the simple, non-CHERI-aware bump
    allocator from~\autoref{lst:bump_alloc1}. Conversely,
    \memalloc{bump-alloc-cheri} is the CHERI aware version, presented
    in~\autoref{lst:bump_alloc2}.
\end{itemize}

\input{./data/results/slocs.tex}

\autoref{tab:allocator_summary} shows the version of each allocator we used.
We are aware of at least two other major memory allocators that have been
partly ported to CHERI: the \emph{Boehm-Demers-Weiser} conservative garbage
collector; and the \emph{WebKit} garbage collector. Since neither port is yet
complete, we have not included them in this paper.


\subsection{How Much Have the Allocators Been Adapted for CHERI?}
\label{sec:rqs}

As we saw from \autoref{lst:bump_alloc1}, simple allocators don't need to be
adapted for CHERI at all, though they then derive only minor security gains. In
practise, we expect most allocators to at least reflect the capability bound
changes of \autoref{lst:bump_alloc2}. \laurie{this is speculative: andrei,
jeremy, is this correct?} More sophisticated allocators will also tend to tend
to crash without at least some modifications. For example, as memory is freed
and reused, different sized blocks will sometimes be handed out by
\texttt{malloc}: if, as in \autoref{lst:bump_alloc2}, an allocator wants to
hand out correctly bounded capabilities, it will need to derive a new child
capability from a parent capability that has sufficiently wide bounds.

Understanding all of the CHERI modifications to all of the allocators under
consideration would lead to us not being able to see the forest for the trees.
Instead, \autoref{tab:allocator_summary} shows what proportion of an
allocator's LoC are `CHERI specific' by calculating the percentage of lines of code contained between
\texttt{\#ifdef CHERI} blocks. This count is an under-approximation, as some
code outside such \texttt{\#ifdef} blocks may also have been adapted, but it
gives a rough idea of the extent of changes. \laurie{jeremy: what tool did you use for this?}

With the exception of the extremely small \texttt{libmalloc-simple}, the pure capability CheriBSD allocators
have had around 0.3--0.9\% of their LoC adapted. Although this is a relatively small portion,
it is an order of magnitude bigger than the
0.026\% lines that were adapted when porting a desktop environment (including X11 and
KDE)~\cite{watson21assessing}. It is a reasonable assumption that the
lower-level, and more platform dependent, nature of allocators has
caused more LoC to be adapted.

A different proxy for the complexity of CHERI adaption is the number of CHERI API
calls a ported memory allocator makes use of: broadly speaking, the more of the
CHERI API is used, the `deeper' we might consider the adaption to be.
Comparing across the allocators is somewhat muddied because there are (at
least) three CHERI APIs in common use. We define these APIs as follows:

\begin{itemize}
  \item
The \emph{builtin} API consists of C functions provided as LLVM / Clang
extensions (e.g.~\texttt{\_\_builtin\_cheri\_base\_get}). There are 39 generic
CHERI functions, with Morello defining four more.

\item
The \emph{cheric.h} API is deprecated, but still frequently used,
providing 63 functions and macros (29 of \laurie{just the macros?} which are,
in essence, simple wrappers around the \emph{builtin} API).

\item
The \emph{cheriintrin.h} API is similar to, but supersedes, the \emph{cheric.h}
API. \laurie{can we explain why it supersedes \laurie{cheric.h}?} It provides
34 functions and macros, 30 of which map directly to the \emph{builtin} API.
\end{itemize}

\laurie{obvious question: why does cheriintrin.h exist if it's just wrapping
the builtins?!}

\laurie{table 2 doesn't always make sense to me: we say that e.g.~bump-alloc uses 10
API calls when Listing 2 suggests it uses more like 4. And we also say it uses
10 builtins, but we've just defined that as a separate API? And we say that
dlmalloc-cheribuild uses the builtin API which uses 10 API calls and 10
builtins?}\andrei{This table needs fixing}
For each of the allocators, we explain which of these three APIs it uses,
and the number of distinct API calls it makes.
Note that if the same function is called in multiple
source code locations, we only count it once.  This gives us a static measure
of API coverage, for each allocator. \autoref{tab:rq1} shows the results,
indicating that some allocators have a broader spread of API
calls.\andrei{Presumably left TODO>} \emph{What does this imply?} \emph{What
are the API calls doing?}

\input{./data/results/cheri_api.tex}


\section{The Attacks}
\label{sec:atks}

\input{./data/results/tests.tex}

In this section we introduce a number of `attacks' on CHERI allocators (1
spatial and 4 temporal) and then run those attacks on the allocators from
Section~\ref{sec:cheriallocators}. The results are shown in \autoref{tab:atks}. Many allocators,
including the default CheriBSD allocator, are vulnerable. It is beyond the
scope of this paper to ascertain whether these vulnerabilities are because the
allocators have not yet been fully adapted to CHERI or whether the necessary
adaptations to the allocator are impractical.
In the rest of this section we explain each attack in detail, giving
C code using the CHERI API when possible. We make use of the following
CHERI functions:

\setlength{\leftskip}{6pt}

\vspace{6pt}
\noindent\texttt{void *cheri\_address\_set(void *c, \\vaddr\_t a)}\\
Takes a capability \texttt{c} as input and produces a new capability
that is a copy of \texttt{c} except with the address \texttt{a}.
\texttt{vaddr\_t} is a CHERI C integer type that is guaranteed to be big enough
to represent addresses but, unlike \texttt{intptr\_t} is not big enough to
represent capabilities.

\vspace{6pt}
\noindent\texttt{void *cheri\_bounds\_set(void *c, \\size\_t s)}\\
Takes a capability \texttt{c} as input and produces a new capability
that is a copy of \texttt{c} except with bounds of size \texttt{s}.

\vspace{6pt}
\noindent\texttt{size\_t cheri\_length\_get(void *c)}\\
Returns the bounds of a capability \texttt{c}.

\vspace{6pt}
\noindent\texttt{\_Bool cheri\_tag\_get(void *c)}\\
Returns true if the capability \texttt{c} is authentic or false otherwise.

\setlength{\leftskip}{0pt}
Bounds or Permissions Escalation}

In the simple bump allocator of \autoref{lst:bump_alloc1}, \texttt{realloc} always
allocates a new block of memory. While this is always correct, it is inefficient,
in part because it requires copying part of the block's existing content. Performance
focussed allocators thus try to avoid allocating a new block of memory when
shrinking or maintaining a block's size, or if increasing the block's size does not
make it overwrite its nearest neighbour. The latter optimisation is dangerous
for a CHERI allocator.

To see the danger, consider the case where \texttt{realloc} wants to increase a
block in size, and there is sufficient room to do so without moving the block.
\texttt{realloc} needs to return a capability whose bounds encompass the new
(larger) size --- but such a capability cannot be derived from the input
capability, since doing so would require increasing a capabilities abilities
(see \pageref{abilities}). Thus the allocator needs access to a `super'
capability which it can use to derive a capability representing the new bounds.
Let us call the `super' capability \texttt{SC} and introduce a function
\texttt{size\_of\_bucket} which tells us the maximum space available for
the block starting at \texttt{ptr}:

\begin{lstlisting}[language=C]
void *realloc(void *ptr, size_of size) {
  if (size_of_bucket(ptr) <= size) {
    // No need to reallocate.
    return cheri_bounds_set(
      cheri_address_set(MC, cap),
      size);
  } else {
    // Allocate a larger region of memory
    // and copy the old contents.
  }
}
\end{lstlisting}

\noindent The crucial optimisation is on line 2: if we already have enough
memory for the resized block, we simply return a new capability with the same
address as the original capability but with an increased upper bound. By
definition, reducing the size of a block means that it will always fit within
its existing bucket so the above optimisation is guaranteed to be correct.

We can now observe two related attacks on this \fnc{realloc}, the first
of which we term \escbounds. We can pass in a capability with narrow bounds and
receive back a capability with wider bounds:

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(16);
arr = cheri_bounds_set(arr, 8);
assert(cheri_tag_get(arr) && cheri_length_get(arr) == 8);
arr = realloc(arr, 16);
assert(cheri_tag_get(arr) && cheri_length_get(arr) == 16);
\end{lstlisting}

We first \fnc{malloc} a block, returning a capability \emph{C1} with bounds
$0\ldots{}n$ bytes (line 1). We then derive a new capability \emph{C2} with
bounds $0\ldots{}m$ bytes where $m < n$ (lines 2 and 3). We can then use
\fnc{realloc} to turn \emph{C2} back into \emph{C1} -- even though we had
lost access to \emph{C1} entirely!

An important variant of this attack is \escperms, where the bounds are
set correctly, but other permissions (e.g.~read/write) are incorrectly changed:

\laurie{XYZ}

\subsubsection{Mitigations}

Privilege escalation occurs when a function fails to fully validate a possibly
lower-privileged capability correctly before using a higher-privileged
capability. Exactly what validation should occur is highly situation dependent,
which is why it is easy to get wrong.

In most, perhaps all, reasonable cases, the input CHERI capability should be
authentic and the capability's address in-bounds. However, as our
\fnc{realloc} attack shows, these two conditions are necessary but not
sufficient.  For example, one solution to the \fnc{realloc} attack is to
check that \fnc{cap}'s address refers to the start of a memory block and
that the capability's permissions are equal to the permissions returned by the
most recent \fnc{malloc} or \fnc{realloc} for that memory block. This
implies that the memory allocator must either store, or be able to derive by
other means, the capability returned by the most recent \fnc{malloc} or
\fnc{realloc} call.

However, it may be too restrictive to restrict \fnc{realloc} to precisely
equal capabilities: one may wish to allow \emph{compatible} capabilities. The
definition of compatibility is then crucial, particularly as different CHERI
architectures have different bounds representations and permissions.

\subsection{\narrowwiden: Narrowing then widening}

Assuming that a child capability with narrow bounds has been derived while
respecting the issues raised in \narrowingdoesnt (\autoref{sec:narrow}), it may
seem that our issues with capability bounds are over. However, if one later
widens those bounds again, one may unintentionally leak secrets.

CheriBSD's default \fnc{realloc} is subject to this problem. The following
code executes successfully, with the capability returned by \fnc{realloc}
giving access to the same range of memory as the original \fnc{malloc}. Note
that \fnc{realloc} does not move, or scrub, memory in such a case. Thus, if
the user expected the setting of bounds to protect a secret, this code will not
give the protection expected.

\begin{lstlisting}[language=C]
uint8_t *arr = malloc(256);
for (uint8_t i = 0; i < 255; i++) arr[i] = i;
arr = realloc(arr, 1);
assert(cheri_tag_get(arr) && cheri_length_get(arr) == 1);
arr = realloc(arr, 256);
for (uint8_t i = 0; i < 255; i++) assert(arr[i] == i);
\end{lstlisting}


\subsubsection{Mitigations}

In the specific example above, \fnc{realloc} should scrub memory when the
size of a memory block is being narrowed. However, this may not be appropriate
in all cases, particularly where capability bounds narrowing is being used to
hide a secret from another compartment. In such cases, code which can widen a
capability's bounds must be carefully audited.


\subsection{\myundef: Authentic capabilities from undefined behaviour}

It is easy to assume that authentic capabilities can only be derived if one
follows CHERI-C's
\andrei{This is the first and only reference to this ``CHERI-C''}
rules correctly. However, it is possible for an attacker to use undefined
behaviour to derive authentic capabilities. Consider the following code:

\begin{lstlisting}[language=C]
uint8_t *c1 = malloc(16);
ptraddr_t c1_addr = cheri_address_get(c1);
uint8_t *c2 = cheri_bounds_set(c1, 8);

free(c2);
uint8_t *c3 = malloc(16);
assert(cheri_tag_get(c3) && cheri_length_get(c3) == 16);
assert(cheri_address_get(c3) == c1_addr);
\end{lstlisting}

In this example, we first derive a capability \emph{C1} with bounds of 16 bytes
(line 1) before deriving a narrower capability \emph{C2} from it (line 3). It
is then possible that after \fnc{free}ing the block of memory addressed by \emph{C1},
a subsequent \fnc{malloc} of 16 bytes returns a
capability \emph{C3} that is identical to \emph{C1}. This attack relies
on the underlying memory allocator reusing memory blocks, which many do in a
predictable fashion: this example runs successfully on CheriBSD (as of
2021-08-19).

Interestingly, C's pointer provenance rules mean that, after the code above has
executed, using \emph{C1} is no longer defined behaviour though this will not
trouble an attacker, who will find that most programs still execute as expected
and who now has a capability \emph{C3} giving the same access as \emph{C1}.


\subsubsection{Mitigations}

There are no general mitigations for \myundef. For the particular concrete
example, a partial mitigation is for \texttt{free} to scrub memory so that, at
least, whatever was present in the buffer cannot read by the attacker: however,
since the attack has in effect `aliased' the capability, future writes can be
observed and tampered with by the attacker.

A more complete mitigation for the concrete example is for \texttt{free} to
revoke all references to the capability. In other words, CHERI allows one to
scan memory looking for all capabilities with bounds encompassing an address
$p$ and render them inauthentic~\cite{xia29cherivoke}. In this case, this
means that the original code will then fail with a \texttt{SIGPROT} when it
tries to dereference \emph{C1}, downgrading the security leak into a
denial-of-service. However, scanning the stack and heap in order to perform
revocation is not likely to be a quick operation.


\subsection{\overlap: Returning capabilities whose bounds overlap with another block's}
\label{sec:overlap}

Capabilities have high and low bounds, which are a strong enforcement mechanism
for restricting the region of memory that the capability can access for
reading and writing. However, while small bounds can be precisely represented,
large bounds are over-approximated, raising the possibility of the capability
for one memory block having bounds which overlap with that of another nearby
memory block. For example, we expect that the following code never succeeds:

\begin{lstlisting}[language=C]
void *b1 = malloc(size);
void *b2 = malloc(size);
assert(
  cheri_base_get(b1) >= cheri_base_get(b2) &&
  cheri_base_get(b1) <
    cheri_base_get(b2) + cheri_length_get(f2)
);
}
\end{lstlisting}

The underlying issue is that capabilities have to be able to cover the full
span of virtual memory without having enough bits to do so precisely. For
example, Morello's capabilities have 31 bits to express the bounds for a 64-bit
address space. Modern CHERI systems use `CHERI
Concentrate'~\cite{woodruff19chericoncentrate} to encode bounds. A good analogy
is that CHERI Concentrate is similar IEEE 754 floating point numbers: the wider
the bound, the less accurately it will be represented. When a desired length
cannot be precisely represented, the next largest precisely representable
length is used in the bound. On Morello, 16,385 bytes is the smallest bound
which can not be precisely represented in a capability, and which is thus
rounded up to the next representable bound (in this case 16,392\footnote{For
CHERI RISC-V the first unrepresentable length is 4,097 bytes, which is rounded
up to 4,104.}).


\subsubsection{Mitigations}

There are three approaches that can ensure that narrowing bounds does not cause
secrets to be leaked.

First, one can check whether the narrowed bounds do/would capture only the
desired region of memory and if they don't/wouldn't, move the secret data to a
(probably new) non-overlapping region of memory. One can check whether bounds
will be adequately narrowed in advance using
\fnc{cheri\_representable\_length} or retrospectively by querying the
narrowed capability with \fnc{cheri\_length\_get}.

Second, one can lay out memory in advance such that, no matter what imprecise
bounds are used, secrets will not leak. In essence, this requires adding
padding to each object to take account of imprecise bounds. One could rewrite
\fnc{array\_with\_hidden\_secret} using this technique, provided that the
number of secret items at the end of the array does not vary after array
creation time.

These two approaches have different costs. The first approach requires users
only to pay for the cost of wasted memory if it is needed. However, at best
this introduces unexpected pauses as memory is allocated and copied. At worst,
this approach is infeasible --- one cannot, for example, easily move the
\emph{n}th element of a contiguous array because it is too big to be
represented with precise bounds. The second approach, in contrast, has fixed
up-front costs, but requires wasting memory for every object, even if no
future capability will ever have bounds covering it.

Third, one can abort execution if bounds cannot be precisely represented. The
\fnc{cheri\_bounds\_set\_exact} is a `safe' variant of
\fnc{cheri\_bounds\_set} which raises an error if bounds cannot be precisely
represented. We would prefer to see this be the standard bounds-setting
function, with a \fnc{cheri\_bounds\_set\_unsafe} variant allowing the
programmer to bypass bounds precision checks (because they are confident that
either: their bounds request can be precisely represented; or their code works
correctly with any resulting imprecision).

\jacob{Notably, occurrences of this pattern in real code will (as we've seen) be
much less obvious, and very hard to spot in code reviews. We could really do
with a helper that tests whether or not a hypothetical access would be
permitted, so we can write assertions in our \texttt{realloc} implementation, etc.}
\laurie{what would such a helper function look like?}


\subsection{Capability overflow}

\laurie{is this possible?}
\jacob{Not when used in the obvious way (e.g. dereferencing), but extreme
(65-bit) bounds behave in non-portable ways when queried explicitly, e.g.
saturating on Morello, and this isn't obvious in the CHERI API\@. This makes
manually testing the bounds difficult.}
\laurie{interesting! can we make a simple code example which shows this?}
\jacob{Yes, if there's time!}


\section{Performance}
\label{performance}

Our measurements on Morello hardware show a performance penalty on most
`purecap' benchmarks (compared with a `hybrid' baseline).
\jacob{We should quantify this with one of our graphs.}
Although the relative performance of purecap code is of great interest, there
are significant differences between contemporary hybrid and purecap workloads
that make a fair comparison difficult. Recall that the principle difference
between the purecap and hybrid ABI is that C pointers are capabilities in
purecap, but addresses (by default) in hybrid workloads. This also extends to
the stack pointer, and other ABI details not usually visible to the C language.

Many factors affect the overall performance of purecap allocators:

\begin{itemize}
  \item Hardware pointer operations (including arithmetic, loads and stores)
    have different semantics for capabilities, and may show performance
    difference.
  \item Capabilities are larger than addresses, and will exert greater pressure
    on caches and related system resources.
  \item Hybrid C compilers are likely to inherit many optimisations from the
    mature, capability-unaware compilers on which they are based. However, we
    expect purecap toolchains to be much less mature, and therefore more likely
    to miss possible optimisations.
  \item Security-related behaviours of purecap code (such as setting bounds on
    allocations) requires extra work.
  \item The purecap ABI design may make some common optimisations difficult.
    Many (or all) of these might be important for maintaining the desired
    security properties.
\end{itemize}

To an extent, some of the above affect capability-aware hybrid allocators too,
for example in comparison with a capability-unaware baseline. For example, a
hybrid \fnc{memcpy} has to preserve capabilities, and so requires a slightly
different implementation than the true baseline. However, we were not able to
measure any performance difference in preliminary tests, and so we focussed our
analysis on purecap and hybrid.
\jacob{Do we have data to back this up?}

\subsection{Hardware pointer operations}

To attempt to rule out (or account for) low-level hardware performance
variation, we wrote a series of very simple microbenchmarks, each designed to
reveal low-level differences:

\begin{itemize}
  \item \texttt{00-factorial-asm-minimal} is a tail-recursive factorial
    implementation, used as a control. This does not use capabilities (or the
    stack), and should behave identically on hybrid and purecap.
  \item \texttt{01-factorial-asm-minimal} is similar, but uses an indirect
    tail call, to attempt to measure any fundamental overhead in executing a
    capability.
  \item \texttt{99-busy-loop} is an empty C loop, to act as another control.
    The C loop uses no capabilities, and compiles to identical code for both
    hybrid and purecap.
\end{itemize}
\jacob{TODO: Test pointer arithmetic too.}

In addition, we included some benchmarks that (for practical reasons) we wrote
in C, and therefore are influenced by the ability of the C compiler to optimise
them:

\begin{itemize}
  \item \texttt{10-random-graph-walk-l1} performs a (C) random walk through a
    graph that fits in the L1 D cache, to attempt to measure any fundamental
    overhead in reading from a capability. Note that the purecap workload has a
    smaller number of graph nodes, since each node is larger.\jacob{TODO:
    Confirm the L1 cache size.}
  \item \texttt{11-random-graph-walk-fixed} is the same, but keeping the number
    of nodes constant. We picked 16384 nodes because this is the first
    power-of-two working set size at which the hybrid and purecap variants start
    to perform differently.
\end{itemize}

\jacob{TODO: Analysis}

\subsection{Cache pressure}

\jacob{Include and describe PMU results.}

\subsection{Purecap ABI difficulties}

We have observed some toolchain behaviours that differ between hybrid and
purecap. For example, this is a store (of zero) to a global variable in Morello
hybrid:

\begin{lstlisting}
    adrp x8, #+0x20000
    str xzr, [x8, #2472]
\end{lstlisting}

In that case, the \texttt{adrp} combined with the \texttt{str} offset locate
the global, and the store can write to it directly. However, the purecap ABI
requires another level of indirection in order to obtain a capability with
tight bounds:

\begin{lstlisting}
    adrp c1, #+0x10000
    ldr c1, [c1, #3776]
    str xzr, [c1]
\end{lstlisting}

Behaviours of this sort may be required (or at least be beneficial) under the
purecap security model, and may therefore be difficult to optimise. However, we
have completed neither security nor performance analysis for the examples we've
seen.

\subsection{Toolchain maturity}

\jacob{TODO: Code examples.}

\subsection{Security behaviours}

\jacob{TODO: All the scbnds instructions. These are important for security.}

\section{Allocator Performance Study}
%% Glasgow contribution here

This section analyses the runtime performance of various
CHERI memory allocator implementations when linked against a
set of compute- and memory-intensive benchmarks written in C.
The selected benchmarks are listed in Table \ref{tab:benchmarks},
drawn from the \emph{mimalloc-bench} test suite \cite{leijen19mimalloc}
chosen for their minimal library dependences, along with other common pointer-intensive
workloads \cite{boehm14artificial,richards99bench} that are frequently used for allocator performance evaluation.

\begin{table}
  \begin{center}
    \begin{tabular}{l|l|l}
      \emph{name} & \emph{source} & \emph{character} \\ \hline
      barnes & mimalloc & floating-point compute \\
      binary-tree & boehm & alloc, pointer chasing \\
      cfrac & mimalloc & alloc, int compute \\
      espresso & mimalloc & alloc, int compute \\
      glibc-simple & mimalloc & alloc \\
      glibc-thread & mimalloc & alloc, multi-thread \\
      mstress & mimalloc & alloc \\
      richards & richards & pointer chasing \\
      rptest & mimalloc & ? \\
      xmalloc & mimalloc & alloc, multi-thread \\ \hline
    \end{tabular}
  \end{center}
  \caption{\label{tab:benchmarks}Benchmarks used for CHERI allocator performance evaluation}
\end{table}

For each benchmark, we compile \emph{hybrid} (i.e.\ with no capability support) and
\emph{purecap} (i.e.\ using capabilities) binaries at O3 optimization level with the Morello LLVM toolchain.
We use \texttt{LD\_{}PRELOAD} to link with the various memory allocators. We measure execution times for each benchmark (hybrid and purecap variants) with
each allocator on CheriBSD and report geometric mean slowdown across the benchmarks
relative to the platform default allocator which is a CHERI-extended version of \emph{jemalloc}.
Figure FIXME presents results for this experiment, showing that \jeremy{the majority of allocators are significantly slower than jemalloc (presumably because they are less optimized)}.

\begin{figure*}
  \begin{center}
    \includegraphics[width=\textwidth]{fig/jemalloc_bm_overall.pdf}
  \end{center}
 \caption{\label{fig:eval jemalloc}Normalized perfomance characteristics of purecap \texttt{jemalloc}}
\end{figure*}

For the remainder of this performance analysis, we focus exclusively on jemalloc since it is the default allocator for CheriBSD. We attempt to quantify the overhead of deploying capabilities with jemalloc in our memory-intensive benchmark workloads.
When looking at individual benchmark performance, it is clear that the slowdown is highly dependent on the nature of each workload.
Figure FIXME shows the relative slowdown of the purecap binaries for each benchmark with jemalloc, relative to the hybrid binaries.
Notice which benchmarks have highest relative slowdowns - binary tree cfrac, espresso, mstress - highly allocation intensive. Also richards - which is \emph{not} allocation intensive but performs many pointer-chasing operations.

Next we considered the hardware performance counter metrics for these executions, using the \texttt{pmcstat} tool on CheriBSD. Again, we report purecap results relative to the corresponding hybrid results. We note large overheads in memory access \jeremy{what else?}
indicating that there is significantly increased pressure on the memory system due to capability values being twice the size of raw pointers.
\jeremy{also look at RSS sizes}


\jeremy{should we report our correlation stats, showing which performance counters correlate with execution time?}


Finally we considered the dynamic instruction counts for
these executions, categorizing instructions based on their
opcode types (following the classification from the Arm index-by-opcode in the Morello architecture reference manual - cite).
We generated instruction counts using the Morello QEMU emulator with a custom plugin, and validated a subset of these results by cross-checking them against the Arm FVP emulator for Morello.
Instructions captured are user mode instructions (i.e.\ excluding kernel activity) during benchmark execution
(i.e.\ excluding any OS boot activity).
Figure FIXME shows the results, with purecap benchmark results presented relative to hybrid dynamic instruction counts.
For the majority of benchmarks, we see that the pointer arithmetic (which in hybrid mode is captured as data processing) is now morello arithmetic, involving capabilities. Similarly, some load and store operations are now morello operations, loading and storing capabilities.
We notice that sometoimes there is an overall increase in loads and stores for purecap, possibly caused by immature compiler code generation for Morello.
The `morello misc' overhead involves capability bounds checks, tag checks, etc --- which are intrinsic features of
CHERI. This is inescapable overhead, additional instructions that must run to support capability-aware execution. In general, this overhead is within \jeremy{XXX 10?? } \% of the total instruction count. 


\section{Conclusions}

CHERI allocator ports don't take full advantage of the new secure features. Is it difficult to backport CHERI features onto legacy allocators? Which allocator does best and why?
Do we actually need a custom allocator, created specifically for CHERI?

Performance results are difficult to generalize, given we are working with an experimental architecture and a relatively immature software ecosystem / compiler toolchain. However we draw the following high-level conclusions from our performance analysis. CHERI does have a significant impact on memory access, particularly for pointer-intensive workloads. Careful micro-architectural and compiler optimizations are required here.
The instruction execution overhead of CHERI is not unreasonable - quote geometric mean figures. It's a worthwhile price to pay for improved runtime security of
legacy C workloads.

Note - ongoing performance analysis and optimization from Arm / CHERI team.
Also note other security and performance benefits of CHERI (compartmentalization) that we have not considered at all in this study.

% \textbf{Acknowledgements:} We thank Ruben Ayrapetyan and David Chisnall for
% comments. This work was funded by the Digital Security by Design (DSbD) Programme
% delivered by UKRI.


\bibliographystyle{plain}
\bibliography{bib}

\end{document}
